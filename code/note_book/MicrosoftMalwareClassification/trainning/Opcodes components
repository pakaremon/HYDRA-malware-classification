{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24176,"status":"ok","timestamp":1713408025093,"user":{"displayName":"Nguyễn Thành Công","userId":"07855209270426231427"},"user_tz":-420},"id":"FSRz6T6ftrJN","outputId":"d48c3faf-9b57-4406-9bad-83e1539eafef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10386,"status":"ok","timestamp":1713408038375,"user":{"displayName":"Nguyễn Thành Công","userId":"07855209270426231427"},"user_tz":-420},"id":"FqYYnr80jJY6","outputId":"730a6e5d-445f-4f54-8b87-02c6d3e5c9a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n"]}],"source":["!pip install pyyaml h5py  # Required to save models in HDF5 format"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12408,"status":"ok","timestamp":1713408050779,"user":{"displayName":"Nguyễn Thành Công","userId":"07855209270426231427"},"user_tz":-420},"id":"H4AhIJAtK6bL","outputId":"152b35d2-1d29-44cc-fef1-c316662022f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_text==2.15.0\n","  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text==2.15.0) (0.16.1)\n","Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text==2.15.0) (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (4.11.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.62.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.15.0)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.13.0->tensorflow_text==2.15.0) (2.15.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.0.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.2.2)\n","Installing collected packages: tensorflow_text\n","Successfully installed tensorflow_text-2.15.0\n"]}],"source":["%pip install tensorflow_text==2.15.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kwj9SqgiehyI"},"outputs":[],"source":["import os\n","\n","import tensorflow as tf\n","import csv\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","from keras.models import load_model\n","from tensorflow.keras.models import model_from_json\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1713408058598,"user":{"displayName":"Nguyễn Thành Công","userId":"07855209270426231427"},"user_tz":-420},"id":"MWxFnDQLLgxa","outputId":"91f75ba1-efd9-40db-9699-3bed05d0bc1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.15.0\n"]}],"source":["import tensorflow_text\n","print(tensorflow_text.__version__)"]},{"cell_type":"markdown","metadata":{"id":"nBc9NN71DkJI"},"source":[]},{"cell_type":"markdown","metadata":{"id":"pYEN05bVzhe5"},"source":["# trainning opcode"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m6V1OkNnz1fV"},"outputs":[],"source":["def create_lookup_table(vocabulary_mapping, num_oov_buckets):\n","    keys = [k for k in vocabulary_mapping.keys()]\n","    values = [tf.constant(vocabulary_mapping[k], dtype=tf.int64) for k in keys]\n","\n","    table = tf.lookup.StaticVocabularyTable(\n","        tf.lookup.KeyValueTensorInitializer(\n","            keys=keys,\n","            values=values\n","        ),\n","        num_oov_buckets\n","    )\n","    return table"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UALnHpsBz2PN"},"outputs":[],"source":["import tensorflow_text as text\n","\n","\n","def _parse_tfrecord_function(example, lookup_table):\n","    example_fmt = {\n","            'opcodes': tf.io.FixedLenFeature([], tf.string),\n","            'label': tf.io.FixedLenFeature([], tf.int64)\n","        }\n","    parsed = tf.io.parse_single_example(example, example_fmt)\n","    tokenizer = text.WhitespaceTokenizer()\n","    tokens = tokenizer.tokenize(parsed['opcodes'])\n","    IDs = lookup_table.lookup(tokens)\n","    return IDs, parsed['label']\n","\n","\n","def make_dataset(filepath, lookup_table, SHUFFLE_BUFFER_SIZE=1024, BATCH_SIZE=32, EPOCHS=5):\n","    dataset = tf.data.TFRecordDataset(filepath)\n","    dataset = dataset.shuffle(SHUFFLE_BUFFER_SIZE)\n","    dataset = dataset.repeat(EPOCHS)\n","    dataset = dataset.map(lambda x: _parse_tfrecord_function(x, lookup_table))\n","    dataset = dataset.batch(batch_size=BATCH_SIZE)\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bi6PBoAf0qpN"},"outputs":[],"source":["parameters = {\n","\"V\": 461,\n","\"E\": 4,\n","\"conv\":{\n","  \"num_filters\": 100,\n","  \"size\":[3,5,7]\n","},\n","\"output\":9,\n","\"buffer_size\": 8000,\n","\"batch_size\":32,\n","\"epochs\":50,\n","\"learning_rate\":0.001,\n","\"seq_length\":50000,\n","\"gpu\":\"0\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZRHSS6-0BMW"},"outputs":[],"source":["class ShallowCNN(tf.keras.Model):\n","    def __init__(self, parameters):\n","        super(ShallowCNN, self).__init__()\n","        self.parameters = parameters\n","\n","    def build(self, input_shapes):\n","        self.emb = tf.keras.layers.Embedding(self.parameters['V'], self.parameters['E'], input_shape=(None, self.parameters['seq_length']))\n","\n","        self.conv_3 = tf.keras.layers.Conv2D(self.parameters['conv']['num_filters'],\n","                                             (self.parameters['conv']['size'][0], self.parameters['E']),\n","                                             activation=\"relu\",\n","                                             input_shape=(None,\n","                                                          self.parameters['seq_length'],\n","                                                          self.parameters['E']))\n","        self.global_max_pooling_3 = tf.keras.layers.GlobalMaxPooling2D()\n","\n","        self.conv_5 = tf.keras.layers.Conv2D(self.parameters['conv']['num_filters'],\n","                                             (self.parameters['conv']['size'][1], self.parameters['E']),\n","                                             activation=\"relu\",\n","                                             input_shape=(None,\n","                                                          self.parameters['seq_length'],\n","                                                          self.parameters['E']))\n","        self.global_max_pooling_5 = tf.keras.layers.GlobalMaxPooling2D()\n","\n","\n","        self.conv_7 = tf.keras.layers.Conv2D(self.parameters['conv']['num_filters'],\n","                                             (self.parameters['conv']['size'][2], self.parameters['E']),\n","                                             activation=\"relu\",\n","                                             input_shape=(None,\n","                                                          self.parameters['seq_length'],\n","                                                          self.parameters['E']))\n","        self.global_max_pooling_7 = tf.keras.layers.GlobalMaxPooling2D()\n","\n","        self.dense_dropout = tf.keras.layers.Dropout(0.5)\n","        self.dense = tf.keras.layers.Dense(self.parameters['output'],\n","                                           activation=\"softmax\")\n","\n","    def call(self, input_tensor, training=False):\n","        emb = self.emb(input_tensor)\n","        emb_expanded = tf.keras.backend.expand_dims(emb, axis=-1)\n","\n","\n","        conv_3 = self.conv_3(emb_expanded)\n","        pool_3 = self.global_max_pooling_3(conv_3)\n","\n","        conv_5 = self.conv_5(emb_expanded)\n","        pool_5 = self.global_max_pooling_5(conv_5)\n","\n","        conv_7 = self.conv_7(emb_expanded)\n","        pool_7 = self.global_max_pooling_7(conv_7)\n","\n","        features = tf.keras.layers.concatenate([pool_3, pool_5, pool_7])\n","        features_dropout = self.dense_dropout(features, training=training)\n","        output = self.dense(features_dropout)\n","\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vxRLY0M90B3V"},"outputs":[],"source":["model = ShallowCNN(parameters)\n","# if os.path.isfile(\"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/opcodes/FullData/opcode_model_cp.weights.h5\"):\n","#         print(\"LOADING WEIGHTS!!!!\")\n","#         # latest = tf.train.latest_checkpoint(\"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/bytes/model/bytes_model.weights.h5\")\n","#         model.load_weights(\"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/opcodes/FullData/opcode_model_cp.weights.h5\")\n","\n","# if os.path.isdir(\"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/models/{}/\".format(\"ShallowCNN\")):\n","#    print(\"LOADING WEIGHTS!!!!\")\n","#    latest = tf.train.latest_checkpoint(\"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/models/{}/\".format(\"ShallowCNN\"))\n","#    model.load_weights(latest)\n","\n","loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n","accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=parameters['learning_rate'])\n","def train_loop(features, labels, training=False):\n","    # Define the GradientTape context\n","    with tf.GradientTape() as tape:\n","        # Get the probabilities\n","        predictions = model(features)\n","        labels = tf.dtypes.cast(labels, tf.float32)\n","        # Calculate the loss\n","        loss = loss_func(labels, predictions)\n","\n","    # Get the gradients\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    # Update the weights\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","    return loss, predictions\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"k3ZowJ077ot0"},"source":["# train for 5000 samples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"0hK5aEe6r3QQ","executionInfo":{"status":"error","timestamp":1713258407456,"user_tz":-420,"elapsed":1104131,"user":{"displayName":"Nguyễn Thành Công","userId":"07855209270426231427"}},"outputId":"228b774f-1d8d-41b4-e8ec-9c8299fc27be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Current epoch: 0\n","Iteration step: 0; Loss: 2.194, Accuracy: 21.875%\n","Iteration step: 1; Loss: 2.189, Accuracy: 23.438%\n","Iteration step: 2; Loss: 2.183, Accuracy: 32.292%\n","Iteration step: 3; Loss: 2.177, Accuracy: 37.500%\n","Iteration step: 4; Loss: 2.171, Accuracy: 39.375%\n","Iteration step: 5; Loss: 2.164, Accuracy: 41.667%\n","Iteration step: 6; Loss: 2.162, Accuracy: 37.500%\n","Iteration step: 7; Loss: 2.158, Accuracy: 38.672%\n","Iteration step: 8; Loss: 2.155, Accuracy: 37.847%\n","Iteration step: 9; Loss: 2.149, Accuracy: 38.438%\n","Iteration step: 10; Loss: 2.142, Accuracy: 40.341%\n","Iteration step: 11; Loss: 2.138, Accuracy: 40.104%\n","Iteration step: 12; Loss: 2.134, Accuracy: 40.144%\n","Iteration step: 13; Loss: 2.132, Accuracy: 39.509%\n","Iteration step: 14; Loss: 2.127, Accuracy: 38.125%\n","Iteration step: 15; Loss: 2.121, Accuracy: 37.891%\n","Iteration step: 16; Loss: 2.116, Accuracy: 37.500%\n","Iteration step: 17; Loss: 2.109, Accuracy: 37.500%\n","Iteration step: 18; Loss: 2.104, Accuracy: 36.842%\n","Iteration step: 19; Loss: 2.102, Accuracy: 35.469%\n","Iteration step: 20; Loss: 2.102, Accuracy: 34.673%\n","Iteration step: 21; Loss: 2.097, Accuracy: 34.659%\n","Iteration step: 22; Loss: 2.091, Accuracy: 34.918%\n","Iteration step: 23; Loss: 2.086, Accuracy: 35.286%\n","Iteration step: 24; Loss: 2.082, Accuracy: 35.750%\n","Iteration step: 25; Loss: 2.080, Accuracy: 36.058%\n","Iteration step: 26; Loss: 2.075, Accuracy: 36.574%\n","Iteration step: 27; Loss: 2.067, Accuracy: 37.388%\n","Iteration step: 28; Loss: 2.064, Accuracy: 37.500%\n","Iteration step: 29; Loss: 2.059, Accuracy: 37.917%\n","Iteration step: 30; Loss: 2.055, Accuracy: 38.407%\n","Iteration step: 31; Loss: 2.048, Accuracy: 38.574%\n","Iteration step: 32; Loss: 2.040, Accuracy: 38.636%\n","Iteration step: 33; Loss: 2.036, Accuracy: 38.419%\n","Iteration step: 34; Loss: 2.029, Accuracy: 38.214%\n","Iteration step: 35; Loss: 2.029, Accuracy: 37.674%\n","Iteration step: 36; Loss: 2.026, Accuracy: 37.078%\n","Iteration step: 37; Loss: 2.022, Accuracy: 36.678%\n","Iteration step: 38; Loss: 2.013, Accuracy: 36.699%\n","Iteration step: 39; Loss: 2.009, Accuracy: 36.562%\n","Iteration step: 40; Loss: 2.006, Accuracy: 36.433%\n","Iteration step: 41; Loss: 1.998, Accuracy: 36.310%\n","Iteration step: 42; Loss: 1.995, Accuracy: 36.119%\n","Iteration step: 43; Loss: 1.994, Accuracy: 35.653%\n","Iteration step: 44; Loss: 1.991, Accuracy: 35.278%\n","Iteration step: 45; Loss: 1.983, Accuracy: 35.462%\n","Iteration step: 46; Loss: 1.984, Accuracy: 35.106%\n","Iteration step: 47; Loss: 1.978, Accuracy: 35.026%\n","Iteration step: 48; Loss: 1.971, Accuracy: 34.758%\n","Iteration step: 49; Loss: 1.967, Accuracy: 34.813%\n","Iteration step: 50; Loss: 1.967, Accuracy: 34.743%\n","Iteration step: 51; Loss: 1.967, Accuracy: 34.796%\n","Iteration step: 52; Loss: 1.969, Accuracy: 34.906%\n","Iteration step: 53; Loss: 1.964, Accuracy: 34.954%\n","Iteration step: 54; Loss: 1.963, Accuracy: 35.057%\n","Iteration step: 55; Loss: 1.957, Accuracy: 35.379%\n","Iteration step: 56; Loss: 1.951, Accuracy: 35.800%\n","Iteration step: 57; Loss: 1.945, Accuracy: 36.045%\n","Iteration step: 58; Loss: 1.940, Accuracy: 36.335%\n","Iteration step: 59; Loss: 1.937, Accuracy: 36.458%\n","Iteration step: 60; Loss: 1.932, Accuracy: 36.834%\n","Iteration step: 61; Loss: 1.929, Accuracy: 37.046%\n","Iteration step: 62; Loss: 1.924, Accuracy: 37.351%\n","Iteration step: 63; Loss: 1.921, Accuracy: 37.598%\n","Iteration step: 64; Loss: 1.917, Accuracy: 37.788%\n","Iteration step: 65; Loss: 1.916, Accuracy: 37.879%\n","Iteration step: 66; Loss: 1.916, Accuracy: 38.060%\n","Iteration step: 67; Loss: 1.918, Accuracy: 37.960%\n","Iteration step: 68; Loss: 1.917, Accuracy: 37.998%\n","Iteration step: 69; Loss: 1.910, Accuracy: 38.348%\n","Iteration step: 70; Loss: 1.911, Accuracy: 38.292%\n","Iteration step: 71; Loss: 1.910, Accuracy: 38.368%\n","Iteration step: 72; Loss: 1.908, Accuracy: 38.399%\n","Iteration step: 73; Loss: 1.904, Accuracy: 38.767%\n","Iteration step: 74; Loss: 1.902, Accuracy: 38.667%\n","Iteration step: 75; Loss: 1.899, Accuracy: 38.857%\n","Iteration step: 76; Loss: 1.895, Accuracy: 39.205%\n","Iteration step: 77; Loss: 1.893, Accuracy: 39.223%\n","Iteration step: 78; Loss: 1.892, Accuracy: 39.122%\n","Iteration step: 79; Loss: 1.889, Accuracy: 39.180%\n","Iteration step: 80; Loss: 1.886, Accuracy: 39.236%\n","Iteration step: 81; Loss: 1.885, Accuracy: 39.329%\n","Iteration step: 82; Loss: 1.883, Accuracy: 39.383%\n","Iteration step: 83; Loss: 1.883, Accuracy: 39.286%\n","Iteration step: 84; Loss: 1.883, Accuracy: 39.228%\n","Iteration step: 85; Loss: 1.878, Accuracy: 39.426%\n","Iteration step: 86; Loss: 1.875, Accuracy: 39.511%\n","Iteration step: 87; Loss: 1.870, Accuracy: 39.844%\n","Iteration step: 88; Loss: 1.868, Accuracy: 39.993%\n","Iteration step: 89; Loss: 1.865, Accuracy: 40.000%\n","Iteration step: 90; Loss: 1.862, Accuracy: 40.076%\n","Iteration step: 91; Loss: 1.862, Accuracy: 40.048%\n","Iteration step: 92; Loss: 1.861, Accuracy: 40.087%\n","Iteration step: 93; Loss: 1.859, Accuracy: 40.193%\n","Iteration step: 94; Loss: 1.854, Accuracy: 40.329%\n","Iteration step: 95; Loss: 1.849, Accuracy: 40.592%\n","Iteration step: 96; Loss: 1.847, Accuracy: 40.561%\n","Iteration step: 97; Loss: 1.844, Accuracy: 40.721%\n","Iteration step: 98; Loss: 1.840, Accuracy: 40.909%\n","Iteration step: 99; Loss: 1.837, Accuracy: 40.969%\n","Iteration step: 100; Loss: 1.834, Accuracy: 40.965%\n","Iteration step: 101; Loss: 1.836, Accuracy: 40.839%\n","Iteration step: 102; Loss: 1.835, Accuracy: 40.777%\n","Iteration step: 103; Loss: 1.831, Accuracy: 40.865%\n","Iteration step: 104; Loss: 1.828, Accuracy: 40.952%\n","Iteration step: 105; Loss: 1.823, Accuracy: 41.067%\n","Iteration step: 106; Loss: 1.819, Accuracy: 41.238%\n","Iteration step: 107; Loss: 1.818, Accuracy: 41.204%\n","Iteration step: 108; Loss: 1.814, Accuracy: 41.313%\n","Iteration step: 109; Loss: 1.811, Accuracy: 41.449%\n","Iteration step: 110; Loss: 1.809, Accuracy: 41.441%\n","Iteration step: 111; Loss: 1.807, Accuracy: 41.490%\n","Iteration step: 112; Loss: 1.805, Accuracy: 41.510%\n","Iteration step: 113; Loss: 1.801, Accuracy: 41.584%\n","Iteration step: 114; Loss: 1.798, Accuracy: 41.576%\n","Iteration step: 115; Loss: 1.795, Accuracy: 41.649%\n","Iteration step: 116; Loss: 1.793, Accuracy: 41.800%\n","Iteration step: 117; Loss: 1.789, Accuracy: 42.055%\n","Iteration step: 118; Loss: 1.784, Accuracy: 42.279%\n","Iteration step: 119; Loss: 1.782, Accuracy: 42.448%\n","Iteration step: 120; Loss: 1.780, Accuracy: 42.536%\n","Iteration step: 121; Loss: 1.775, Accuracy: 42.828%\n","Iteration step: 122; Loss: 1.770, Accuracy: 43.089%\n","Iteration step: 123; Loss: 1.770, Accuracy: 43.095%\n","Iteration step: 124; Loss: 1.767, Accuracy: 43.300%\n","Iteration step: 125; Loss: 1.764, Accuracy: 43.477%\n","Iteration step: 126; Loss: 1.760, Accuracy: 43.725%\n","Iteration step: 127; Loss: 1.755, Accuracy: 43.896%\n","Iteration step: 128; Loss: 1.753, Accuracy: 43.871%\n","Iteration step: 129; Loss: 1.750, Accuracy: 43.966%\n","Iteration step: 130; Loss: 1.746, Accuracy: 44.060%\n","Iteration step: 131; Loss: 1.743, Accuracy: 44.010%\n","Iteration step: 132; Loss: 1.740, Accuracy: 44.126%\n","Iteration step: 133; Loss: 1.737, Accuracy: 44.216%\n","Iteration step: 134; Loss: 1.732, Accuracy: 44.352%\n","Iteration step: 135; Loss: 1.730, Accuracy: 44.324%\n","Iteration step: 136; Loss: 1.727, Accuracy: 44.297%\n","Iteration step: 137; Loss: 1.722, Accuracy: 44.407%\n","Iteration step: 138; Loss: 1.721, Accuracy: 44.312%\n","Iteration step: 139; Loss: 1.720, Accuracy: 44.308%\n","Iteration step: 140; Loss: 1.717, Accuracy: 44.348%\n","Iteration step: 141; Loss: 1.715, Accuracy: 44.366%\n","Iteration step: 142; Loss: 1.713, Accuracy: 44.318%\n","Iteration step: 143; Loss: 1.711, Accuracy: 44.314%\n","Iteration step: 144; Loss: 1.710, Accuracy: 44.375%\n","Iteration step: 145; Loss: 1.706, Accuracy: 44.521%\n","Iteration step: 146; Loss: 1.703, Accuracy: 44.643%\n","Iteration step: 147; Loss: 1.700, Accuracy: 44.806%\n","Iteration step: 148; Loss: 1.696, Accuracy: 45.029%\n","Iteration step: 149; Loss: 1.693, Accuracy: 45.229%\n","Iteration step: 150; Loss: 1.689, Accuracy: 45.385%\n","Iteration step: 151; Loss: 1.684, Accuracy: 45.559%\n","Iteration step: 152; Loss: 1.682, Accuracy: 45.690%\n","Iteration step: 153; Loss: 1.680, Accuracy: 45.820%\n","Iteration step: 154; Loss: 1.676, Accuracy: 46.008%\n","Iteration step: 155; Loss: 1.672, Accuracy: 46.154%\n","Iteration step: 156; Loss: 1.668, Accuracy: 46.318%\n","Iteration step: 157; Loss: 1.664, Accuracy: 46.460%\n","Iteration step: 158; Loss: 1.661, Accuracy: 46.600%\n","Iteration step: 159; Loss: 1.657, Accuracy: 46.738%\n","Iteration step: 160; Loss: 1.655, Accuracy: 46.875%\n","Iteration step: 161; Loss: 1.652, Accuracy: 46.933%\n","Iteration step: 162; Loss: 1.649, Accuracy: 46.952%\n","Iteration step: 163; Loss: 1.647, Accuracy: 46.932%\n","Iteration step: 164; Loss: 1.642, Accuracy: 47.083%\n","Iteration step: 165; Loss: 1.640, Accuracy: 47.079%\n","Epoch: 0; Validation loss 1.1506518125534058; acc: 0.4951786696910858\n","Current epoch: 1\n","Iteration step: 0; Loss: 1.576, Accuracy: 31.250%\n","Iteration step: 1; Loss: 1.520, Accuracy: 35.938%\n","Iteration step: 2; Loss: 1.343, Accuracy: 47.917%\n","Iteration step: 3; Loss: 1.204, Accuracy: 56.250%\n","Iteration step: 4; Loss: 1.175, Accuracy: 56.875%\n","Iteration step: 5; Loss: 1.124, Accuracy: 59.375%\n","Iteration step: 6; Loss: 1.115, Accuracy: 60.714%\n","Iteration step: 7; Loss: 1.120, Accuracy: 61.719%\n","Iteration step: 8; Loss: 1.108, Accuracy: 62.500%\n","Iteration step: 9; Loss: 1.102, Accuracy: 63.750%\n","Iteration step: 10; Loss: 1.091, Accuracy: 65.057%\n","Iteration step: 11; Loss: 1.076, Accuracy: 65.885%\n","Iteration step: 12; Loss: 1.075, Accuracy: 66.106%\n","Iteration step: 13; Loss: 1.090, Accuracy: 66.071%\n","Iteration step: 14; Loss: 1.080, Accuracy: 66.875%\n","Iteration step: 15; Loss: 1.086, Accuracy: 66.406%\n","Iteration step: 16; Loss: 1.081, Accuracy: 66.544%\n","Iteration step: 17; Loss: 1.077, Accuracy: 67.014%\n","Iteration step: 18; Loss: 1.088, Accuracy: 66.941%\n","Iteration step: 19; Loss: 1.085, Accuracy: 67.188%\n","Iteration step: 20; Loss: 1.098, Accuracy: 66.815%\n","Iteration step: 21; Loss: 1.093, Accuracy: 67.188%\n","Iteration step: 22; Loss: 1.083, Accuracy: 67.663%\n","Iteration step: 23; Loss: 1.085, Accuracy: 67.318%\n","Iteration step: 24; Loss: 1.095, Accuracy: 66.750%\n","Iteration step: 25; Loss: 1.087, Accuracy: 66.707%\n","Iteration step: 26; Loss: 1.083, Accuracy: 66.898%\n","Iteration step: 27; Loss: 1.074, Accuracy: 66.964%\n","Iteration step: 28; Loss: 1.073, Accuracy: 66.918%\n","Iteration step: 29; Loss: 1.074, Accuracy: 66.771%\n","Iteration step: 30; Loss: 1.066, Accuracy: 67.238%\n","Iteration step: 31; Loss: 1.068, Accuracy: 67.578%\n","Iteration step: 32; Loss: 1.065, Accuracy: 67.614%\n","Iteration step: 33; Loss: 1.064, Accuracy: 67.647%\n","Iteration step: 34; Loss: 1.063, Accuracy: 67.589%\n","Iteration step: 35; Loss: 1.059, Accuracy: 67.882%\n","Iteration step: 36; Loss: 1.055, Accuracy: 68.243%\n","Iteration step: 37; Loss: 1.053, Accuracy: 68.586%\n","Iteration step: 38; Loss: 1.054, Accuracy: 68.510%\n","Iteration step: 39; Loss: 1.051, Accuracy: 68.672%\n","Iteration step: 40; Loss: 1.047, Accuracy: 68.826%\n","Iteration step: 41; Loss: 1.052, Accuracy: 68.378%\n","Iteration step: 42; Loss: 1.050, Accuracy: 68.605%\n","Iteration step: 43; Loss: 1.053, Accuracy: 68.537%\n","Iteration step: 44; Loss: 1.053, Accuracy: 68.611%\n","Iteration step: 45; Loss: 1.056, Accuracy: 68.614%\n","Iteration step: 46; Loss: 1.056, Accuracy: 68.883%\n","Iteration step: 47; Loss: 1.059, Accuracy: 68.750%\n","Iteration step: 48; Loss: 1.060, Accuracy: 68.941%\n","Iteration step: 49; Loss: 1.052, Accuracy: 69.125%\n","Iteration step: 50; Loss: 1.048, Accuracy: 69.118%\n","Iteration step: 51; Loss: 1.046, Accuracy: 69.291%\n","Iteration step: 52; Loss: 1.044, Accuracy: 69.458%\n","Iteration step: 53; Loss: 1.040, Accuracy: 69.734%\n","Iteration step: 54; Loss: 1.036, Accuracy: 70.000%\n","Iteration step: 55; Loss: 1.034, Accuracy: 69.978%\n","Iteration step: 56; Loss: 1.034, Accuracy: 69.901%\n","Iteration step: 57; Loss: 1.032, Accuracy: 69.881%\n","Iteration step: 58; Loss: 1.034, Accuracy: 69.703%\n","Iteration step: 59; Loss: 1.032, Accuracy: 69.687%\n","Iteration step: 60; Loss: 1.033, Accuracy: 69.621%\n","Iteration step: 61; Loss: 1.031, Accuracy: 69.708%\n","Iteration step: 62; Loss: 1.033, Accuracy: 69.643%\n","Iteration step: 63; Loss: 1.035, Accuracy: 69.434%\n","Iteration step: 64; Loss: 1.031, Accuracy: 69.519%\n","Iteration step: 65; Loss: 1.032, Accuracy: 69.508%\n","Iteration step: 66; Loss: 1.027, Accuracy: 69.729%\n","Iteration step: 67; Loss: 1.025, Accuracy: 69.899%\n","Iteration step: 68; Loss: 1.023, Accuracy: 70.018%\n","Iteration step: 69; Loss: 1.022, Accuracy: 70.089%\n","Iteration step: 70; Loss: 1.018, Accuracy: 70.246%\n","Iteration step: 71; Loss: 1.017, Accuracy: 70.226%\n","Iteration step: 72; Loss: 1.012, Accuracy: 70.505%\n","Iteration step: 73; Loss: 1.013, Accuracy: 70.481%\n","Iteration step: 74; Loss: 1.011, Accuracy: 70.500%\n","Iteration step: 75; Loss: 1.008, Accuracy: 70.765%\n","Iteration step: 76; Loss: 1.003, Accuracy: 71.023%\n","Iteration step: 77; Loss: 1.000, Accuracy: 71.074%\n","Iteration step: 78; Loss: 0.997, Accuracy: 71.163%\n","Iteration step: 79; Loss: 0.996, Accuracy: 71.172%\n","Iteration step: 80; Loss: 0.995, Accuracy: 71.181%\n","Iteration step: 81; Loss: 0.992, Accuracy: 71.303%\n","Iteration step: 82; Loss: 0.989, Accuracy: 71.348%\n","Iteration step: 83; Loss: 0.988, Accuracy: 71.280%\n","Iteration step: 84; Loss: 0.990, Accuracy: 71.140%\n","Iteration step: 85; Loss: 0.987, Accuracy: 71.112%\n","Iteration step: 86; Loss: 0.983, Accuracy: 71.228%\n","Iteration step: 87; Loss: 0.981, Accuracy: 71.236%\n","Iteration step: 88; Loss: 0.977, Accuracy: 71.383%\n","Iteration step: 89; Loss: 0.977, Accuracy: 71.493%\n","Iteration step: 90; Loss: 0.975, Accuracy: 71.497%\n","Iteration step: 91; Loss: 0.974, Accuracy: 71.535%\n","Iteration step: 92; Loss: 0.974, Accuracy: 71.438%\n","Iteration step: 93; Loss: 0.973, Accuracy: 71.476%\n","Iteration step: 94; Loss: 0.971, Accuracy: 71.546%\n","Iteration step: 95; Loss: 0.968, Accuracy: 71.582%\n","Iteration step: 96; Loss: 0.967, Accuracy: 71.553%\n","Iteration step: 97; Loss: 0.966, Accuracy: 71.652%\n","Iteration step: 98; Loss: 0.964, Accuracy: 71.749%\n","Iteration step: 99; Loss: 0.962, Accuracy: 71.844%\n","Iteration step: 100; Loss: 0.961, Accuracy: 71.906%\n","Iteration step: 101; Loss: 0.958, Accuracy: 72.059%\n","Iteration step: 102; Loss: 0.955, Accuracy: 72.118%\n","Iteration step: 103; Loss: 0.951, Accuracy: 72.296%\n","Iteration step: 104; Loss: 0.951, Accuracy: 72.351%\n","Iteration step: 105; Loss: 0.950, Accuracy: 72.376%\n","Iteration step: 106; Loss: 0.949, Accuracy: 72.401%\n","Iteration step: 107; Loss: 0.948, Accuracy: 72.454%\n","Iteration step: 108; Loss: 0.947, Accuracy: 72.506%\n","Iteration step: 109; Loss: 0.944, Accuracy: 72.670%\n","Iteration step: 110; Loss: 0.943, Accuracy: 72.748%\n","Iteration step: 111; Loss: 0.940, Accuracy: 72.852%\n","Iteration step: 112; Loss: 0.938, Accuracy: 72.954%\n","Iteration step: 113; Loss: 0.935, Accuracy: 73.081%\n","Iteration step: 114; Loss: 0.934, Accuracy: 73.125%\n","Iteration step: 115; Loss: 0.933, Accuracy: 73.195%\n","Iteration step: 116; Loss: 0.932, Accuracy: 73.237%\n","Iteration step: 117; Loss: 0.928, Accuracy: 73.305%\n","Iteration step: 118; Loss: 0.927, Accuracy: 73.398%\n","Iteration step: 119; Loss: 0.927, Accuracy: 73.385%\n","Iteration step: 120; Loss: 0.925, Accuracy: 73.528%\n","Iteration step: 121; Loss: 0.921, Accuracy: 73.668%\n","Iteration step: 122; Loss: 0.918, Accuracy: 73.780%\n","Iteration step: 123; Loss: 0.917, Accuracy: 73.790%\n","Iteration step: 124; Loss: 0.917, Accuracy: 73.725%\n","Iteration step: 125; Loss: 0.916, Accuracy: 73.760%\n","Iteration step: 126; Loss: 0.914, Accuracy: 73.868%\n","Iteration step: 127; Loss: 0.912, Accuracy: 73.950%\n","Iteration step: 128; Loss: 0.909, Accuracy: 74.079%\n","Iteration step: 129; Loss: 0.908, Accuracy: 74.087%\n","Iteration step: 130; Loss: 0.907, Accuracy: 74.117%\n","Iteration step: 131; Loss: 0.906, Accuracy: 74.195%\n","Iteration step: 132; Loss: 0.903, Accuracy: 74.319%\n","Iteration step: 133; Loss: 0.902, Accuracy: 74.324%\n","Iteration step: 134; Loss: 0.900, Accuracy: 74.421%\n","Iteration step: 135; Loss: 0.899, Accuracy: 74.449%\n","Iteration step: 136; Loss: 0.899, Accuracy: 74.384%\n","Iteration step: 137; Loss: 0.898, Accuracy: 74.479%\n","Iteration step: 138; Loss: 0.895, Accuracy: 74.618%\n","Iteration step: 139; Loss: 0.893, Accuracy: 74.687%\n","Iteration step: 140; Loss: 0.891, Accuracy: 74.778%\n","Iteration step: 141; Loss: 0.887, Accuracy: 74.912%\n","Iteration step: 142; Loss: 0.885, Accuracy: 75.000%\n","Iteration step: 143; Loss: 0.884, Accuracy: 75.000%\n","Iteration step: 144; Loss: 0.882, Accuracy: 75.108%\n","Iteration step: 145; Loss: 0.880, Accuracy: 75.171%\n","Iteration step: 146; Loss: 0.878, Accuracy: 75.213%\n","Iteration step: 147; Loss: 0.875, Accuracy: 75.317%\n","Iteration step: 148; Loss: 0.874, Accuracy: 75.315%\n","Iteration step: 149; Loss: 0.872, Accuracy: 75.354%\n","Iteration step: 150; Loss: 0.872, Accuracy: 75.352%\n","Iteration step: 151; Loss: 0.870, Accuracy: 75.391%\n","Iteration step: 152; Loss: 0.868, Accuracy: 75.470%\n","Iteration step: 153; Loss: 0.867, Accuracy: 75.467%\n","Iteration step: 154; Loss: 0.865, Accuracy: 75.484%\n","Iteration step: 155; Loss: 0.863, Accuracy: 75.561%\n","Iteration step: 156; Loss: 0.862, Accuracy: 75.518%\n","Iteration step: 157; Loss: 0.860, Accuracy: 75.613%\n","Iteration step: 158; Loss: 0.861, Accuracy: 75.590%\n","Iteration step: 159; Loss: 0.860, Accuracy: 75.605%\n","Iteration step: 160; Loss: 0.858, Accuracy: 75.699%\n","Iteration step: 161; Loss: 0.856, Accuracy: 75.791%\n","Iteration step: 162; Loss: 0.854, Accuracy: 75.824%\n","Iteration step: 163; Loss: 0.854, Accuracy: 75.857%\n","Iteration step: 164; Loss: 0.851, Accuracy: 75.985%\n","Iteration step: 165; Loss: 0.849, Accuracy: 76.007%\n","Epoch: 1; Validation loss 0.6135990023612976; acc: 0.8205710053443909\n","Current epoch: 2\n","Iteration step: 0; Loss: 0.613, Accuracy: 78.125%\n","Iteration step: 1; Loss: 0.647, Accuracy: 78.125%\n","Iteration step: 2; Loss: 0.593, Accuracy: 80.208%\n","Iteration step: 3; Loss: 0.588, Accuracy: 80.469%\n","Iteration step: 4; Loss: 0.612, Accuracy: 81.250%\n","Iteration step: 5; Loss: 0.670, Accuracy: 79.688%\n","Iteration step: 6; Loss: 0.639, Accuracy: 81.250%\n","Iteration step: 7; Loss: 0.632, Accuracy: 81.641%\n","Iteration step: 8; Loss: 0.621, Accuracy: 82.639%\n","Iteration step: 9; Loss: 0.614, Accuracy: 82.500%\n","Iteration step: 10; Loss: 0.610, Accuracy: 82.102%\n","Iteration step: 11; Loss: 0.618, Accuracy: 81.510%\n","Iteration step: 12; Loss: 0.606, Accuracy: 81.971%\n","Iteration step: 13; Loss: 0.604, Accuracy: 82.589%\n","Iteration step: 14; Loss: 0.598, Accuracy: 82.917%\n","Iteration step: 15; Loss: 0.584, Accuracy: 83.594%\n","Iteration step: 16; Loss: 0.603, Accuracy: 83.088%\n","Iteration step: 17; Loss: 0.589, Accuracy: 83.507%\n","Iteration step: 18; Loss: 0.577, Accuracy: 84.046%\n","Iteration step: 19; Loss: 0.570, Accuracy: 84.375%\n","Iteration step: 20; Loss: 0.566, Accuracy: 84.375%\n","Iteration step: 21; Loss: 0.566, Accuracy: 84.517%\n","Iteration step: 22; Loss: 0.570, Accuracy: 84.511%\n","Iteration step: 23; Loss: 0.573, Accuracy: 84.375%\n","Iteration step: 24; Loss: 0.570, Accuracy: 84.500%\n","Iteration step: 25; Loss: 0.572, Accuracy: 84.375%\n","Iteration step: 26; Loss: 0.569, Accuracy: 84.606%\n","Iteration step: 27; Loss: 0.563, Accuracy: 85.045%\n","Iteration step: 28; Loss: 0.560, Accuracy: 85.237%\n","Iteration step: 29; Loss: 0.555, Accuracy: 85.312%\n","Iteration step: 30; Loss: 0.551, Accuracy: 85.383%\n","Iteration step: 31; Loss: 0.549, Accuracy: 85.449%\n","Iteration step: 32; Loss: 0.546, Accuracy: 85.606%\n","Iteration step: 33; Loss: 0.548, Accuracy: 85.478%\n","Iteration step: 34; Loss: 0.546, Accuracy: 85.804%\n","Iteration step: 35; Loss: 0.544, Accuracy: 85.938%\n","Iteration step: 36; Loss: 0.539, Accuracy: 86.149%\n","Iteration step: 37; Loss: 0.541, Accuracy: 86.102%\n","Iteration step: 38; Loss: 0.541, Accuracy: 86.218%\n","Iteration step: 39; Loss: 0.542, Accuracy: 86.328%\n","Iteration step: 40; Loss: 0.546, Accuracy: 86.357%\n","Iteration step: 41; Loss: 0.547, Accuracy: 86.235%\n","Iteration step: 42; Loss: 0.547, Accuracy: 86.337%\n","Iteration step: 43; Loss: 0.552, Accuracy: 86.222%\n","Iteration step: 44; Loss: 0.551, Accuracy: 86.319%\n","Iteration step: 45; Loss: 0.552, Accuracy: 86.413%\n","Iteration step: 46; Loss: 0.555, Accuracy: 86.237%\n","Iteration step: 47; Loss: 0.559, Accuracy: 86.198%\n","Iteration step: 48; Loss: 0.556, Accuracy: 86.288%\n","Iteration step: 49; Loss: 0.555, Accuracy: 86.250%\n","Iteration step: 50; Loss: 0.553, Accuracy: 86.213%\n","Iteration step: 51; Loss: 0.551, Accuracy: 86.358%\n","Iteration step: 52; Loss: 0.551, Accuracy: 86.321%\n","Iteration step: 53; Loss: 0.548, Accuracy: 86.458%\n","Iteration step: 54; Loss: 0.558, Accuracy: 86.193%\n","Iteration step: 55; Loss: 0.557, Accuracy: 86.328%\n","Iteration step: 56; Loss: 0.556, Accuracy: 86.184%\n","Iteration step: 57; Loss: 0.556, Accuracy: 86.207%\n","Iteration step: 58; Loss: 0.555, Accuracy: 86.282%\n","Iteration step: 59; Loss: 0.556, Accuracy: 86.302%\n","Iteration step: 60; Loss: 0.557, Accuracy: 86.373%\n","Iteration step: 61; Loss: 0.559, Accuracy: 86.190%\n","Iteration step: 62; Loss: 0.556, Accuracy: 86.310%\n","Iteration step: 63; Loss: 0.558, Accuracy: 86.084%\n","Iteration step: 64; Loss: 0.556, Accuracy: 86.202%\n","Iteration step: 65; Loss: 0.554, Accuracy: 86.222%\n","Iteration step: 66; Loss: 0.553, Accuracy: 86.287%\n","Iteration step: 67; Loss: 0.556, Accuracy: 86.213%\n","Iteration step: 68; Loss: 0.555, Accuracy: 86.232%\n","Iteration step: 69; Loss: 0.557, Accuracy: 86.161%\n","Iteration step: 70; Loss: 0.558, Accuracy: 86.092%\n","Iteration step: 71; Loss: 0.558, Accuracy: 85.938%\n","Iteration step: 72; Loss: 0.558, Accuracy: 85.873%\n","Iteration step: 73; Loss: 0.555, Accuracy: 85.980%\n","Iteration step: 74; Loss: 0.555, Accuracy: 85.958%\n","Iteration step: 75; Loss: 0.555, Accuracy: 85.896%\n","Iteration step: 76; Loss: 0.555, Accuracy: 85.877%\n","Iteration step: 77; Loss: 0.557, Accuracy: 85.777%\n","Iteration step: 78; Loss: 0.561, Accuracy: 85.562%\n","Iteration step: 79; Loss: 0.561, Accuracy: 85.547%\n","Iteration step: 80; Loss: 0.562, Accuracy: 85.455%\n","Iteration step: 81; Loss: 0.561, Accuracy: 85.442%\n","Iteration step: 82; Loss: 0.562, Accuracy: 85.429%\n","Iteration step: 83; Loss: 0.565, Accuracy: 85.231%\n","Iteration step: 84; Loss: 0.566, Accuracy: 85.294%\n","Iteration step: 85; Loss: 0.565, Accuracy: 85.283%\n","Iteration step: 86; Loss: 0.565, Accuracy: 85.309%\n","Iteration step: 87; Loss: 0.564, Accuracy: 85.298%\n","Iteration step: 88; Loss: 0.565, Accuracy: 85.358%\n","Iteration step: 89; Loss: 0.566, Accuracy: 85.278%\n","Iteration step: 90; Loss: 0.565, Accuracy: 85.268%\n","Iteration step: 91; Loss: 0.565, Accuracy: 85.190%\n","Iteration step: 92; Loss: 0.561, Accuracy: 85.249%\n","Iteration step: 93; Loss: 0.560, Accuracy: 85.306%\n","Iteration step: 94; Loss: 0.561, Accuracy: 85.197%\n","Iteration step: 95; Loss: 0.561, Accuracy: 85.091%\n","Iteration step: 96; Loss: 0.560, Accuracy: 85.148%\n","Iteration step: 97; Loss: 0.561, Accuracy: 85.140%\n","Iteration step: 98; Loss: 0.561, Accuracy: 85.101%\n","Iteration step: 99; Loss: 0.561, Accuracy: 85.094%\n","Iteration step: 100; Loss: 0.559, Accuracy: 85.118%\n","Iteration step: 101; Loss: 0.557, Accuracy: 85.172%\n","Iteration step: 102; Loss: 0.555, Accuracy: 85.255%\n","Iteration step: 103; Loss: 0.554, Accuracy: 85.337%\n","Iteration step: 104; Loss: 0.553, Accuracy: 85.417%\n","Iteration step: 105; Loss: 0.553, Accuracy: 85.407%\n","Iteration step: 106; Loss: 0.551, Accuracy: 85.456%\n","Iteration step: 107; Loss: 0.549, Accuracy: 85.446%\n","Iteration step: 108; Loss: 0.549, Accuracy: 85.493%\n","Iteration step: 109; Loss: 0.548, Accuracy: 85.540%\n","Iteration step: 110; Loss: 0.548, Accuracy: 85.529%\n","Iteration step: 111; Loss: 0.548, Accuracy: 85.547%\n","Iteration step: 112; Loss: 0.547, Accuracy: 85.564%\n","Iteration step: 113; Loss: 0.546, Accuracy: 85.609%\n","Iteration step: 114; Loss: 0.548, Accuracy: 85.571%\n","Iteration step: 115; Loss: 0.548, Accuracy: 85.587%\n","Iteration step: 116; Loss: 0.547, Accuracy: 85.684%\n","Iteration step: 117; Loss: 0.546, Accuracy: 85.699%\n","Iteration step: 118; Loss: 0.546, Accuracy: 85.714%\n","Iteration step: 119; Loss: 0.544, Accuracy: 85.807%\n","Iteration step: 120; Loss: 0.545, Accuracy: 85.718%\n","Iteration step: 121; Loss: 0.545, Accuracy: 85.758%\n","Iteration step: 122; Loss: 0.545, Accuracy: 85.696%\n","Iteration step: 123; Loss: 0.543, Accuracy: 85.736%\n","Iteration step: 124; Loss: 0.542, Accuracy: 85.775%\n","Iteration step: 125; Loss: 0.542, Accuracy: 85.764%\n","Iteration step: 126; Loss: 0.541, Accuracy: 85.753%\n","Iteration step: 127; Loss: 0.540, Accuracy: 85.767%\n","Iteration step: 128; Loss: 0.537, Accuracy: 85.853%\n","Iteration step: 129; Loss: 0.535, Accuracy: 85.938%\n","Iteration step: 130; Loss: 0.533, Accuracy: 85.949%\n","Iteration step: 131; Loss: 0.533, Accuracy: 85.961%\n","Iteration step: 132; Loss: 0.532, Accuracy: 85.949%\n","Iteration step: 133; Loss: 0.532, Accuracy: 85.961%\n","Iteration step: 134; Loss: 0.532, Accuracy: 85.949%\n","Iteration step: 135; Loss: 0.531, Accuracy: 85.983%\n","Iteration step: 136; Loss: 0.529, Accuracy: 86.063%\n","Iteration step: 137; Loss: 0.530, Accuracy: 86.051%\n","Iteration step: 138; Loss: 0.530, Accuracy: 86.039%\n","Iteration step: 139; Loss: 0.528, Accuracy: 86.116%\n","Iteration step: 140; Loss: 0.526, Accuracy: 86.170%\n","Iteration step: 141; Loss: 0.526, Accuracy: 86.202%\n","Iteration step: 142; Loss: 0.525, Accuracy: 86.254%\n","Iteration step: 143; Loss: 0.523, Accuracy: 86.285%\n","Iteration step: 144; Loss: 0.522, Accuracy: 86.315%\n","Iteration step: 145; Loss: 0.522, Accuracy: 86.280%\n","Iteration step: 146; Loss: 0.523, Accuracy: 86.203%\n","Iteration step: 147; Loss: 0.523, Accuracy: 86.170%\n","Iteration step: 148; Loss: 0.521, Accuracy: 86.200%\n","Iteration step: 149; Loss: 0.520, Accuracy: 86.229%\n","Iteration step: 150; Loss: 0.519, Accuracy: 86.258%\n","Iteration step: 151; Loss: 0.518, Accuracy: 86.308%\n","Iteration step: 152; Loss: 0.517, Accuracy: 86.336%\n","Iteration step: 153; Loss: 0.517, Accuracy: 86.343%\n","Iteration step: 154; Loss: 0.517, Accuracy: 86.331%\n","Iteration step: 155; Loss: 0.515, Accuracy: 86.358%\n","Iteration step: 156; Loss: 0.515, Accuracy: 86.346%\n","Iteration step: 157; Loss: 0.514, Accuracy: 86.392%\n","Iteration step: 158; Loss: 0.515, Accuracy: 86.360%\n","Iteration step: 159; Loss: 0.514, Accuracy: 86.406%\n","Iteration step: 160; Loss: 0.515, Accuracy: 86.374%\n","Iteration step: 161; Loss: 0.514, Accuracy: 86.381%\n","Iteration step: 162; Loss: 0.514, Accuracy: 86.369%\n","Iteration step: 163; Loss: 0.513, Accuracy: 86.376%\n","Iteration step: 164; Loss: 0.513, Accuracy: 86.364%\n","Iteration step: 165; Loss: 0.511, Accuracy: 86.368%\n","Epoch: 2; Validation loss 0.4157547652721405; acc: 0.8844771981239319\n","Current epoch: 3\n","Iteration step: 0; Loss: 0.488, Accuracy: 81.250%\n","Iteration step: 1; Loss: 0.387, Accuracy: 89.062%\n","Iteration step: 2; Loss: 0.414, Accuracy: 86.458%\n","Iteration step: 3; Loss: 0.432, Accuracy: 86.719%\n","Iteration step: 4; Loss: 0.457, Accuracy: 86.250%\n","Iteration step: 5; Loss: 0.438, Accuracy: 88.021%\n","Iteration step: 6; Loss: 0.422, Accuracy: 88.839%\n","Iteration step: 7; Loss: 0.396, Accuracy: 89.453%\n","Iteration step: 8; Loss: 0.365, Accuracy: 90.278%\n","Iteration step: 9; Loss: 0.365, Accuracy: 90.312%\n","Iteration step: 10; Loss: 0.374, Accuracy: 90.057%\n","Iteration step: 11; Loss: 0.356, Accuracy: 90.885%\n","Iteration step: 12; Loss: 0.377, Accuracy: 89.904%\n","Iteration step: 13; Loss: 0.382, Accuracy: 89.286%\n","Iteration step: 14; Loss: 0.379, Accuracy: 89.167%\n","Iteration step: 15; Loss: 0.380, Accuracy: 88.867%\n","Iteration step: 16; Loss: 0.382, Accuracy: 88.971%\n","Iteration step: 17; Loss: 0.376, Accuracy: 89.410%\n","Iteration step: 18; Loss: 0.371, Accuracy: 89.309%\n","Iteration step: 19; Loss: 0.363, Accuracy: 89.688%\n","Iteration step: 20; Loss: 0.362, Accuracy: 90.030%\n","Iteration step: 21; Loss: 0.370, Accuracy: 89.773%\n","Iteration step: 22; Loss: 0.367, Accuracy: 89.810%\n","Iteration step: 23; Loss: 0.371, Accuracy: 89.714%\n","Iteration step: 24; Loss: 0.369, Accuracy: 90.000%\n","Iteration step: 25; Loss: 0.368, Accuracy: 90.144%\n","Iteration step: 26; Loss: 0.372, Accuracy: 90.046%\n","Iteration step: 27; Loss: 0.375, Accuracy: 89.844%\n","Iteration step: 28; Loss: 0.371, Accuracy: 89.871%\n","Iteration step: 29; Loss: 0.369, Accuracy: 89.896%\n","Iteration step: 30; Loss: 0.370, Accuracy: 89.819%\n","Iteration step: 31; Loss: 0.372, Accuracy: 89.746%\n","Iteration step: 32; Loss: 0.366, Accuracy: 89.962%\n","Iteration step: 33; Loss: 0.364, Accuracy: 90.165%\n","Iteration step: 34; Loss: 0.370, Accuracy: 90.000%\n","Iteration step: 35; Loss: 0.372, Accuracy: 89.844%\n","Iteration step: 36; Loss: 0.370, Accuracy: 89.865%\n","Iteration step: 37; Loss: 0.368, Accuracy: 90.049%\n","Iteration step: 38; Loss: 0.378, Accuracy: 89.824%\n","Iteration step: 39; Loss: 0.378, Accuracy: 89.844%\n","Iteration step: 40; Loss: 0.377, Accuracy: 89.863%\n","Iteration step: 41; Loss: 0.373, Accuracy: 90.030%\n","Iteration step: 42; Loss: 0.370, Accuracy: 90.189%\n","Iteration step: 43; Loss: 0.371, Accuracy: 90.270%\n","Iteration step: 44; Loss: 0.368, Accuracy: 90.347%\n","Iteration step: 45; Loss: 0.371, Accuracy: 90.285%\n","Iteration step: 46; Loss: 0.372, Accuracy: 90.293%\n","Iteration step: 47; Loss: 0.369, Accuracy: 90.365%\n","Iteration step: 48; Loss: 0.372, Accuracy: 90.370%\n","Iteration step: 49; Loss: 0.372, Accuracy: 90.250%\n","Iteration step: 50; Loss: 0.376, Accuracy: 90.196%\n","Iteration step: 51; Loss: 0.377, Accuracy: 90.264%\n","Iteration step: 52; Loss: 0.380, Accuracy: 89.976%\n","Iteration step: 53; Loss: 0.381, Accuracy: 89.931%\n","Iteration step: 54; Loss: 0.383, Accuracy: 89.886%\n","Iteration step: 55; Loss: 0.388, Accuracy: 89.732%\n","Iteration step: 56; Loss: 0.391, Accuracy: 89.693%\n","Iteration step: 57; Loss: 0.388, Accuracy: 89.763%\n","Iteration step: 58; Loss: 0.391, Accuracy: 89.619%\n","Iteration step: 59; Loss: 0.393, Accuracy: 89.583%\n","Iteration step: 60; Loss: 0.394, Accuracy: 89.549%\n","Iteration step: 61; Loss: 0.394, Accuracy: 89.567%\n","Iteration step: 62; Loss: 0.397, Accuracy: 89.435%\n","Iteration step: 63; Loss: 0.396, Accuracy: 89.502%\n","Iteration step: 64; Loss: 0.398, Accuracy: 89.423%\n","Iteration step: 65; Loss: 0.398, Accuracy: 89.441%\n","Iteration step: 66; Loss: 0.398, Accuracy: 89.366%\n","Iteration step: 67; Loss: 0.397, Accuracy: 89.476%\n","Iteration step: 68; Loss: 0.398, Accuracy: 89.493%\n","Iteration step: 69; Loss: 0.400, Accuracy: 89.464%\n","Iteration step: 70; Loss: 0.398, Accuracy: 89.525%\n","Iteration step: 71; Loss: 0.395, Accuracy: 89.670%\n","Iteration step: 72; Loss: 0.394, Accuracy: 89.640%\n","Iteration step: 73; Loss: 0.395, Accuracy: 89.527%\n","Iteration step: 74; Loss: 0.395, Accuracy: 89.542%\n","Iteration step: 75; Loss: 0.397, Accuracy: 89.474%\n","Iteration step: 76; Loss: 0.401, Accuracy: 89.245%\n","Iteration step: 77; Loss: 0.400, Accuracy: 89.343%\n","Iteration step: 78; Loss: 0.399, Accuracy: 89.320%\n","Iteration step: 79; Loss: 0.401, Accuracy: 89.297%\n","Iteration step: 80; Loss: 0.403, Accuracy: 89.236%\n","Iteration step: 81; Loss: 0.404, Accuracy: 89.215%\n","Iteration step: 82; Loss: 0.402, Accuracy: 89.345%\n","Iteration step: 83; Loss: 0.400, Accuracy: 89.435%\n","Iteration step: 84; Loss: 0.399, Accuracy: 89.412%\n","Iteration step: 85; Loss: 0.397, Accuracy: 89.462%\n","Iteration step: 86; Loss: 0.398, Accuracy: 89.404%\n","Iteration step: 87; Loss: 0.398, Accuracy: 89.382%\n","Iteration step: 88; Loss: 0.398, Accuracy: 89.361%\n","Iteration step: 89; Loss: 0.396, Accuracy: 89.410%\n","Iteration step: 90; Loss: 0.396, Accuracy: 89.389%\n","Iteration step: 91; Loss: 0.396, Accuracy: 89.368%\n","Iteration step: 92; Loss: 0.397, Accuracy: 89.348%\n","Iteration step: 93; Loss: 0.398, Accuracy: 89.262%\n","Iteration step: 94; Loss: 0.399, Accuracy: 89.178%\n","Iteration step: 95; Loss: 0.400, Accuracy: 89.095%\n","Iteration step: 96; Loss: 0.400, Accuracy: 89.111%\n","Iteration step: 97; Loss: 0.398, Accuracy: 89.190%\n","Iteration step: 98; Loss: 0.397, Accuracy: 89.205%\n","Iteration step: 99; Loss: 0.398, Accuracy: 89.156%\n","Iteration step: 100; Loss: 0.397, Accuracy: 89.140%\n","Iteration step: 101; Loss: 0.396, Accuracy: 89.216%\n","Iteration step: 102; Loss: 0.397, Accuracy: 89.199%\n","Iteration step: 103; Loss: 0.396, Accuracy: 89.243%\n","Iteration step: 104; Loss: 0.397, Accuracy: 89.196%\n","Iteration step: 105; Loss: 0.398, Accuracy: 89.210%\n","Iteration step: 106; Loss: 0.397, Accuracy: 89.282%\n","Iteration step: 107; Loss: 0.395, Accuracy: 89.323%\n","Iteration step: 108; Loss: 0.396, Accuracy: 89.249%\n","Iteration step: 109; Loss: 0.395, Accuracy: 89.290%\n","Iteration step: 110; Loss: 0.394, Accuracy: 89.330%\n","Iteration step: 111; Loss: 0.391, Accuracy: 89.425%\n","Iteration step: 112; Loss: 0.391, Accuracy: 89.381%\n","Iteration step: 113; Loss: 0.394, Accuracy: 89.309%\n","Iteration step: 114; Loss: 0.394, Accuracy: 89.293%\n","Iteration step: 115; Loss: 0.394, Accuracy: 89.305%\n","Iteration step: 116; Loss: 0.395, Accuracy: 89.290%\n","Iteration step: 117; Loss: 0.395, Accuracy: 89.327%\n","Iteration step: 118; Loss: 0.394, Accuracy: 89.338%\n","Iteration step: 119; Loss: 0.395, Accuracy: 89.349%\n","Iteration step: 120; Loss: 0.393, Accuracy: 89.437%\n","Iteration step: 121; Loss: 0.391, Accuracy: 89.498%\n","Iteration step: 122; Loss: 0.390, Accuracy: 89.533%\n","Iteration step: 123; Loss: 0.391, Accuracy: 89.516%\n","Iteration step: 124; Loss: 0.390, Accuracy: 89.575%\n","Iteration step: 125; Loss: 0.389, Accuracy: 89.633%\n","Iteration step: 126; Loss: 0.389, Accuracy: 89.616%\n","Iteration step: 127; Loss: 0.391, Accuracy: 89.526%\n","Iteration step: 128; Loss: 0.391, Accuracy: 89.535%\n","Iteration step: 129; Loss: 0.392, Accuracy: 89.495%\n","Iteration step: 130; Loss: 0.389, Accuracy: 89.575%\n","Iteration step: 131; Loss: 0.388, Accuracy: 89.631%\n","Iteration step: 132; Loss: 0.388, Accuracy: 89.638%\n","Iteration step: 133; Loss: 0.386, Accuracy: 89.715%\n","Iteration step: 134; Loss: 0.387, Accuracy: 89.722%\n","Iteration step: 135; Loss: 0.388, Accuracy: 89.637%\n","Iteration step: 136; Loss: 0.388, Accuracy: 89.644%\n","Iteration step: 137; Loss: 0.388, Accuracy: 89.629%\n","Iteration step: 138; Loss: 0.387, Accuracy: 89.658%\n","Iteration step: 139; Loss: 0.387, Accuracy: 89.665%\n","Iteration step: 140; Loss: 0.386, Accuracy: 89.716%\n","Iteration step: 141; Loss: 0.385, Accuracy: 89.745%\n","Iteration step: 142; Loss: 0.385, Accuracy: 89.729%\n","Iteration step: 143; Loss: 0.385, Accuracy: 89.714%\n","Iteration step: 144; Loss: 0.384, Accuracy: 89.763%\n","Iteration step: 145; Loss: 0.383, Accuracy: 89.790%\n","Iteration step: 146; Loss: 0.383, Accuracy: 89.796%\n","Iteration step: 147; Loss: 0.382, Accuracy: 89.780%\n","Iteration step: 148; Loss: 0.383, Accuracy: 89.723%\n","Iteration step: 149; Loss: 0.383, Accuracy: 89.729%\n","Iteration step: 150; Loss: 0.381, Accuracy: 89.756%\n","Iteration step: 151; Loss: 0.381, Accuracy: 89.782%\n","Iteration step: 152; Loss: 0.380, Accuracy: 89.828%\n","Iteration step: 153; Loss: 0.380, Accuracy: 89.834%\n","Iteration step: 154; Loss: 0.380, Accuracy: 89.839%\n","Iteration step: 155; Loss: 0.379, Accuracy: 89.864%\n","Iteration step: 156; Loss: 0.377, Accuracy: 89.908%\n","Iteration step: 157; Loss: 0.378, Accuracy: 89.893%\n","Iteration step: 158; Loss: 0.377, Accuracy: 89.937%\n","Iteration step: 159; Loss: 0.377, Accuracy: 89.941%\n","Iteration step: 160; Loss: 0.376, Accuracy: 89.965%\n","Iteration step: 161; Loss: 0.375, Accuracy: 90.027%\n","Iteration step: 162; Loss: 0.375, Accuracy: 90.050%\n","Iteration step: 163; Loss: 0.375, Accuracy: 90.053%\n","Iteration step: 164; Loss: 0.375, Accuracy: 90.057%\n","Iteration step: 165; Loss: 0.373, Accuracy: 90.074%\n","Epoch: 3; Validation loss 0.31843051314353943; acc: 0.9135942459106445\n","Current epoch: 4\n","Iteration step: 0; Loss: 0.163, Accuracy: 96.875%\n","Iteration step: 1; Loss: 0.252, Accuracy: 93.750%\n","Iteration step: 2; Loss: 0.207, Accuracy: 94.792%\n","Iteration step: 3; Loss: 0.205, Accuracy: 94.531%\n","Iteration step: 4; Loss: 0.225, Accuracy: 94.375%\n","Iteration step: 5; Loss: 0.230, Accuracy: 93.750%\n","Iteration step: 6; Loss: 0.242, Accuracy: 93.304%\n","Iteration step: 7; Loss: 0.248, Accuracy: 92.578%\n","Iteration step: 8; Loss: 0.251, Accuracy: 92.708%\n","Iteration step: 9; Loss: 0.265, Accuracy: 92.500%\n","Iteration step: 10; Loss: 0.260, Accuracy: 92.330%\n","Iteration step: 11; Loss: 0.263, Accuracy: 92.708%\n","Iteration step: 12; Loss: 0.263, Accuracy: 92.788%\n","Iteration step: 13; Loss: 0.262, Accuracy: 92.634%\n","Iteration step: 14; Loss: 0.268, Accuracy: 92.708%\n","Iteration step: 15; Loss: 0.274, Accuracy: 92.578%\n","Iteration step: 16; Loss: 0.287, Accuracy: 92.096%\n","Iteration step: 17; Loss: 0.281, Accuracy: 92.188%\n","Iteration step: 18; Loss: 0.284, Accuracy: 92.105%\n","Iteration step: 19; Loss: 0.294, Accuracy: 91.719%\n","Iteration step: 20; Loss: 0.294, Accuracy: 91.964%\n","Iteration step: 21; Loss: 0.285, Accuracy: 92.188%\n","Iteration step: 22; Loss: 0.280, Accuracy: 92.391%\n","Iteration step: 23; Loss: 0.279, Accuracy: 92.318%\n","Iteration step: 24; Loss: 0.282, Accuracy: 92.125%\n","Iteration step: 25; Loss: 0.278, Accuracy: 92.188%\n","Iteration step: 26; Loss: 0.276, Accuracy: 92.361%\n","Iteration step: 27; Loss: 0.272, Accuracy: 92.411%\n","Iteration step: 28; Loss: 0.278, Accuracy: 92.349%\n","Iteration step: 29; Loss: 0.278, Accuracy: 92.396%\n","Iteration step: 30; Loss: 0.277, Accuracy: 92.339%\n","Iteration step: 31; Loss: 0.277, Accuracy: 92.383%\n","Iteration step: 32; Loss: 0.280, Accuracy: 92.235%\n","Iteration step: 33; Loss: 0.280, Accuracy: 92.279%\n","Iteration step: 34; Loss: 0.280, Accuracy: 92.143%\n","Iteration step: 35; Loss: 0.283, Accuracy: 92.188%\n","Iteration step: 36; Loss: 0.283, Accuracy: 92.061%\n","Iteration step: 37; Loss: 0.283, Accuracy: 92.188%\n","Iteration step: 38; Loss: 0.284, Accuracy: 92.067%\n","Iteration step: 39; Loss: 0.287, Accuracy: 91.875%\n","Iteration step: 40; Loss: 0.286, Accuracy: 91.921%\n","Iteration step: 41; Loss: 0.283, Accuracy: 92.039%\n","Iteration step: 42; Loss: 0.281, Accuracy: 92.151%\n","Iteration step: 43; Loss: 0.282, Accuracy: 92.045%\n","Iteration step: 44; Loss: 0.282, Accuracy: 92.153%\n","Iteration step: 45; Loss: 0.285, Accuracy: 92.052%\n","Iteration step: 46; Loss: 0.289, Accuracy: 91.822%\n","Iteration step: 47; Loss: 0.287, Accuracy: 91.797%\n","Iteration step: 48; Loss: 0.289, Accuracy: 91.773%\n","Iteration step: 49; Loss: 0.295, Accuracy: 91.562%\n","Iteration step: 50; Loss: 0.296, Accuracy: 91.483%\n","Iteration step: 51; Loss: 0.299, Accuracy: 91.346%\n","Iteration step: 52; Loss: 0.302, Accuracy: 91.333%\n","Iteration step: 53; Loss: 0.301, Accuracy: 91.377%\n","Iteration step: 54; Loss: 0.301, Accuracy: 91.364%\n","Iteration step: 55; Loss: 0.305, Accuracy: 91.295%\n","Iteration step: 56; Loss: 0.303, Accuracy: 91.393%\n","Iteration step: 57; Loss: 0.304, Accuracy: 91.379%\n","Iteration step: 58; Loss: 0.305, Accuracy: 91.367%\n","Iteration step: 59; Loss: 0.304, Accuracy: 91.406%\n","Iteration step: 60; Loss: 0.304, Accuracy: 91.445%\n","Iteration step: 61; Loss: 0.303, Accuracy: 91.532%\n","Iteration step: 62; Loss: 0.306, Accuracy: 91.518%\n","Iteration step: 63; Loss: 0.305, Accuracy: 91.553%\n","Iteration step: 64; Loss: 0.304, Accuracy: 91.635%\n","Iteration step: 65; Loss: 0.303, Accuracy: 91.714%\n","Iteration step: 66; Loss: 0.306, Accuracy: 91.604%\n","Iteration step: 67; Loss: 0.306, Accuracy: 91.682%\n","Iteration step: 68; Loss: 0.306, Accuracy: 91.712%\n","Iteration step: 69; Loss: 0.306, Accuracy: 91.741%\n","Iteration step: 70; Loss: 0.304, Accuracy: 91.769%\n","Iteration step: 71; Loss: 0.304, Accuracy: 91.797%\n","Iteration step: 72; Loss: 0.303, Accuracy: 91.824%\n","Iteration step: 73; Loss: 0.304, Accuracy: 91.807%\n","Iteration step: 74; Loss: 0.303, Accuracy: 91.833%\n","Iteration step: 75; Loss: 0.302, Accuracy: 91.900%\n","Iteration step: 76; Loss: 0.301, Accuracy: 91.964%\n","Iteration step: 77; Loss: 0.300, Accuracy: 91.987%\n","Iteration step: 78; Loss: 0.299, Accuracy: 91.930%\n","Iteration step: 79; Loss: 0.299, Accuracy: 91.992%\n","Iteration step: 80; Loss: 0.298, Accuracy: 92.052%\n","Iteration step: 81; Loss: 0.298, Accuracy: 92.073%\n","Iteration step: 82; Loss: 0.298, Accuracy: 92.131%\n","Iteration step: 83; Loss: 0.299, Accuracy: 92.113%\n","Iteration step: 84; Loss: 0.299, Accuracy: 92.022%\n","Iteration step: 85; Loss: 0.302, Accuracy: 91.897%\n","Iteration step: 86; Loss: 0.305, Accuracy: 91.810%\n","Iteration step: 87; Loss: 0.305, Accuracy: 91.868%\n","Iteration step: 88; Loss: 0.303, Accuracy: 91.959%\n","Iteration step: 89; Loss: 0.303, Accuracy: 91.979%\n","Iteration step: 90; Loss: 0.302, Accuracy: 92.033%\n","Iteration step: 91; Loss: 0.303, Accuracy: 92.018%\n","Iteration step: 92; Loss: 0.303, Accuracy: 92.036%\n","Iteration step: 93; Loss: 0.302, Accuracy: 92.055%\n","Iteration step: 94; Loss: 0.303, Accuracy: 92.007%\n","Iteration step: 95; Loss: 0.304, Accuracy: 91.927%\n","Iteration step: 96; Loss: 0.304, Accuracy: 91.914%\n","Iteration step: 97; Loss: 0.303, Accuracy: 91.964%\n","Iteration step: 98; Loss: 0.303, Accuracy: 91.919%\n","Iteration step: 99; Loss: 0.304, Accuracy: 91.906%\n","Iteration step: 100; Loss: 0.307, Accuracy: 91.770%\n","Iteration step: 101; Loss: 0.307, Accuracy: 91.759%\n","Iteration step: 102; Loss: 0.308, Accuracy: 91.717%\n","Iteration step: 103; Loss: 0.308, Accuracy: 91.677%\n","Iteration step: 104; Loss: 0.308, Accuracy: 91.696%\n","Iteration step: 105; Loss: 0.307, Accuracy: 91.657%\n","Iteration step: 106; Loss: 0.307, Accuracy: 91.676%\n","Iteration step: 107; Loss: 0.309, Accuracy: 91.609%\n","Iteration step: 108; Loss: 0.309, Accuracy: 91.628%\n","Iteration step: 109; Loss: 0.309, Accuracy: 91.676%\n","Iteration step: 110; Loss: 0.310, Accuracy: 91.695%\n","Iteration step: 111; Loss: 0.309, Accuracy: 91.741%\n","Iteration step: 112; Loss: 0.309, Accuracy: 91.704%\n","Iteration step: 113; Loss: 0.308, Accuracy: 91.749%\n","Iteration step: 114; Loss: 0.308, Accuracy: 91.739%\n","Iteration step: 115; Loss: 0.308, Accuracy: 91.730%\n","Iteration step: 116; Loss: 0.307, Accuracy: 91.774%\n","Iteration step: 117; Loss: 0.307, Accuracy: 91.764%\n","Iteration step: 118; Loss: 0.307, Accuracy: 91.754%\n","Iteration step: 119; Loss: 0.307, Accuracy: 91.771%\n","Iteration step: 120; Loss: 0.306, Accuracy: 91.787%\n","Iteration step: 121; Loss: 0.305, Accuracy: 91.829%\n","Iteration step: 122; Loss: 0.304, Accuracy: 91.819%\n","Iteration step: 123; Loss: 0.305, Accuracy: 91.784%\n","Iteration step: 124; Loss: 0.305, Accuracy: 91.750%\n","Iteration step: 125; Loss: 0.305, Accuracy: 91.766%\n","Iteration step: 126; Loss: 0.306, Accuracy: 91.757%\n","Iteration step: 127; Loss: 0.304, Accuracy: 91.821%\n","Iteration step: 128; Loss: 0.304, Accuracy: 91.836%\n","Iteration step: 129; Loss: 0.304, Accuracy: 91.851%\n","Iteration step: 130; Loss: 0.302, Accuracy: 91.913%\n","Iteration step: 131; Loss: 0.302, Accuracy: 91.903%\n","Iteration step: 132; Loss: 0.302, Accuracy: 91.870%\n","Iteration step: 133; Loss: 0.301, Accuracy: 91.908%\n","Iteration step: 134; Loss: 0.301, Accuracy: 91.898%\n","Iteration step: 135; Loss: 0.300, Accuracy: 91.935%\n","Iteration step: 136; Loss: 0.300, Accuracy: 91.948%\n","Iteration step: 137; Loss: 0.299, Accuracy: 91.961%\n","Iteration step: 138; Loss: 0.298, Accuracy: 91.996%\n","Iteration step: 139; Loss: 0.298, Accuracy: 92.009%\n","Iteration step: 140; Loss: 0.299, Accuracy: 91.955%\n","Iteration step: 141; Loss: 0.298, Accuracy: 91.945%\n","Iteration step: 142; Loss: 0.299, Accuracy: 91.892%\n","Iteration step: 143; Loss: 0.298, Accuracy: 91.949%\n","Iteration step: 144; Loss: 0.298, Accuracy: 91.940%\n","Iteration step: 145; Loss: 0.298, Accuracy: 91.952%\n","Iteration step: 146; Loss: 0.299, Accuracy: 91.901%\n","Iteration step: 147; Loss: 0.299, Accuracy: 91.871%\n","Iteration step: 148; Loss: 0.298, Accuracy: 91.904%\n","Iteration step: 149; Loss: 0.298, Accuracy: 91.875%\n","Iteration step: 150; Loss: 0.298, Accuracy: 91.908%\n","Iteration step: 151; Loss: 0.298, Accuracy: 91.879%\n","Iteration step: 152; Loss: 0.298, Accuracy: 91.891%\n","Iteration step: 153; Loss: 0.298, Accuracy: 91.863%\n","Iteration step: 154; Loss: 0.298, Accuracy: 91.855%\n","Iteration step: 155; Loss: 0.298, Accuracy: 91.867%\n","Iteration step: 156; Loss: 0.297, Accuracy: 91.859%\n","Iteration step: 157; Loss: 0.297, Accuracy: 91.871%\n","Iteration step: 158; Loss: 0.296, Accuracy: 91.883%\n","Iteration step: 159; Loss: 0.296, Accuracy: 91.875%\n","Iteration step: 160; Loss: 0.298, Accuracy: 91.770%\n","Iteration step: 161; Loss: 0.297, Accuracy: 91.802%\n","Iteration step: 162; Loss: 0.297, Accuracy: 91.775%\n","Iteration step: 163; Loss: 0.296, Accuracy: 91.806%\n","Iteration step: 164; Loss: 0.297, Accuracy: 91.780%\n","Iteration step: 165; Loss: 0.297, Accuracy: 91.794%\n","Epoch: 4; Validation loss 0.26154881715774536; acc: 0.9311779141426086\n","Current epoch: 5\n","Iteration step: 0; Loss: 0.325, Accuracy: 93.750%\n","Iteration step: 1; Loss: 0.348, Accuracy: 92.188%\n","Iteration step: 2; Loss: 0.284, Accuracy: 93.750%\n","Iteration step: 3; Loss: 0.320, Accuracy: 91.406%\n","Iteration step: 4; Loss: 0.291, Accuracy: 93.125%\n","Iteration step: 5; Loss: 0.259, Accuracy: 94.271%\n","Iteration step: 6; Loss: 0.249, Accuracy: 94.196%\n","Iteration step: 7; Loss: 0.273, Accuracy: 93.750%\n","Iteration step: 8; Loss: 0.279, Accuracy: 93.403%\n","Iteration step: 9; Loss: 0.289, Accuracy: 93.125%\n","Iteration step: 10; Loss: 0.292, Accuracy: 92.614%\n","Iteration step: 11; Loss: 0.292, Accuracy: 92.708%\n","Iteration step: 12; Loss: 0.287, Accuracy: 92.788%\n","Iteration step: 13; Loss: 0.278, Accuracy: 93.304%\n","Iteration step: 14; Loss: 0.278, Accuracy: 93.333%\n","Iteration step: 15; Loss: 0.278, Accuracy: 93.164%\n","Iteration step: 16; Loss: 0.282, Accuracy: 93.015%\n","Iteration step: 17; Loss: 0.288, Accuracy: 92.535%\n","Iteration step: 18; Loss: 0.280, Accuracy: 92.763%\n","Iteration step: 19; Loss: 0.287, Accuracy: 92.500%\n","Iteration step: 20; Loss: 0.288, Accuracy: 92.411%\n","Iteration step: 21; Loss: 0.293, Accuracy: 92.188%\n","Iteration step: 22; Loss: 0.293, Accuracy: 91.848%\n","Iteration step: 23; Loss: 0.291, Accuracy: 91.927%\n","Iteration step: 24; Loss: 0.287, Accuracy: 92.125%\n","Iteration step: 25; Loss: 0.284, Accuracy: 92.188%\n","Iteration step: 26; Loss: 0.287, Accuracy: 91.898%\n","Iteration step: 27; Loss: 0.286, Accuracy: 91.853%\n","Iteration step: 28; Loss: 0.287, Accuracy: 91.595%\n","Iteration step: 29; Loss: 0.286, Accuracy: 91.667%\n","Iteration step: 30; Loss: 0.284, Accuracy: 91.734%\n","Iteration step: 31; Loss: 0.294, Accuracy: 91.406%\n","Iteration step: 32; Loss: 0.290, Accuracy: 91.572%\n","Iteration step: 33; Loss: 0.290, Accuracy: 91.452%\n","Iteration step: 34; Loss: 0.285, Accuracy: 91.696%\n","Iteration step: 35; Loss: 0.288, Accuracy: 91.667%\n","Iteration step: 36; Loss: 0.285, Accuracy: 91.723%\n","Iteration step: 37; Loss: 0.283, Accuracy: 91.776%\n","Iteration step: 38; Loss: 0.283, Accuracy: 91.827%\n","Iteration step: 39; Loss: 0.286, Accuracy: 91.719%\n","Iteration step: 40; Loss: 0.285, Accuracy: 91.692%\n","Iteration step: 41; Loss: 0.283, Accuracy: 91.667%\n","Iteration step: 42; Loss: 0.280, Accuracy: 91.860%\n","Iteration step: 43; Loss: 0.284, Accuracy: 91.690%\n","Iteration step: 44; Loss: 0.281, Accuracy: 91.736%\n","Iteration step: 45; Loss: 0.282, Accuracy: 91.780%\n","Iteration step: 46; Loss: 0.283, Accuracy: 91.689%\n","Iteration step: 47; Loss: 0.284, Accuracy: 91.667%\n","Iteration step: 48; Loss: 0.284, Accuracy: 91.709%\n","Iteration step: 49; Loss: 0.282, Accuracy: 91.750%\n","Iteration step: 50; Loss: 0.284, Accuracy: 91.605%\n","Iteration step: 51; Loss: 0.283, Accuracy: 91.647%\n","Iteration step: 52; Loss: 0.284, Accuracy: 91.686%\n","Iteration step: 53; Loss: 0.283, Accuracy: 91.667%\n","Iteration step: 54; Loss: 0.283, Accuracy: 91.591%\n","Iteration step: 55; Loss: 0.288, Accuracy: 91.406%\n","Iteration step: 56; Loss: 0.291, Accuracy: 91.393%\n","Iteration step: 57; Loss: 0.289, Accuracy: 91.433%\n","Iteration step: 58; Loss: 0.287, Accuracy: 91.525%\n","Iteration step: 59; Loss: 0.285, Accuracy: 91.562%\n","Iteration step: 60; Loss: 0.283, Accuracy: 91.598%\n","Iteration step: 61; Loss: 0.281, Accuracy: 91.683%\n","Iteration step: 62; Loss: 0.278, Accuracy: 91.766%\n","Iteration step: 63; Loss: 0.282, Accuracy: 91.602%\n","Iteration step: 64; Loss: 0.281, Accuracy: 91.635%\n","Iteration step: 65; Loss: 0.278, Accuracy: 91.761%\n","Iteration step: 66; Loss: 0.278, Accuracy: 91.744%\n","Iteration step: 67; Loss: 0.277, Accuracy: 91.774%\n","Iteration step: 68; Loss: 0.276, Accuracy: 91.803%\n","Iteration step: 69; Loss: 0.274, Accuracy: 91.875%\n","Iteration step: 70; Loss: 0.275, Accuracy: 91.901%\n","Iteration step: 71; Loss: 0.275, Accuracy: 91.927%\n","Iteration step: 72; Loss: 0.275, Accuracy: 91.909%\n","Iteration step: 73; Loss: 0.272, Accuracy: 92.019%\n","Iteration step: 74; Loss: 0.274, Accuracy: 91.958%\n","Iteration step: 75; Loss: 0.276, Accuracy: 91.859%\n","Iteration step: 76; Loss: 0.273, Accuracy: 91.964%\n","Iteration step: 77; Loss: 0.274, Accuracy: 91.907%\n","Iteration step: 78; Loss: 0.273, Accuracy: 92.009%\n","Iteration step: 79; Loss: 0.272, Accuracy: 92.070%\n","Iteration step: 80; Loss: 0.270, Accuracy: 92.130%\n","Iteration step: 81; Loss: 0.269, Accuracy: 92.188%\n","Iteration step: 82; Loss: 0.268, Accuracy: 92.206%\n","Iteration step: 83; Loss: 0.267, Accuracy: 92.262%\n","Iteration step: 84; Loss: 0.267, Accuracy: 92.243%\n","Iteration step: 85; Loss: 0.268, Accuracy: 92.260%\n","Iteration step: 86; Loss: 0.267, Accuracy: 92.277%\n","Iteration step: 87; Loss: 0.268, Accuracy: 92.223%\n","Iteration step: 88; Loss: 0.268, Accuracy: 92.205%\n","Iteration step: 89; Loss: 0.266, Accuracy: 92.257%\n","Iteration step: 90; Loss: 0.265, Accuracy: 92.308%\n","Iteration step: 91; Loss: 0.264, Accuracy: 92.323%\n","Iteration step: 92; Loss: 0.264, Accuracy: 92.339%\n","Iteration step: 93; Loss: 0.264, Accuracy: 92.354%\n","Iteration step: 94; Loss: 0.262, Accuracy: 92.401%\n","Iteration step: 95; Loss: 0.263, Accuracy: 92.383%\n","Iteration step: 96; Loss: 0.264, Accuracy: 92.332%\n","Iteration step: 97; Loss: 0.264, Accuracy: 92.283%\n","Iteration step: 98; Loss: 0.263, Accuracy: 92.298%\n","Iteration step: 99; Loss: 0.262, Accuracy: 92.344%\n","Iteration step: 100; Loss: 0.262, Accuracy: 92.358%\n","Iteration step: 101; Loss: 0.261, Accuracy: 92.371%\n","Iteration step: 102; Loss: 0.260, Accuracy: 92.415%\n","Iteration step: 103; Loss: 0.259, Accuracy: 92.488%\n","Iteration step: 104; Loss: 0.259, Accuracy: 92.440%\n","Iteration step: 105; Loss: 0.260, Accuracy: 92.423%\n","Iteration step: 106; Loss: 0.259, Accuracy: 92.494%\n","Iteration step: 107; Loss: 0.258, Accuracy: 92.535%\n","Iteration step: 108; Loss: 0.257, Accuracy: 92.575%\n","Iteration step: 109; Loss: 0.257, Accuracy: 92.614%\n","Iteration step: 110; Loss: 0.256, Accuracy: 92.624%\n","Iteration step: 111; Loss: 0.256, Accuracy: 92.662%\n","Iteration step: 112; Loss: 0.256, Accuracy: 92.671%\n","Iteration step: 113; Loss: 0.256, Accuracy: 92.654%\n","Iteration step: 114; Loss: 0.255, Accuracy: 92.690%\n","Iteration step: 115; Loss: 0.255, Accuracy: 92.672%\n","Iteration step: 116; Loss: 0.254, Accuracy: 92.708%\n","Iteration step: 117; Loss: 0.253, Accuracy: 92.744%\n","Iteration step: 118; Loss: 0.253, Accuracy: 92.752%\n","Iteration step: 119; Loss: 0.252, Accuracy: 92.786%\n","Iteration step: 120; Loss: 0.252, Accuracy: 92.743%\n","Iteration step: 121; Loss: 0.252, Accuracy: 92.751%\n","Iteration step: 122; Loss: 0.252, Accuracy: 92.785%\n","Iteration step: 123; Loss: 0.251, Accuracy: 92.792%\n","Iteration step: 124; Loss: 0.251, Accuracy: 92.825%\n","Iteration step: 125; Loss: 0.249, Accuracy: 92.882%\n","Iteration step: 126; Loss: 0.249, Accuracy: 92.864%\n","Iteration step: 127; Loss: 0.248, Accuracy: 92.920%\n","Iteration step: 128; Loss: 0.248, Accuracy: 92.951%\n","Iteration step: 129; Loss: 0.247, Accuracy: 92.981%\n","Iteration step: 130; Loss: 0.248, Accuracy: 92.963%\n","Iteration step: 131; Loss: 0.248, Accuracy: 92.969%\n","Iteration step: 132; Loss: 0.248, Accuracy: 92.975%\n","Iteration step: 133; Loss: 0.248, Accuracy: 93.004%\n","Iteration step: 134; Loss: 0.247, Accuracy: 93.056%\n","Iteration step: 135; Loss: 0.246, Accuracy: 93.084%\n","Iteration step: 136; Loss: 0.247, Accuracy: 93.089%\n","Iteration step: 137; Loss: 0.246, Accuracy: 93.116%\n","Iteration step: 138; Loss: 0.247, Accuracy: 93.098%\n","Iteration step: 139; Loss: 0.248, Accuracy: 93.058%\n","Iteration step: 140; Loss: 0.247, Accuracy: 93.085%\n","Iteration step: 141; Loss: 0.246, Accuracy: 93.090%\n","Iteration step: 142; Loss: 0.245, Accuracy: 93.138%\n","Iteration step: 143; Loss: 0.247, Accuracy: 93.077%\n","Iteration step: 144; Loss: 0.246, Accuracy: 93.125%\n","Iteration step: 145; Loss: 0.246, Accuracy: 93.129%\n","Iteration step: 146; Loss: 0.246, Accuracy: 93.155%\n","Iteration step: 147; Loss: 0.245, Accuracy: 93.180%\n","Iteration step: 148; Loss: 0.245, Accuracy: 93.184%\n","Iteration step: 149; Loss: 0.244, Accuracy: 93.208%\n","Iteration step: 150; Loss: 0.244, Accuracy: 93.233%\n","Iteration step: 151; Loss: 0.244, Accuracy: 93.236%\n","Iteration step: 152; Loss: 0.244, Accuracy: 93.260%\n","Iteration step: 153; Loss: 0.243, Accuracy: 93.283%\n","Iteration step: 154; Loss: 0.242, Accuracy: 93.306%\n","Iteration step: 155; Loss: 0.241, Accuracy: 93.309%\n","Iteration step: 156; Loss: 0.241, Accuracy: 93.292%\n","Iteration step: 157; Loss: 0.242, Accuracy: 93.236%\n","Iteration step: 158; Loss: 0.242, Accuracy: 93.180%\n","Iteration step: 159; Loss: 0.241, Accuracy: 93.203%\n","Iteration step: 160; Loss: 0.240, Accuracy: 93.226%\n","Iteration step: 161; Loss: 0.240, Accuracy: 93.248%\n","Iteration step: 162; Loss: 0.241, Accuracy: 93.252%\n","Iteration step: 163; Loss: 0.241, Accuracy: 93.197%\n","Iteration step: 164; Loss: 0.240, Accuracy: 93.239%\n","Iteration step: 165; Loss: 0.241, Accuracy: 93.212%\n","Epoch: 5; Validation loss 0.21921426057815552; acc: 0.9368500709533691\n","Current epoch: 6\n","Iteration step: 0; Loss: 0.184, Accuracy: 96.875%\n","Iteration step: 1; Loss: 0.210, Accuracy: 96.875%\n","Iteration step: 2; Loss: 0.270, Accuracy: 93.750%\n","Iteration step: 3; Loss: 0.230, Accuracy: 94.531%\n","Iteration step: 4; Loss: 0.252, Accuracy: 93.750%\n","Iteration step: 5; Loss: 0.242, Accuracy: 93.750%\n","Iteration step: 6; Loss: 0.263, Accuracy: 92.411%\n","Iteration step: 7; Loss: 0.278, Accuracy: 91.797%\n","Iteration step: 8; Loss: 0.270, Accuracy: 92.014%\n","Iteration step: 9; Loss: 0.268, Accuracy: 91.562%\n","Iteration step: 10; Loss: 0.258, Accuracy: 92.045%\n","Iteration step: 11; Loss: 0.259, Accuracy: 91.667%\n","Iteration step: 12; Loss: 0.250, Accuracy: 92.067%\n","Iteration step: 13; Loss: 0.243, Accuracy: 92.411%\n","Iteration step: 14; Loss: 0.245, Accuracy: 92.500%\n","Iteration step: 15; Loss: 0.251, Accuracy: 92.383%\n","Iteration step: 16; Loss: 0.250, Accuracy: 92.279%\n","Iteration step: 17; Loss: 0.246, Accuracy: 92.361%\n","Iteration step: 18; Loss: 0.244, Accuracy: 92.434%\n","Iteration step: 19; Loss: 0.250, Accuracy: 92.500%\n","Iteration step: 20; Loss: 0.246, Accuracy: 92.560%\n","Iteration step: 21; Loss: 0.253, Accuracy: 92.330%\n","Iteration step: 22; Loss: 0.251, Accuracy: 92.527%\n","Iteration step: 23; Loss: 0.245, Accuracy: 92.708%\n","Iteration step: 24; Loss: 0.244, Accuracy: 92.625%\n","Iteration step: 25; Loss: 0.247, Accuracy: 92.668%\n","Iteration step: 26; Loss: 0.245, Accuracy: 92.708%\n","Iteration step: 27; Loss: 0.248, Accuracy: 92.522%\n","Iteration step: 28; Loss: 0.249, Accuracy: 92.565%\n","Iteration step: 29; Loss: 0.251, Accuracy: 92.500%\n","Iteration step: 30; Loss: 0.250, Accuracy: 92.540%\n","Iteration step: 31; Loss: 0.253, Accuracy: 92.383%\n","Iteration step: 32; Loss: 0.250, Accuracy: 92.424%\n","Iteration step: 33; Loss: 0.249, Accuracy: 92.463%\n","Iteration step: 34; Loss: 0.249, Accuracy: 92.589%\n","Iteration step: 35; Loss: 0.243, Accuracy: 92.708%\n","Iteration step: 36; Loss: 0.239, Accuracy: 92.905%\n","Iteration step: 37; Loss: 0.237, Accuracy: 93.010%\n","Iteration step: 38; Loss: 0.234, Accuracy: 93.109%\n","Iteration step: 39; Loss: 0.233, Accuracy: 93.125%\n","Iteration step: 40; Loss: 0.231, Accuracy: 93.140%\n","Iteration step: 41; Loss: 0.228, Accuracy: 93.229%\n","Iteration step: 42; Loss: 0.229, Accuracy: 93.241%\n","Iteration step: 43; Loss: 0.231, Accuracy: 93.253%\n","Iteration step: 44; Loss: 0.230, Accuracy: 93.333%\n","Iteration step: 45; Loss: 0.229, Accuracy: 93.410%\n","Iteration step: 46; Loss: 0.233, Accuracy: 93.218%\n","Iteration step: 47; Loss: 0.231, Accuracy: 93.294%\n","Iteration step: 48; Loss: 0.231, Accuracy: 93.240%\n","Iteration step: 49; Loss: 0.233, Accuracy: 93.187%\n","Iteration step: 50; Loss: 0.231, Accuracy: 93.260%\n","Iteration step: 51; Loss: 0.229, Accuracy: 93.389%\n","Iteration step: 52; Loss: 0.231, Accuracy: 93.278%\n","Iteration step: 53; Loss: 0.230, Accuracy: 93.345%\n","Iteration step: 54; Loss: 0.229, Accuracy: 93.409%\n","Iteration step: 55; Loss: 0.230, Accuracy: 93.304%\n","Iteration step: 56; Loss: 0.231, Accuracy: 93.257%\n","Iteration step: 57; Loss: 0.228, Accuracy: 93.373%\n","Iteration step: 58; Loss: 0.228, Accuracy: 93.326%\n","Iteration step: 59; Loss: 0.230, Accuracy: 93.125%\n","Iteration step: 60; Loss: 0.228, Accuracy: 93.186%\n","Iteration step: 61; Loss: 0.226, Accuracy: 93.296%\n","Iteration step: 62; Loss: 0.224, Accuracy: 93.353%\n","Iteration step: 63; Loss: 0.222, Accuracy: 93.457%\n","Iteration step: 64; Loss: 0.224, Accuracy: 93.365%\n","Iteration step: 65; Loss: 0.223, Accuracy: 93.419%\n","Iteration step: 66; Loss: 0.222, Accuracy: 93.517%\n","Iteration step: 67; Loss: 0.222, Accuracy: 93.474%\n","Iteration step: 68; Loss: 0.222, Accuracy: 93.478%\n","Iteration step: 69; Loss: 0.221, Accuracy: 93.527%\n","Iteration step: 70; Loss: 0.221, Accuracy: 93.530%\n","Iteration step: 71; Loss: 0.222, Accuracy: 93.576%\n","Iteration step: 72; Loss: 0.220, Accuracy: 93.664%\n","Iteration step: 73; Loss: 0.219, Accuracy: 93.708%\n","Iteration step: 74; Loss: 0.218, Accuracy: 93.792%\n","Iteration step: 75; Loss: 0.222, Accuracy: 93.709%\n","Iteration step: 76; Loss: 0.223, Accuracy: 93.669%\n","Iteration step: 77; Loss: 0.223, Accuracy: 93.670%\n","Iteration step: 78; Loss: 0.221, Accuracy: 93.750%\n","Iteration step: 79; Loss: 0.221, Accuracy: 93.711%\n","Iteration step: 80; Loss: 0.220, Accuracy: 93.750%\n","Iteration step: 81; Loss: 0.221, Accuracy: 93.750%\n","Iteration step: 82; Loss: 0.220, Accuracy: 93.825%\n","Iteration step: 83; Loss: 0.221, Accuracy: 93.750%\n","Iteration step: 84; Loss: 0.220, Accuracy: 93.787%\n","Iteration step: 85; Loss: 0.219, Accuracy: 93.786%\n","Iteration step: 86; Loss: 0.220, Accuracy: 93.750%\n","Iteration step: 87; Loss: 0.219, Accuracy: 93.786%\n","Iteration step: 88; Loss: 0.220, Accuracy: 93.785%\n","Iteration step: 89; Loss: 0.220, Accuracy: 93.785%\n","Iteration step: 90; Loss: 0.219, Accuracy: 93.819%\n","Iteration step: 91; Loss: 0.219, Accuracy: 93.750%\n","Iteration step: 92; Loss: 0.218, Accuracy: 93.817%\n","Iteration step: 93; Loss: 0.217, Accuracy: 93.883%\n","Iteration step: 94; Loss: 0.215, Accuracy: 93.947%\n","Iteration step: 95; Loss: 0.214, Accuracy: 93.945%\n","Iteration step: 96; Loss: 0.213, Accuracy: 94.008%\n","Iteration step: 97; Loss: 0.213, Accuracy: 94.005%\n","Iteration step: 98; Loss: 0.211, Accuracy: 94.066%\n","Iteration step: 99; Loss: 0.211, Accuracy: 94.094%\n","Iteration step: 100; Loss: 0.211, Accuracy: 94.090%\n","Iteration step: 101; Loss: 0.210, Accuracy: 94.118%\n","Iteration step: 102; Loss: 0.210, Accuracy: 94.144%\n","Iteration step: 103; Loss: 0.210, Accuracy: 94.081%\n","Iteration step: 104; Loss: 0.210, Accuracy: 94.107%\n","Iteration step: 105; Loss: 0.208, Accuracy: 94.163%\n","Iteration step: 106; Loss: 0.208, Accuracy: 94.159%\n","Iteration step: 107; Loss: 0.207, Accuracy: 94.184%\n","Iteration step: 108; Loss: 0.208, Accuracy: 94.180%\n","Iteration step: 109; Loss: 0.207, Accuracy: 94.205%\n","Iteration step: 110; Loss: 0.206, Accuracy: 94.229%\n","Iteration step: 111; Loss: 0.207, Accuracy: 94.196%\n","Iteration step: 112; Loss: 0.207, Accuracy: 94.192%\n","Iteration step: 113; Loss: 0.206, Accuracy: 94.243%\n","Iteration step: 114; Loss: 0.206, Accuracy: 94.239%\n","Iteration step: 115; Loss: 0.207, Accuracy: 94.208%\n","Iteration step: 116; Loss: 0.206, Accuracy: 94.231%\n","Iteration step: 117; Loss: 0.206, Accuracy: 94.253%\n","Iteration step: 118; Loss: 0.207, Accuracy: 94.249%\n","Iteration step: 119; Loss: 0.206, Accuracy: 94.271%\n","Iteration step: 120; Loss: 0.207, Accuracy: 94.267%\n","Iteration step: 121; Loss: 0.208, Accuracy: 94.211%\n","Iteration step: 122; Loss: 0.208, Accuracy: 94.233%\n","Iteration step: 123; Loss: 0.207, Accuracy: 94.279%\n","Iteration step: 124; Loss: 0.206, Accuracy: 94.300%\n","Iteration step: 125; Loss: 0.206, Accuracy: 94.320%\n","Iteration step: 126; Loss: 0.206, Accuracy: 94.316%\n","Iteration step: 127; Loss: 0.206, Accuracy: 94.336%\n","Iteration step: 128; Loss: 0.206, Accuracy: 94.356%\n","Iteration step: 129; Loss: 0.205, Accuracy: 94.375%\n","Iteration step: 130; Loss: 0.205, Accuracy: 94.394%\n","Iteration step: 131; Loss: 0.204, Accuracy: 94.413%\n","Iteration step: 132; Loss: 0.205, Accuracy: 94.361%\n","Iteration step: 133; Loss: 0.205, Accuracy: 94.356%\n","Iteration step: 134; Loss: 0.205, Accuracy: 94.352%\n","Iteration step: 135; Loss: 0.204, Accuracy: 94.370%\n","Iteration step: 136; Loss: 0.204, Accuracy: 94.389%\n","Iteration step: 137; Loss: 0.204, Accuracy: 94.407%\n","Iteration step: 138; Loss: 0.203, Accuracy: 94.447%\n","Iteration step: 139; Loss: 0.203, Accuracy: 94.442%\n","Iteration step: 140; Loss: 0.203, Accuracy: 94.437%\n","Iteration step: 141; Loss: 0.203, Accuracy: 94.410%\n","Iteration step: 142; Loss: 0.204, Accuracy: 94.384%\n","Iteration step: 143; Loss: 0.205, Accuracy: 94.358%\n","Iteration step: 144; Loss: 0.204, Accuracy: 94.353%\n","Iteration step: 145; Loss: 0.206, Accuracy: 94.328%\n","Iteration step: 146; Loss: 0.207, Accuracy: 94.303%\n","Iteration step: 147; Loss: 0.206, Accuracy: 94.320%\n","Iteration step: 148; Loss: 0.206, Accuracy: 94.295%\n","Iteration step: 149; Loss: 0.206, Accuracy: 94.292%\n","Iteration step: 150; Loss: 0.206, Accuracy: 94.329%\n","Iteration step: 151; Loss: 0.205, Accuracy: 94.346%\n","Iteration step: 152; Loss: 0.206, Accuracy: 94.322%\n","Iteration step: 153; Loss: 0.205, Accuracy: 94.359%\n","Iteration step: 154; Loss: 0.204, Accuracy: 94.375%\n","Iteration step: 155; Loss: 0.204, Accuracy: 94.351%\n","Iteration step: 156; Loss: 0.203, Accuracy: 94.367%\n","Iteration step: 157; Loss: 0.204, Accuracy: 94.284%\n","Iteration step: 158; Loss: 0.204, Accuracy: 94.261%\n","Iteration step: 159; Loss: 0.204, Accuracy: 94.258%\n","Iteration step: 160; Loss: 0.203, Accuracy: 94.293%\n","Iteration step: 161; Loss: 0.204, Accuracy: 94.271%\n","Iteration step: 162; Loss: 0.204, Accuracy: 94.248%\n","Iteration step: 163; Loss: 0.204, Accuracy: 94.284%\n","Iteration step: 164; Loss: 0.204, Accuracy: 94.299%\n","Iteration step: 165; Loss: 0.203, Accuracy: 94.309%\n","Epoch: 6; Validation loss 0.18382972478866577; acc: 0.9531102180480957\n","Current epoch: 7\n","Iteration step: 0; Loss: 0.146, Accuracy: 96.875%\n","Iteration step: 1; Loss: 0.119, Accuracy: 98.438%\n","Iteration step: 2; Loss: 0.122, Accuracy: 98.958%\n","Iteration step: 3; Loss: 0.146, Accuracy: 98.438%\n","Iteration step: 4; Loss: 0.181, Accuracy: 97.500%\n","Iteration step: 5; Loss: 0.176, Accuracy: 97.396%\n","Iteration step: 6; Loss: 0.164, Accuracy: 97.768%\n","Iteration step: 7; Loss: 0.157, Accuracy: 98.047%\n","Iteration step: 8; Loss: 0.149, Accuracy: 98.264%\n","Iteration step: 9; Loss: 0.147, Accuracy: 98.125%\n","Iteration step: 10; Loss: 0.146, Accuracy: 97.727%\n","Iteration step: 11; Loss: 0.165, Accuracy: 96.615%\n","Iteration step: 12; Loss: 0.160, Accuracy: 96.875%\n","Iteration step: 13; Loss: 0.161, Accuracy: 96.652%\n","Iteration step: 14; Loss: 0.157, Accuracy: 96.667%\n","Iteration step: 15; Loss: 0.177, Accuracy: 96.094%\n","Iteration step: 16; Loss: 0.185, Accuracy: 95.588%\n","Iteration step: 17; Loss: 0.180, Accuracy: 95.660%\n","Iteration step: 18; Loss: 0.178, Accuracy: 95.724%\n","Iteration step: 19; Loss: 0.184, Accuracy: 95.469%\n","Iteration step: 20; Loss: 0.185, Accuracy: 95.387%\n","Iteration step: 21; Loss: 0.190, Accuracy: 95.028%\n","Iteration step: 22; Loss: 0.193, Accuracy: 94.837%\n","Iteration step: 23; Loss: 0.191, Accuracy: 94.792%\n","Iteration step: 24; Loss: 0.194, Accuracy: 94.750%\n","Iteration step: 25; Loss: 0.194, Accuracy: 94.712%\n","Iteration step: 26; Loss: 0.192, Accuracy: 94.792%\n","Iteration step: 27; Loss: 0.190, Accuracy: 94.866%\n","Iteration step: 28; Loss: 0.190, Accuracy: 94.828%\n","Iteration step: 29; Loss: 0.186, Accuracy: 95.000%\n","Iteration step: 30; Loss: 0.190, Accuracy: 94.859%\n","Iteration step: 31; Loss: 0.186, Accuracy: 95.020%\n","Iteration step: 32; Loss: 0.183, Accuracy: 95.170%\n","Iteration step: 33; Loss: 0.183, Accuracy: 95.037%\n","Iteration step: 34; Loss: 0.188, Accuracy: 94.732%\n","Iteration step: 35; Loss: 0.188, Accuracy: 94.792%\n","Iteration step: 36; Loss: 0.187, Accuracy: 94.764%\n","Iteration step: 37; Loss: 0.189, Accuracy: 94.737%\n","Iteration step: 38; Loss: 0.188, Accuracy: 94.712%\n","Iteration step: 39; Loss: 0.189, Accuracy: 94.766%\n","Iteration step: 40; Loss: 0.189, Accuracy: 94.665%\n","Iteration step: 41; Loss: 0.189, Accuracy: 94.568%\n","Iteration step: 42; Loss: 0.188, Accuracy: 94.622%\n","Iteration step: 43; Loss: 0.186, Accuracy: 94.673%\n","Iteration step: 44; Loss: 0.185, Accuracy: 94.653%\n","Iteration step: 45; Loss: 0.185, Accuracy: 94.633%\n","Iteration step: 46; Loss: 0.186, Accuracy: 94.681%\n","Iteration step: 47; Loss: 0.184, Accuracy: 94.792%\n","Iteration step: 48; Loss: 0.184, Accuracy: 94.834%\n","Iteration step: 49; Loss: 0.183, Accuracy: 94.813%\n","Iteration step: 50; Loss: 0.183, Accuracy: 94.792%\n","Iteration step: 51; Loss: 0.180, Accuracy: 94.892%\n","Iteration step: 52; Loss: 0.180, Accuracy: 94.929%\n","Iteration step: 53; Loss: 0.180, Accuracy: 94.965%\n","Iteration step: 54; Loss: 0.180, Accuracy: 95.000%\n","Iteration step: 55; Loss: 0.182, Accuracy: 94.866%\n","Iteration step: 56; Loss: 0.181, Accuracy: 94.901%\n","Iteration step: 57; Loss: 0.179, Accuracy: 94.989%\n","Iteration step: 58; Loss: 0.179, Accuracy: 94.968%\n","Iteration step: 59; Loss: 0.178, Accuracy: 95.000%\n","Iteration step: 60; Loss: 0.177, Accuracy: 95.031%\n","Iteration step: 61; Loss: 0.177, Accuracy: 95.060%\n","Iteration step: 62; Loss: 0.176, Accuracy: 95.139%\n","Iteration step: 63; Loss: 0.176, Accuracy: 95.117%\n","Iteration step: 64; Loss: 0.174, Accuracy: 95.192%\n","Iteration step: 65; Loss: 0.175, Accuracy: 95.076%\n","Iteration step: 66; Loss: 0.176, Accuracy: 95.056%\n","Iteration step: 67; Loss: 0.175, Accuracy: 95.129%\n","Iteration step: 68; Loss: 0.175, Accuracy: 95.109%\n","Iteration step: 69; Loss: 0.175, Accuracy: 95.089%\n","Iteration step: 70; Loss: 0.178, Accuracy: 95.026%\n","Iteration step: 71; Loss: 0.177, Accuracy: 95.009%\n","Iteration step: 72; Loss: 0.177, Accuracy: 94.991%\n","Iteration step: 73; Loss: 0.176, Accuracy: 95.059%\n","Iteration step: 74; Loss: 0.176, Accuracy: 95.042%\n","Iteration step: 75; Loss: 0.175, Accuracy: 95.107%\n","Iteration step: 76; Loss: 0.175, Accuracy: 95.170%\n","Iteration step: 77; Loss: 0.175, Accuracy: 95.112%\n","Iteration step: 78; Loss: 0.175, Accuracy: 95.055%\n","Iteration step: 79; Loss: 0.175, Accuracy: 95.039%\n","Iteration step: 80; Loss: 0.175, Accuracy: 95.023%\n","Iteration step: 81; Loss: 0.174, Accuracy: 95.084%\n","Iteration step: 82; Loss: 0.174, Accuracy: 95.105%\n","Iteration step: 83; Loss: 0.175, Accuracy: 95.052%\n","Iteration step: 84; Loss: 0.176, Accuracy: 95.074%\n","Iteration step: 85; Loss: 0.175, Accuracy: 95.094%\n","Iteration step: 86; Loss: 0.175, Accuracy: 95.151%\n","Iteration step: 87; Loss: 0.177, Accuracy: 94.957%\n","Iteration step: 88; Loss: 0.176, Accuracy: 95.014%\n","Iteration step: 89; Loss: 0.177, Accuracy: 95.000%\n","Iteration step: 90; Loss: 0.179, Accuracy: 94.918%\n","Iteration step: 91; Loss: 0.178, Accuracy: 94.973%\n","Iteration step: 92; Loss: 0.178, Accuracy: 94.960%\n","Iteration step: 93; Loss: 0.178, Accuracy: 94.980%\n","Iteration step: 94; Loss: 0.177, Accuracy: 95.000%\n","Iteration step: 95; Loss: 0.177, Accuracy: 95.020%\n","Iteration step: 96; Loss: 0.176, Accuracy: 95.071%\n","Iteration step: 97; Loss: 0.176, Accuracy: 95.026%\n","Iteration step: 98; Loss: 0.176, Accuracy: 95.044%\n","Iteration step: 99; Loss: 0.179, Accuracy: 94.937%\n","Iteration step: 100; Loss: 0.180, Accuracy: 94.926%\n","Iteration step: 101; Loss: 0.179, Accuracy: 94.945%\n","Iteration step: 102; Loss: 0.179, Accuracy: 94.964%\n","Iteration step: 103; Loss: 0.178, Accuracy: 94.982%\n","Iteration step: 104; Loss: 0.178, Accuracy: 94.970%\n","Iteration step: 105; Loss: 0.178, Accuracy: 94.988%\n","Iteration step: 106; Loss: 0.178, Accuracy: 95.006%\n","Iteration step: 107; Loss: 0.178, Accuracy: 94.994%\n","Iteration step: 108; Loss: 0.177, Accuracy: 95.011%\n","Iteration step: 109; Loss: 0.177, Accuracy: 95.028%\n","Iteration step: 110; Loss: 0.178, Accuracy: 95.045%\n","Iteration step: 111; Loss: 0.177, Accuracy: 95.089%\n","Iteration step: 112; Loss: 0.177, Accuracy: 95.077%\n","Iteration step: 113; Loss: 0.177, Accuracy: 95.093%\n","Iteration step: 114; Loss: 0.178, Accuracy: 95.000%\n","Iteration step: 115; Loss: 0.177, Accuracy: 95.043%\n","Iteration step: 116; Loss: 0.177, Accuracy: 95.032%\n","Iteration step: 117; Loss: 0.177, Accuracy: 95.048%\n","Iteration step: 118; Loss: 0.176, Accuracy: 95.037%\n","Iteration step: 119; Loss: 0.177, Accuracy: 95.000%\n","Iteration step: 120; Loss: 0.177, Accuracy: 95.015%\n","Iteration step: 121; Loss: 0.177, Accuracy: 95.005%\n","Iteration step: 122; Loss: 0.177, Accuracy: 95.020%\n","Iteration step: 123; Loss: 0.176, Accuracy: 95.060%\n","Iteration step: 124; Loss: 0.175, Accuracy: 95.100%\n","Iteration step: 125; Loss: 0.175, Accuracy: 95.089%\n","Iteration step: 126; Loss: 0.176, Accuracy: 95.054%\n","Iteration step: 127; Loss: 0.175, Accuracy: 95.093%\n","Iteration step: 128; Loss: 0.175, Accuracy: 95.058%\n","Iteration step: 129; Loss: 0.175, Accuracy: 95.072%\n","Iteration step: 130; Loss: 0.174, Accuracy: 95.086%\n","Iteration step: 131; Loss: 0.176, Accuracy: 95.052%\n","Iteration step: 132; Loss: 0.175, Accuracy: 95.042%\n","Iteration step: 133; Loss: 0.175, Accuracy: 95.056%\n","Iteration step: 134; Loss: 0.175, Accuracy: 95.093%\n","Iteration step: 135; Loss: 0.175, Accuracy: 95.083%\n","Iteration step: 136; Loss: 0.175, Accuracy: 95.073%\n","Iteration step: 137; Loss: 0.175, Accuracy: 95.086%\n","Iteration step: 138; Loss: 0.175, Accuracy: 95.076%\n","Iteration step: 139; Loss: 0.175, Accuracy: 95.112%\n","Iteration step: 140; Loss: 0.174, Accuracy: 95.124%\n","Iteration step: 141; Loss: 0.174, Accuracy: 95.114%\n","Iteration step: 142; Loss: 0.175, Accuracy: 95.105%\n","Iteration step: 143; Loss: 0.174, Accuracy: 95.139%\n","Iteration step: 144; Loss: 0.173, Accuracy: 95.172%\n","Iteration step: 145; Loss: 0.174, Accuracy: 95.163%\n","Iteration step: 146; Loss: 0.173, Accuracy: 95.174%\n","Iteration step: 147; Loss: 0.174, Accuracy: 95.165%\n","Iteration step: 148; Loss: 0.174, Accuracy: 95.155%\n","Iteration step: 149; Loss: 0.174, Accuracy: 95.187%\n","Iteration step: 150; Loss: 0.173, Accuracy: 95.219%\n","Iteration step: 151; Loss: 0.173, Accuracy: 95.210%\n","Iteration step: 152; Loss: 0.174, Accuracy: 95.221%\n","Iteration step: 153; Loss: 0.173, Accuracy: 95.231%\n","Iteration step: 154; Loss: 0.174, Accuracy: 95.202%\n","Iteration step: 155; Loss: 0.174, Accuracy: 95.192%\n","Iteration step: 156; Loss: 0.173, Accuracy: 95.223%\n","Iteration step: 157; Loss: 0.174, Accuracy: 95.214%\n","Iteration step: 158; Loss: 0.173, Accuracy: 95.244%\n","Iteration step: 159; Loss: 0.173, Accuracy: 95.254%\n","Iteration step: 160; Loss: 0.172, Accuracy: 95.264%\n","Iteration step: 161; Loss: 0.174, Accuracy: 95.216%\n","Iteration step: 162; Loss: 0.174, Accuracy: 95.226%\n","Iteration step: 163; Loss: 0.173, Accuracy: 95.236%\n","Iteration step: 164; Loss: 0.174, Accuracy: 95.189%\n","Iteration step: 165; Loss: 0.174, Accuracy: 95.179%\n","Epoch: 7; Validation loss 0.1705159842967987; acc: 0.9442238807678223\n","Current epoch: 8\n","Iteration step: 0; Loss: 0.108, Accuracy: 100.000%\n","Iteration step: 1; Loss: 0.133, Accuracy: 96.875%\n","Iteration step: 2; Loss: 0.232, Accuracy: 94.792%\n","Iteration step: 3; Loss: 0.198, Accuracy: 96.094%\n","Iteration step: 4; Loss: 0.190, Accuracy: 95.625%\n","Iteration step: 5; Loss: 0.200, Accuracy: 93.750%\n","Iteration step: 6; Loss: 0.187, Accuracy: 94.196%\n","Iteration step: 7; Loss: 0.181, Accuracy: 94.531%\n","Iteration step: 8; Loss: 0.206, Accuracy: 94.097%\n","Iteration step: 9; Loss: 0.202, Accuracy: 94.063%\n","Iteration step: 10; Loss: 0.193, Accuracy: 94.602%\n","Iteration step: 11; Loss: 0.197, Accuracy: 94.792%\n","Iteration step: 12; Loss: 0.193, Accuracy: 94.952%\n","Iteration step: 13; Loss: 0.187, Accuracy: 95.089%\n","Iteration step: 14; Loss: 0.188, Accuracy: 95.000%\n","Iteration step: 15; Loss: 0.187, Accuracy: 95.117%\n","Iteration step: 16; Loss: 0.184, Accuracy: 95.404%\n","Iteration step: 17; Loss: 0.177, Accuracy: 95.660%\n","Iteration step: 18; Loss: 0.181, Accuracy: 95.559%\n","Iteration step: 19; Loss: 0.176, Accuracy: 95.625%\n","Iteration step: 20; Loss: 0.180, Accuracy: 95.685%\n","Iteration step: 21; Loss: 0.174, Accuracy: 95.881%\n","Iteration step: 22; Loss: 0.173, Accuracy: 95.924%\n","Iteration step: 23; Loss: 0.177, Accuracy: 95.833%\n","Iteration step: 24; Loss: 0.173, Accuracy: 96.000%\n","Iteration step: 25; Loss: 0.177, Accuracy: 95.913%\n","Iteration step: 26; Loss: 0.178, Accuracy: 95.949%\n","Iteration step: 27; Loss: 0.174, Accuracy: 96.094%\n","Iteration step: 28; Loss: 0.171, Accuracy: 96.228%\n","Iteration step: 29; Loss: 0.174, Accuracy: 96.146%\n","Iteration step: 30; Loss: 0.170, Accuracy: 96.270%\n","Iteration step: 31; Loss: 0.171, Accuracy: 96.191%\n","Iteration step: 32; Loss: 0.171, Accuracy: 96.117%\n","Iteration step: 33; Loss: 0.167, Accuracy: 96.232%\n","Iteration step: 34; Loss: 0.166, Accuracy: 96.161%\n","Iteration step: 35; Loss: 0.163, Accuracy: 96.267%\n","Iteration step: 36; Loss: 0.164, Accuracy: 96.199%\n","Iteration step: 37; Loss: 0.164, Accuracy: 96.135%\n","Iteration step: 38; Loss: 0.162, Accuracy: 96.234%\n","Iteration step: 39; Loss: 0.161, Accuracy: 96.250%\n","Iteration step: 40; Loss: 0.158, Accuracy: 96.341%\n","Iteration step: 41; Loss: 0.156, Accuracy: 96.429%\n","Iteration step: 42; Loss: 0.154, Accuracy: 96.512%\n","Iteration step: 43; Loss: 0.156, Accuracy: 96.378%\n","Iteration step: 44; Loss: 0.158, Accuracy: 96.111%\n","Iteration step: 45; Loss: 0.156, Accuracy: 96.196%\n","Iteration step: 46; Loss: 0.155, Accuracy: 96.210%\n","Iteration step: 47; Loss: 0.154, Accuracy: 96.224%\n","Iteration step: 48; Loss: 0.152, Accuracy: 96.301%\n","Iteration step: 49; Loss: 0.153, Accuracy: 96.188%\n","Iteration step: 50; Loss: 0.153, Accuracy: 96.201%\n","Iteration step: 51; Loss: 0.152, Accuracy: 96.274%\n","Iteration step: 52; Loss: 0.152, Accuracy: 96.285%\n","Iteration step: 53; Loss: 0.151, Accuracy: 96.354%\n","Iteration step: 54; Loss: 0.149, Accuracy: 96.420%\n","Iteration step: 55; Loss: 0.149, Accuracy: 96.429%\n","Iteration step: 56; Loss: 0.149, Accuracy: 96.436%\n","Iteration step: 57; Loss: 0.148, Accuracy: 96.444%\n","Iteration step: 58; Loss: 0.147, Accuracy: 96.504%\n","Iteration step: 59; Loss: 0.146, Accuracy: 96.562%\n","Iteration step: 60; Loss: 0.144, Accuracy: 96.619%\n","Iteration step: 61; Loss: 0.142, Accuracy: 96.673%\n","Iteration step: 62; Loss: 0.142, Accuracy: 96.627%\n","Iteration step: 63; Loss: 0.142, Accuracy: 96.631%\n","Iteration step: 64; Loss: 0.144, Accuracy: 96.587%\n","Iteration step: 65; Loss: 0.145, Accuracy: 96.449%\n","Iteration step: 66; Loss: 0.143, Accuracy: 96.502%\n","Iteration step: 67; Loss: 0.142, Accuracy: 96.553%\n","Iteration step: 68; Loss: 0.142, Accuracy: 96.513%\n","Iteration step: 69; Loss: 0.142, Accuracy: 96.429%\n","Iteration step: 70; Loss: 0.141, Accuracy: 96.479%\n","Iteration step: 71; Loss: 0.141, Accuracy: 96.441%\n","Iteration step: 72; Loss: 0.143, Accuracy: 96.361%\n","Iteration step: 73; Loss: 0.143, Accuracy: 96.368%\n","Iteration step: 74; Loss: 0.144, Accuracy: 96.333%\n","Iteration step: 75; Loss: 0.144, Accuracy: 96.340%\n","Iteration step: 76; Loss: 0.144, Accuracy: 96.347%\n","Iteration step: 77; Loss: 0.144, Accuracy: 96.354%\n","Iteration step: 78; Loss: 0.143, Accuracy: 96.400%\n","Iteration step: 79; Loss: 0.143, Accuracy: 96.406%\n","Iteration step: 80; Loss: 0.143, Accuracy: 96.373%\n","Iteration step: 81; Loss: 0.144, Accuracy: 96.341%\n","Iteration step: 82; Loss: 0.145, Accuracy: 96.310%\n","Iteration step: 83; Loss: 0.147, Accuracy: 96.317%\n","Iteration step: 84; Loss: 0.146, Accuracy: 96.324%\n","Iteration step: 85; Loss: 0.147, Accuracy: 96.294%\n","Iteration step: 86; Loss: 0.148, Accuracy: 96.264%\n","Iteration step: 87; Loss: 0.148, Accuracy: 96.271%\n","Iteration step: 88; Loss: 0.148, Accuracy: 96.243%\n","Iteration step: 89; Loss: 0.148, Accuracy: 96.250%\n","Iteration step: 90; Loss: 0.147, Accuracy: 96.291%\n","Iteration step: 91; Loss: 0.147, Accuracy: 96.298%\n","Iteration step: 92; Loss: 0.149, Accuracy: 96.304%\n","Iteration step: 93; Loss: 0.149, Accuracy: 96.277%\n","Iteration step: 94; Loss: 0.149, Accuracy: 96.283%\n","Iteration step: 95; Loss: 0.149, Accuracy: 96.289%\n","Iteration step: 96; Loss: 0.150, Accuracy: 96.231%\n","Iteration step: 97; Loss: 0.151, Accuracy: 96.173%\n","Iteration step: 98; Loss: 0.150, Accuracy: 96.212%\n","Iteration step: 99; Loss: 0.151, Accuracy: 96.219%\n","Iteration step: 100; Loss: 0.151, Accuracy: 96.194%\n","Iteration step: 101; Loss: 0.150, Accuracy: 96.232%\n","Iteration step: 102; Loss: 0.151, Accuracy: 96.177%\n","Iteration step: 103; Loss: 0.151, Accuracy: 96.214%\n","Iteration step: 104; Loss: 0.151, Accuracy: 96.250%\n","Iteration step: 105; Loss: 0.152, Accuracy: 96.256%\n","Iteration step: 106; Loss: 0.152, Accuracy: 96.262%\n","Iteration step: 107; Loss: 0.152, Accuracy: 96.267%\n","Iteration step: 108; Loss: 0.151, Accuracy: 96.273%\n","Iteration step: 109; Loss: 0.151, Accuracy: 96.278%\n","Iteration step: 110; Loss: 0.152, Accuracy: 96.284%\n","Iteration step: 111; Loss: 0.152, Accuracy: 96.261%\n","Iteration step: 112; Loss: 0.151, Accuracy: 96.267%\n","Iteration step: 113; Loss: 0.152, Accuracy: 96.245%\n","Iteration step: 114; Loss: 0.153, Accuracy: 96.223%\n","Iteration step: 115; Loss: 0.152, Accuracy: 96.255%\n","Iteration step: 116; Loss: 0.151, Accuracy: 96.261%\n","Iteration step: 117; Loss: 0.151, Accuracy: 96.292%\n","Iteration step: 118; Loss: 0.151, Accuracy: 96.324%\n","Iteration step: 119; Loss: 0.150, Accuracy: 96.328%\n","Iteration step: 120; Loss: 0.149, Accuracy: 96.333%\n","Iteration step: 121; Loss: 0.149, Accuracy: 96.363%\n","Iteration step: 122; Loss: 0.149, Accuracy: 96.341%\n","Iteration step: 123; Loss: 0.151, Accuracy: 96.270%\n","Iteration step: 124; Loss: 0.151, Accuracy: 96.275%\n","Iteration step: 125; Loss: 0.152, Accuracy: 96.156%\n","Iteration step: 126; Loss: 0.152, Accuracy: 96.112%\n","Iteration step: 127; Loss: 0.152, Accuracy: 96.118%\n","Iteration step: 128; Loss: 0.152, Accuracy: 96.076%\n","Iteration step: 129; Loss: 0.152, Accuracy: 96.082%\n","Iteration step: 130; Loss: 0.152, Accuracy: 96.088%\n","Iteration step: 131; Loss: 0.151, Accuracy: 96.094%\n","Iteration step: 132; Loss: 0.150, Accuracy: 96.123%\n","Iteration step: 133; Loss: 0.150, Accuracy: 96.152%\n","Iteration step: 134; Loss: 0.149, Accuracy: 96.157%\n","Iteration step: 135; Loss: 0.149, Accuracy: 96.186%\n","Iteration step: 136; Loss: 0.149, Accuracy: 96.168%\n","Iteration step: 137; Loss: 0.150, Accuracy: 96.105%\n","Iteration step: 138; Loss: 0.150, Accuracy: 96.111%\n","Iteration step: 139; Loss: 0.150, Accuracy: 96.094%\n","Iteration step: 140; Loss: 0.149, Accuracy: 96.121%\n","Iteration step: 141; Loss: 0.149, Accuracy: 96.149%\n","Iteration step: 142; Loss: 0.148, Accuracy: 96.154%\n","Iteration step: 143; Loss: 0.148, Accuracy: 96.181%\n","Iteration step: 144; Loss: 0.148, Accuracy: 96.164%\n","Iteration step: 145; Loss: 0.148, Accuracy: 96.147%\n","Iteration step: 146; Loss: 0.148, Accuracy: 96.173%\n","Iteration step: 147; Loss: 0.148, Accuracy: 96.199%\n","Iteration step: 148; Loss: 0.147, Accuracy: 96.204%\n","Iteration step: 149; Loss: 0.147, Accuracy: 96.208%\n","Iteration step: 150; Loss: 0.147, Accuracy: 96.192%\n","Iteration step: 151; Loss: 0.149, Accuracy: 96.135%\n","Iteration step: 152; Loss: 0.148, Accuracy: 96.140%\n","Iteration step: 153; Loss: 0.148, Accuracy: 96.144%\n","Iteration step: 154; Loss: 0.149, Accuracy: 96.129%\n","Iteration step: 155; Loss: 0.149, Accuracy: 96.154%\n","Iteration step: 156; Loss: 0.148, Accuracy: 96.178%\n","Iteration step: 157; Loss: 0.148, Accuracy: 96.163%\n","Iteration step: 158; Loss: 0.149, Accuracy: 96.148%\n","Iteration step: 159; Loss: 0.148, Accuracy: 96.172%\n","Iteration step: 160; Loss: 0.148, Accuracy: 96.196%\n","Iteration step: 161; Loss: 0.148, Accuracy: 96.200%\n","Iteration step: 162; Loss: 0.147, Accuracy: 96.185%\n","Iteration step: 163; Loss: 0.147, Accuracy: 96.189%\n","Iteration step: 164; Loss: 0.149, Accuracy: 96.080%\n","Iteration step: 165; Loss: 0.151, Accuracy: 96.048%\n","Epoch: 8; Validation loss 0.13211385905742645; acc: 0.9640763998031616\n","Current epoch: 9\n","Iteration step: 0; Loss: 0.232, Accuracy: 93.750%\n","Iteration step: 1; Loss: 0.258, Accuracy: 93.750%\n","Iteration step: 2; Loss: 0.196, Accuracy: 95.833%\n","Iteration step: 3; Loss: 0.181, Accuracy: 95.312%\n","Iteration step: 4; Loss: 0.166, Accuracy: 95.625%\n","Iteration step: 5; Loss: 0.161, Accuracy: 95.833%\n","Iteration step: 6; Loss: 0.146, Accuracy: 96.429%\n","Iteration step: 7; Loss: 0.141, Accuracy: 96.875%\n","Iteration step: 8; Loss: 0.136, Accuracy: 97.222%\n","Iteration step: 9; Loss: 0.141, Accuracy: 96.875%\n","Iteration step: 10; Loss: 0.140, Accuracy: 96.875%\n","Iteration step: 11; Loss: 0.154, Accuracy: 96.615%\n","Iteration step: 12; Loss: 0.154, Accuracy: 96.394%\n","Iteration step: 13; Loss: 0.152, Accuracy: 96.429%\n","Iteration step: 14; Loss: 0.150, Accuracy: 96.458%\n","Iteration step: 15; Loss: 0.144, Accuracy: 96.680%\n","Iteration step: 16; Loss: 0.145, Accuracy: 96.691%\n","Iteration step: 17; Loss: 0.139, Accuracy: 96.875%\n","Iteration step: 18; Loss: 0.141, Accuracy: 96.875%\n","Iteration step: 19; Loss: 0.147, Accuracy: 96.562%\n","Iteration step: 20; Loss: 0.144, Accuracy: 96.726%\n","Iteration step: 21; Loss: 0.140, Accuracy: 96.875%\n","Iteration step: 22; Loss: 0.139, Accuracy: 96.739%\n","Iteration step: 23; Loss: 0.137, Accuracy: 96.875%\n","Iteration step: 24; Loss: 0.135, Accuracy: 97.000%\n","Iteration step: 25; Loss: 0.136, Accuracy: 96.875%\n","Iteration step: 26; Loss: 0.138, Accuracy: 96.875%\n","Iteration step: 27; Loss: 0.137, Accuracy: 96.763%\n","Iteration step: 28; Loss: 0.134, Accuracy: 96.875%\n","Iteration step: 29; Loss: 0.133, Accuracy: 96.875%\n","Iteration step: 30; Loss: 0.135, Accuracy: 96.875%\n","Iteration step: 31; Loss: 0.136, Accuracy: 96.777%\n","Iteration step: 32; Loss: 0.133, Accuracy: 96.875%\n","Iteration step: 33; Loss: 0.133, Accuracy: 96.783%\n","Iteration step: 34; Loss: 0.132, Accuracy: 96.875%\n","Iteration step: 35; Loss: 0.131, Accuracy: 96.962%\n","Iteration step: 36; Loss: 0.134, Accuracy: 96.791%\n","Iteration step: 37; Loss: 0.132, Accuracy: 96.875%\n","Iteration step: 38; Loss: 0.130, Accuracy: 96.955%\n","Iteration step: 39; Loss: 0.131, Accuracy: 96.953%\n","Iteration step: 40; Loss: 0.131, Accuracy: 96.951%\n","Iteration step: 41; Loss: 0.129, Accuracy: 97.024%\n","Iteration step: 42; Loss: 0.128, Accuracy: 97.093%\n","Iteration step: 43; Loss: 0.128, Accuracy: 97.088%\n","Iteration step: 44; Loss: 0.129, Accuracy: 97.014%\n","Iteration step: 45; Loss: 0.130, Accuracy: 96.943%\n","Iteration step: 46; Loss: 0.128, Accuracy: 97.008%\n","Iteration step: 47; Loss: 0.126, Accuracy: 97.070%\n","Iteration step: 48; Loss: 0.128, Accuracy: 96.939%\n","Iteration step: 49; Loss: 0.127, Accuracy: 97.000%\n","Iteration step: 50; Loss: 0.127, Accuracy: 96.936%\n","Iteration step: 51; Loss: 0.126, Accuracy: 96.935%\n","Iteration step: 52; Loss: 0.129, Accuracy: 96.875%\n","Iteration step: 53; Loss: 0.130, Accuracy: 96.875%\n","Iteration step: 54; Loss: 0.131, Accuracy: 96.818%\n","Iteration step: 55; Loss: 0.130, Accuracy: 96.875%\n","Iteration step: 56; Loss: 0.129, Accuracy: 96.875%\n","Iteration step: 57; Loss: 0.130, Accuracy: 96.875%\n","Iteration step: 58; Loss: 0.129, Accuracy: 96.928%\n","Iteration step: 59; Loss: 0.129, Accuracy: 96.927%\n","Iteration step: 60; Loss: 0.129, Accuracy: 96.977%\n","Iteration step: 61; Loss: 0.128, Accuracy: 97.026%\n","Iteration step: 62; Loss: 0.126, Accuracy: 97.073%\n","Iteration step: 63; Loss: 0.130, Accuracy: 97.021%\n","Iteration step: 64; Loss: 0.129, Accuracy: 97.067%\n","Iteration step: 65; Loss: 0.128, Accuracy: 97.064%\n","Iteration step: 66; Loss: 0.129, Accuracy: 97.062%\n","Iteration step: 67; Loss: 0.128, Accuracy: 97.059%\n","Iteration step: 68; Loss: 0.130, Accuracy: 96.920%\n","Iteration step: 69; Loss: 0.129, Accuracy: 96.964%\n","Iteration step: 70; Loss: 0.130, Accuracy: 96.963%\n","Iteration step: 71; Loss: 0.132, Accuracy: 96.832%\n","Iteration step: 72; Loss: 0.133, Accuracy: 96.789%\n","Iteration step: 73; Loss: 0.133, Accuracy: 96.833%\n","Iteration step: 74; Loss: 0.132, Accuracy: 96.833%\n","Iteration step: 75; Loss: 0.133, Accuracy: 96.834%\n","Iteration step: 76; Loss: 0.132, Accuracy: 96.834%\n","Iteration step: 77; Loss: 0.133, Accuracy: 96.795%\n","Iteration step: 78; Loss: 0.134, Accuracy: 96.717%\n","Iteration step: 79; Loss: 0.135, Accuracy: 96.680%\n","Iteration step: 80; Loss: 0.135, Accuracy: 96.682%\n","Iteration step: 81; Loss: 0.135, Accuracy: 96.684%\n","Iteration step: 82; Loss: 0.134, Accuracy: 96.724%\n","Iteration step: 83; Loss: 0.136, Accuracy: 96.652%\n","Iteration step: 84; Loss: 0.136, Accuracy: 96.654%\n","Iteration step: 85; Loss: 0.135, Accuracy: 96.657%\n","Iteration step: 86; Loss: 0.134, Accuracy: 96.659%\n","Iteration step: 87; Loss: 0.134, Accuracy: 96.697%\n","Iteration step: 88; Loss: 0.133, Accuracy: 96.735%\n","Iteration step: 89; Loss: 0.132, Accuracy: 96.736%\n","Iteration step: 90; Loss: 0.133, Accuracy: 96.669%\n","Iteration step: 91; Loss: 0.133, Accuracy: 96.637%\n","Iteration step: 92; Loss: 0.134, Accuracy: 96.640%\n","Iteration step: 93; Loss: 0.133, Accuracy: 96.676%\n","Iteration step: 94; Loss: 0.134, Accuracy: 96.645%\n","Iteration step: 95; Loss: 0.135, Accuracy: 96.615%\n","Iteration step: 96; Loss: 0.135, Accuracy: 96.649%\n","Iteration step: 97; Loss: 0.137, Accuracy: 96.588%\n","Iteration step: 98; Loss: 0.137, Accuracy: 96.528%\n","Iteration step: 99; Loss: 0.138, Accuracy: 96.500%\n","Iteration step: 100; Loss: 0.138, Accuracy: 96.504%\n","Iteration step: 101; Loss: 0.137, Accuracy: 96.538%\n","Iteration step: 102; Loss: 0.136, Accuracy: 96.572%\n","Iteration step: 103; Loss: 0.137, Accuracy: 96.575%\n","Iteration step: 104; Loss: 0.139, Accuracy: 96.518%\n","Iteration step: 105; Loss: 0.139, Accuracy: 96.521%\n","Iteration step: 106; Loss: 0.139, Accuracy: 96.525%\n","Iteration step: 107; Loss: 0.138, Accuracy: 96.528%\n","Iteration step: 108; Loss: 0.138, Accuracy: 96.531%\n","Iteration step: 109; Loss: 0.138, Accuracy: 96.562%\n","Iteration step: 110; Loss: 0.137, Accuracy: 96.593%\n","Iteration step: 111; Loss: 0.138, Accuracy: 96.568%\n","Iteration step: 112; Loss: 0.137, Accuracy: 96.598%\n","Iteration step: 113; Loss: 0.137, Accuracy: 96.601%\n","Iteration step: 114; Loss: 0.137, Accuracy: 96.630%\n","Iteration step: 115; Loss: 0.137, Accuracy: 96.633%\n","Iteration step: 116; Loss: 0.137, Accuracy: 96.635%\n","Iteration step: 117; Loss: 0.138, Accuracy: 96.610%\n","Iteration step: 118; Loss: 0.138, Accuracy: 96.639%\n","Iteration step: 119; Loss: 0.138, Accuracy: 96.667%\n","Iteration step: 120; Loss: 0.137, Accuracy: 96.694%\n","Iteration step: 121; Loss: 0.136, Accuracy: 96.721%\n","Iteration step: 122; Loss: 0.136, Accuracy: 96.748%\n","Iteration step: 123; Loss: 0.136, Accuracy: 96.724%\n","Iteration step: 124; Loss: 0.136, Accuracy: 96.700%\n","Iteration step: 125; Loss: 0.136, Accuracy: 96.726%\n","Iteration step: 126; Loss: 0.137, Accuracy: 96.678%\n","Iteration step: 127; Loss: 0.137, Accuracy: 96.680%\n","Iteration step: 128; Loss: 0.137, Accuracy: 96.657%\n","Iteration step: 129; Loss: 0.137, Accuracy: 96.683%\n","Iteration step: 130; Loss: 0.136, Accuracy: 96.708%\n","Iteration step: 131; Loss: 0.136, Accuracy: 96.709%\n","Iteration step: 132; Loss: 0.136, Accuracy: 96.711%\n","Iteration step: 133; Loss: 0.137, Accuracy: 96.665%\n","Iteration step: 134; Loss: 0.137, Accuracy: 96.644%\n","Iteration step: 135; Loss: 0.137, Accuracy: 96.668%\n","Iteration step: 136; Loss: 0.137, Accuracy: 96.693%\n","Iteration step: 137; Loss: 0.136, Accuracy: 96.716%\n","Iteration step: 138; Loss: 0.135, Accuracy: 96.740%\n","Iteration step: 139; Loss: 0.135, Accuracy: 96.741%\n","Iteration step: 140; Loss: 0.134, Accuracy: 96.742%\n","Iteration step: 141; Loss: 0.134, Accuracy: 96.743%\n","Iteration step: 142; Loss: 0.134, Accuracy: 96.700%\n","Iteration step: 143; Loss: 0.134, Accuracy: 96.723%\n","Iteration step: 144; Loss: 0.133, Accuracy: 96.746%\n","Iteration step: 145; Loss: 0.133, Accuracy: 96.768%\n","Iteration step: 146; Loss: 0.132, Accuracy: 96.769%\n","Iteration step: 147; Loss: 0.132, Accuracy: 96.791%\n","Iteration step: 148; Loss: 0.132, Accuracy: 96.749%\n","Iteration step: 149; Loss: 0.132, Accuracy: 96.729%\n","Iteration step: 150; Loss: 0.132, Accuracy: 96.730%\n","Iteration step: 151; Loss: 0.132, Accuracy: 96.731%\n","Iteration step: 152; Loss: 0.132, Accuracy: 96.732%\n","Iteration step: 153; Loss: 0.132, Accuracy: 96.713%\n","Iteration step: 154; Loss: 0.131, Accuracy: 96.734%\n","Iteration step: 155; Loss: 0.131, Accuracy: 96.715%\n","Iteration step: 156; Loss: 0.131, Accuracy: 96.736%\n","Iteration step: 157; Loss: 0.130, Accuracy: 96.756%\n","Iteration step: 158; Loss: 0.131, Accuracy: 96.737%\n","Iteration step: 159; Loss: 0.131, Accuracy: 96.738%\n","Iteration step: 160; Loss: 0.131, Accuracy: 96.739%\n","Iteration step: 161; Loss: 0.132, Accuracy: 96.721%\n","Iteration step: 162; Loss: 0.131, Accuracy: 96.741%\n","Iteration step: 163; Loss: 0.131, Accuracy: 96.761%\n","Iteration step: 164; Loss: 0.131, Accuracy: 96.780%\n","Iteration step: 165; Loss: 0.130, Accuracy: 96.786%\n","Epoch: 9; Validation loss 0.11667460203170776; acc: 0.9722064733505249\n","Current epoch: 10\n","Iteration step: 0; Loss: 0.066, Accuracy: 100.000%\n","Iteration step: 1; Loss: 0.085, Accuracy: 96.875%\n","Iteration step: 2; Loss: 0.098, Accuracy: 96.875%\n","Iteration step: 3; Loss: 0.101, Accuracy: 96.875%\n","Iteration step: 4; Loss: 0.095, Accuracy: 97.500%\n","Iteration step: 5; Loss: 0.094, Accuracy: 97.917%\n","Iteration step: 6; Loss: 0.088, Accuracy: 98.214%\n","Iteration step: 7; Loss: 0.087, Accuracy: 98.047%\n","Iteration step: 8; Loss: 0.096, Accuracy: 97.569%\n","Iteration step: 9; Loss: 0.091, Accuracy: 97.812%\n","Iteration step: 10; Loss: 0.100, Accuracy: 97.443%\n","Iteration step: 11; Loss: 0.097, Accuracy: 97.656%\n","Iteration step: 12; Loss: 0.103, Accuracy: 97.596%\n","Iteration step: 13; Loss: 0.109, Accuracy: 97.098%\n","Iteration step: 14; Loss: 0.108, Accuracy: 97.083%\n","Iteration step: 15; Loss: 0.104, Accuracy: 97.266%\n","Iteration step: 16; Loss: 0.105, Accuracy: 97.059%\n","Iteration step: 17; Loss: 0.108, Accuracy: 96.875%\n","Iteration step: 18; Loss: 0.108, Accuracy: 96.875%\n","Iteration step: 19; Loss: 0.114, Accuracy: 96.719%\n","Iteration step: 20; Loss: 0.117, Accuracy: 96.280%\n","Iteration step: 21; Loss: 0.119, Accuracy: 96.307%\n","Iteration step: 22; Loss: 0.117, Accuracy: 96.332%\n","Iteration step: 23; Loss: 0.116, Accuracy: 96.354%\n","Iteration step: 24; Loss: 0.118, Accuracy: 96.250%\n","Iteration step: 25; Loss: 0.116, Accuracy: 96.394%\n","Iteration step: 26; Loss: 0.114, Accuracy: 96.528%\n","Iteration step: 27; Loss: 0.117, Accuracy: 96.540%\n","Iteration step: 28; Loss: 0.115, Accuracy: 96.659%\n","Iteration step: 29; Loss: 0.114, Accuracy: 96.771%\n","Iteration step: 30; Loss: 0.114, Accuracy: 96.875%\n","Iteration step: 31; Loss: 0.119, Accuracy: 96.875%\n","Iteration step: 32; Loss: 0.119, Accuracy: 96.875%\n","Iteration step: 33; Loss: 0.117, Accuracy: 96.967%\n","Iteration step: 34; Loss: 0.116, Accuracy: 96.964%\n","Iteration step: 35; Loss: 0.117, Accuracy: 96.962%\n","Iteration step: 36; Loss: 0.115, Accuracy: 97.044%\n","Iteration step: 37; Loss: 0.115, Accuracy: 97.039%\n","Iteration step: 38; Loss: 0.116, Accuracy: 96.955%\n","Iteration step: 39; Loss: 0.115, Accuracy: 97.031%\n","Iteration step: 40; Loss: 0.114, Accuracy: 97.104%\n","Iteration step: 41; Loss: 0.114, Accuracy: 97.098%\n","Iteration step: 42; Loss: 0.114, Accuracy: 97.093%\n","Iteration step: 43; Loss: 0.113, Accuracy: 97.159%\n","Iteration step: 44; Loss: 0.113, Accuracy: 97.222%\n","Iteration step: 45; Loss: 0.114, Accuracy: 97.215%\n","Iteration step: 46; Loss: 0.114, Accuracy: 97.207%\n","Iteration step: 47; Loss: 0.116, Accuracy: 97.070%\n","Iteration step: 48; Loss: 0.118, Accuracy: 97.003%\n","Iteration step: 49; Loss: 0.118, Accuracy: 96.938%\n","Iteration step: 50; Loss: 0.116, Accuracy: 96.998%\n","Iteration step: 51; Loss: 0.115, Accuracy: 96.995%\n","Iteration step: 52; Loss: 0.114, Accuracy: 97.052%\n","Iteration step: 53; Loss: 0.113, Accuracy: 97.106%\n","Iteration step: 54; Loss: 0.113, Accuracy: 97.102%\n","Iteration step: 55; Loss: 0.113, Accuracy: 97.042%\n","Iteration step: 56; Loss: 0.112, Accuracy: 97.094%\n","Iteration step: 57; Loss: 0.111, Accuracy: 97.144%\n","Iteration step: 58; Loss: 0.110, Accuracy: 97.193%\n","Iteration step: 59; Loss: 0.111, Accuracy: 97.135%\n","Iteration step: 60; Loss: 0.110, Accuracy: 97.182%\n","Iteration step: 61; Loss: 0.114, Accuracy: 97.077%\n","Iteration step: 62; Loss: 0.113, Accuracy: 97.123%\n","Iteration step: 63; Loss: 0.112, Accuracy: 97.168%\n","Iteration step: 64; Loss: 0.112, Accuracy: 97.163%\n","Iteration step: 65; Loss: 0.112, Accuracy: 97.159%\n","Iteration step: 66; Loss: 0.111, Accuracy: 97.201%\n","Iteration step: 67; Loss: 0.113, Accuracy: 97.105%\n","Iteration step: 68; Loss: 0.113, Accuracy: 97.147%\n","Iteration step: 69; Loss: 0.112, Accuracy: 97.188%\n","Iteration step: 70; Loss: 0.112, Accuracy: 97.183%\n","Iteration step: 71; Loss: 0.111, Accuracy: 97.179%\n","Iteration step: 72; Loss: 0.114, Accuracy: 97.132%\n","Iteration step: 73; Loss: 0.114, Accuracy: 97.086%\n","Iteration step: 74; Loss: 0.113, Accuracy: 97.125%\n","Iteration step: 75; Loss: 0.113, Accuracy: 97.122%\n","Iteration step: 76; Loss: 0.114, Accuracy: 97.119%\n","Iteration step: 77; Loss: 0.114, Accuracy: 97.035%\n","Iteration step: 78; Loss: 0.115, Accuracy: 97.033%\n","Iteration step: 79; Loss: 0.117, Accuracy: 96.953%\n","Iteration step: 80; Loss: 0.116, Accuracy: 96.952%\n","Iteration step: 81; Loss: 0.116, Accuracy: 96.951%\n","Iteration step: 82; Loss: 0.116, Accuracy: 96.988%\n","Iteration step: 83; Loss: 0.115, Accuracy: 97.024%\n","Iteration step: 84; Loss: 0.115, Accuracy: 97.022%\n","Iteration step: 85; Loss: 0.114, Accuracy: 97.057%\n","Iteration step: 86; Loss: 0.113, Accuracy: 97.055%\n","Iteration step: 87; Loss: 0.113, Accuracy: 97.053%\n","Iteration step: 88; Loss: 0.113, Accuracy: 97.086%\n","Iteration step: 89; Loss: 0.115, Accuracy: 96.944%\n","Iteration step: 90; Loss: 0.116, Accuracy: 96.944%\n","Iteration step: 91; Loss: 0.117, Accuracy: 96.909%\n","Iteration step: 92; Loss: 0.116, Accuracy: 96.909%\n","Iteration step: 93; Loss: 0.116, Accuracy: 96.908%\n","Iteration step: 94; Loss: 0.117, Accuracy: 96.908%\n","Iteration step: 95; Loss: 0.116, Accuracy: 96.940%\n","Iteration step: 96; Loss: 0.116, Accuracy: 96.939%\n","Iteration step: 97; Loss: 0.116, Accuracy: 96.939%\n","Iteration step: 98; Loss: 0.115, Accuracy: 96.970%\n","Iteration step: 99; Loss: 0.114, Accuracy: 97.000%\n","Iteration step: 100; Loss: 0.114, Accuracy: 96.968%\n","Iteration step: 101; Loss: 0.114, Accuracy: 96.998%\n","Iteration step: 102; Loss: 0.113, Accuracy: 96.996%\n","Iteration step: 103; Loss: 0.114, Accuracy: 96.995%\n","Iteration step: 104; Loss: 0.114, Accuracy: 96.994%\n","Iteration step: 105; Loss: 0.115, Accuracy: 96.963%\n","Iteration step: 106; Loss: 0.115, Accuracy: 96.992%\n","Iteration step: 107; Loss: 0.116, Accuracy: 96.962%\n","Iteration step: 108; Loss: 0.115, Accuracy: 96.990%\n","Iteration step: 109; Loss: 0.115, Accuracy: 97.017%\n","Iteration step: 110; Loss: 0.114, Accuracy: 97.044%\n","Iteration step: 111; Loss: 0.116, Accuracy: 96.959%\n","Iteration step: 112; Loss: 0.115, Accuracy: 96.986%\n","Iteration step: 113; Loss: 0.115, Accuracy: 96.957%\n","Iteration step: 114; Loss: 0.115, Accuracy: 96.957%\n","Iteration step: 115; Loss: 0.115, Accuracy: 96.956%\n","Iteration step: 116; Loss: 0.115, Accuracy: 96.982%\n","Iteration step: 117; Loss: 0.115, Accuracy: 97.007%\n","Iteration step: 118; Loss: 0.115, Accuracy: 97.033%\n","Iteration step: 119; Loss: 0.115, Accuracy: 97.057%\n","Iteration step: 120; Loss: 0.115, Accuracy: 97.056%\n","Iteration step: 121; Loss: 0.115, Accuracy: 97.054%\n","Iteration step: 122; Loss: 0.114, Accuracy: 97.078%\n","Iteration step: 123; Loss: 0.114, Accuracy: 97.051%\n","Iteration step: 124; Loss: 0.115, Accuracy: 97.050%\n","Iteration step: 125; Loss: 0.116, Accuracy: 96.999%\n","Iteration step: 126; Loss: 0.115, Accuracy: 97.023%\n","Iteration step: 127; Loss: 0.115, Accuracy: 97.021%\n","Iteration step: 128; Loss: 0.115, Accuracy: 97.045%\n","Iteration step: 129; Loss: 0.114, Accuracy: 97.067%\n","Iteration step: 130; Loss: 0.115, Accuracy: 97.018%\n","Iteration step: 131; Loss: 0.115, Accuracy: 97.017%\n","Iteration step: 132; Loss: 0.115, Accuracy: 97.039%\n","Iteration step: 133; Loss: 0.115, Accuracy: 97.038%\n","Iteration step: 134; Loss: 0.115, Accuracy: 97.037%\n","Iteration step: 135; Loss: 0.115, Accuracy: 96.990%\n","Iteration step: 136; Loss: 0.115, Accuracy: 96.989%\n","Iteration step: 137; Loss: 0.115, Accuracy: 96.988%\n","Iteration step: 138; Loss: 0.116, Accuracy: 96.920%\n","Iteration step: 139; Loss: 0.117, Accuracy: 96.897%\n","Iteration step: 140; Loss: 0.116, Accuracy: 96.919%\n","Iteration step: 141; Loss: 0.116, Accuracy: 96.897%\n","Iteration step: 142; Loss: 0.116, Accuracy: 96.897%\n","Iteration step: 143; Loss: 0.116, Accuracy: 96.918%\n","Iteration step: 144; Loss: 0.116, Accuracy: 96.918%\n","Iteration step: 145; Loss: 0.116, Accuracy: 96.939%\n","Iteration step: 146; Loss: 0.115, Accuracy: 96.960%\n","Iteration step: 147; Loss: 0.115, Accuracy: 96.981%\n","Iteration step: 148; Loss: 0.115, Accuracy: 96.959%\n","Iteration step: 149; Loss: 0.116, Accuracy: 96.938%\n","Iteration step: 150; Loss: 0.116, Accuracy: 96.937%\n","Iteration step: 151; Loss: 0.115, Accuracy: 96.957%\n","Iteration step: 152; Loss: 0.116, Accuracy: 96.957%\n","Iteration step: 153; Loss: 0.115, Accuracy: 96.976%\n","Iteration step: 154; Loss: 0.115, Accuracy: 96.996%\n","Iteration step: 155; Loss: 0.115, Accuracy: 96.975%\n","Iteration step: 156; Loss: 0.114, Accuracy: 96.994%\n","Iteration step: 157; Loss: 0.114, Accuracy: 97.013%\n","Iteration step: 158; Loss: 0.114, Accuracy: 97.013%\n","Iteration step: 159; Loss: 0.114, Accuracy: 97.012%\n","Iteration step: 160; Loss: 0.114, Accuracy: 96.991%\n","Iteration step: 161; Loss: 0.115, Accuracy: 96.952%\n","Iteration step: 162; Loss: 0.115, Accuracy: 96.933%\n","Iteration step: 163; Loss: 0.115, Accuracy: 96.932%\n","Iteration step: 164; Loss: 0.114, Accuracy: 96.951%\n","Iteration step: 165; Loss: 0.114, Accuracy: 96.956%\n","Epoch: 10; Validation loss 0.09851185232400894; acc: 0.9731518030166626\n","Current epoch: 11\n","Iteration step: 0; Loss: 0.055, Accuracy: 100.000%\n","Iteration step: 1; Loss: 0.079, Accuracy: 98.438%\n","Iteration step: 2; Loss: 0.085, Accuracy: 97.917%\n","Iteration step: 3; Loss: 0.073, Accuracy: 98.438%\n","Iteration step: 4; Loss: 0.066, Accuracy: 98.750%\n","Iteration step: 5; Loss: 0.095, Accuracy: 97.396%\n","Iteration step: 6; Loss: 0.088, Accuracy: 97.768%\n","Iteration step: 7; Loss: 0.083, Accuracy: 98.047%\n","Iteration step: 8; Loss: 0.081, Accuracy: 97.917%\n","Iteration step: 9; Loss: 0.092, Accuracy: 97.500%\n","Iteration step: 10; Loss: 0.087, Accuracy: 97.727%\n","Iteration step: 11; Loss: 0.089, Accuracy: 97.656%\n","Iteration step: 12; Loss: 0.087, Accuracy: 97.837%\n","Iteration step: 13; Loss: 0.083, Accuracy: 97.991%\n","Iteration step: 14; Loss: 0.083, Accuracy: 97.917%\n","Iteration step: 15; Loss: 0.081, Accuracy: 98.047%\n","Iteration step: 16; Loss: 0.079, Accuracy: 98.162%\n","Iteration step: 17; Loss: 0.086, Accuracy: 97.743%\n","Iteration step: 18; Loss: 0.086, Accuracy: 97.697%\n","Iteration step: 19; Loss: 0.084, Accuracy: 97.812%\n","Iteration step: 20; Loss: 0.089, Accuracy: 97.768%\n","Iteration step: 21; Loss: 0.095, Accuracy: 97.585%\n","Iteration step: 22; Loss: 0.093, Accuracy: 97.690%\n","Iteration step: 23; Loss: 0.090, Accuracy: 97.786%\n","Iteration step: 24; Loss: 0.097, Accuracy: 97.500%\n","Iteration step: 25; Loss: 0.098, Accuracy: 97.476%\n","Iteration step: 26; Loss: 0.101, Accuracy: 97.338%\n","Iteration step: 27; Loss: 0.104, Accuracy: 97.321%\n","Iteration step: 28; Loss: 0.106, Accuracy: 97.198%\n","Iteration step: 29; Loss: 0.106, Accuracy: 97.188%\n","Iteration step: 30; Loss: 0.105, Accuracy: 97.177%\n","Iteration step: 31; Loss: 0.105, Accuracy: 97.168%\n","Iteration step: 32; Loss: 0.104, Accuracy: 97.254%\n","Iteration step: 33; Loss: 0.102, Accuracy: 97.335%\n","Iteration step: 34; Loss: 0.102, Accuracy: 97.411%\n","Iteration step: 35; Loss: 0.101, Accuracy: 97.483%\n","Iteration step: 36; Loss: 0.101, Accuracy: 97.466%\n","Iteration step: 37; Loss: 0.100, Accuracy: 97.533%\n","Iteration step: 38; Loss: 0.101, Accuracy: 97.356%\n","Iteration step: 39; Loss: 0.103, Accuracy: 97.344%\n","Iteration step: 40; Loss: 0.105, Accuracy: 97.180%\n","Iteration step: 41; Loss: 0.107, Accuracy: 97.173%\n","Iteration step: 42; Loss: 0.106, Accuracy: 97.238%\n","Iteration step: 43; Loss: 0.105, Accuracy: 97.230%\n","Iteration step: 44; Loss: 0.106, Accuracy: 97.222%\n","Iteration step: 45; Loss: 0.107, Accuracy: 97.215%\n","Iteration step: 46; Loss: 0.105, Accuracy: 97.274%\n","Iteration step: 47; Loss: 0.104, Accuracy: 97.266%\n","Iteration step: 48; Loss: 0.104, Accuracy: 97.321%\n","Iteration step: 49; Loss: 0.104, Accuracy: 97.312%\n","Iteration step: 50; Loss: 0.103, Accuracy: 97.365%\n","Iteration step: 51; Loss: 0.106, Accuracy: 97.296%\n","Iteration step: 52; Loss: 0.106, Accuracy: 97.288%\n","Iteration step: 53; Loss: 0.106, Accuracy: 97.222%\n","Iteration step: 54; Loss: 0.106, Accuracy: 97.159%\n","Iteration step: 55; Loss: 0.106, Accuracy: 97.154%\n","Iteration step: 56; Loss: 0.106, Accuracy: 97.204%\n","Iteration step: 57; Loss: 0.105, Accuracy: 97.252%\n","Iteration step: 58; Loss: 0.105, Accuracy: 97.246%\n","Iteration step: 59; Loss: 0.104, Accuracy: 97.240%\n","Iteration step: 60; Loss: 0.104, Accuracy: 97.234%\n","Iteration step: 61; Loss: 0.104, Accuracy: 97.228%\n","Iteration step: 62; Loss: 0.103, Accuracy: 97.272%\n","Iteration step: 63; Loss: 0.102, Accuracy: 97.314%\n","Iteration step: 64; Loss: 0.102, Accuracy: 97.308%\n","Iteration step: 65; Loss: 0.102, Accuracy: 97.301%\n","Iteration step: 66; Loss: 0.101, Accuracy: 97.341%\n","Iteration step: 67; Loss: 0.100, Accuracy: 97.381%\n","Iteration step: 68; Loss: 0.100, Accuracy: 97.328%\n","Iteration step: 69; Loss: 0.103, Accuracy: 97.232%\n","Iteration step: 70; Loss: 0.102, Accuracy: 97.271%\n","Iteration step: 71; Loss: 0.102, Accuracy: 97.266%\n","Iteration step: 72; Loss: 0.103, Accuracy: 97.260%\n","Iteration step: 73; Loss: 0.102, Accuracy: 97.297%\n","Iteration step: 74; Loss: 0.101, Accuracy: 97.333%\n","Iteration step: 75; Loss: 0.102, Accuracy: 97.327%\n","Iteration step: 76; Loss: 0.102, Accuracy: 97.281%\n","Iteration step: 77; Loss: 0.102, Accuracy: 97.316%\n","Iteration step: 78; Loss: 0.102, Accuracy: 97.350%\n","Iteration step: 79; Loss: 0.101, Accuracy: 97.383%\n","Iteration step: 80; Loss: 0.100, Accuracy: 97.415%\n","Iteration step: 81; Loss: 0.100, Accuracy: 97.409%\n","Iteration step: 82; Loss: 0.101, Accuracy: 97.364%\n","Iteration step: 83; Loss: 0.100, Accuracy: 97.396%\n","Iteration step: 84; Loss: 0.100, Accuracy: 97.426%\n","Iteration step: 85; Loss: 0.100, Accuracy: 97.456%\n","Iteration step: 86; Loss: 0.101, Accuracy: 97.378%\n","Iteration step: 87; Loss: 0.101, Accuracy: 97.337%\n","Iteration step: 88; Loss: 0.101, Accuracy: 97.367%\n","Iteration step: 89; Loss: 0.100, Accuracy: 97.396%\n","Iteration step: 90; Loss: 0.100, Accuracy: 97.424%\n","Iteration step: 91; Loss: 0.100, Accuracy: 97.418%\n","Iteration step: 92; Loss: 0.100, Accuracy: 97.413%\n","Iteration step: 93; Loss: 0.100, Accuracy: 97.440%\n","Iteration step: 94; Loss: 0.100, Accuracy: 97.434%\n","Iteration step: 95; Loss: 0.102, Accuracy: 97.428%\n","Iteration step: 96; Loss: 0.101, Accuracy: 97.423%\n","Iteration step: 97; Loss: 0.102, Accuracy: 97.385%\n","Iteration step: 98; Loss: 0.102, Accuracy: 97.412%\n","Iteration step: 99; Loss: 0.102, Accuracy: 97.406%\n","Iteration step: 100; Loss: 0.102, Accuracy: 97.432%\n","Iteration step: 101; Loss: 0.102, Accuracy: 97.426%\n","Iteration step: 102; Loss: 0.101, Accuracy: 97.451%\n","Iteration step: 103; Loss: 0.101, Accuracy: 97.476%\n","Iteration step: 104; Loss: 0.101, Accuracy: 97.440%\n","Iteration step: 105; Loss: 0.100, Accuracy: 97.465%\n","Iteration step: 106; Loss: 0.100, Accuracy: 97.488%\n","Iteration step: 107; Loss: 0.102, Accuracy: 97.425%\n","Iteration step: 108; Loss: 0.103, Accuracy: 97.391%\n","Iteration step: 109; Loss: 0.102, Accuracy: 97.415%\n","Iteration step: 110; Loss: 0.102, Accuracy: 97.438%\n","Iteration step: 111; Loss: 0.101, Accuracy: 97.461%\n","Iteration step: 112; Loss: 0.101, Accuracy: 97.428%\n","Iteration step: 113; Loss: 0.101, Accuracy: 97.451%\n","Iteration step: 114; Loss: 0.101, Accuracy: 97.473%\n","Iteration step: 115; Loss: 0.101, Accuracy: 97.414%\n","Iteration step: 116; Loss: 0.102, Accuracy: 97.409%\n","Iteration step: 117; Loss: 0.102, Accuracy: 97.378%\n","Iteration step: 118; Loss: 0.102, Accuracy: 97.400%\n","Iteration step: 119; Loss: 0.103, Accuracy: 97.370%\n","Iteration step: 120; Loss: 0.102, Accuracy: 97.366%\n","Iteration step: 121; Loss: 0.103, Accuracy: 97.336%\n","Iteration step: 122; Loss: 0.103, Accuracy: 97.358%\n","Iteration step: 123; Loss: 0.103, Accuracy: 97.354%\n","Iteration step: 124; Loss: 0.103, Accuracy: 97.375%\n","Iteration step: 125; Loss: 0.102, Accuracy: 97.396%\n","Iteration step: 126; Loss: 0.102, Accuracy: 97.416%\n","Iteration step: 127; Loss: 0.102, Accuracy: 97.412%\n","Iteration step: 128; Loss: 0.102, Accuracy: 97.432%\n","Iteration step: 129; Loss: 0.102, Accuracy: 97.428%\n","Iteration step: 130; Loss: 0.101, Accuracy: 97.448%\n","Iteration step: 131; Loss: 0.101, Accuracy: 97.443%\n","Iteration step: 132; Loss: 0.101, Accuracy: 97.415%\n","Iteration step: 133; Loss: 0.101, Accuracy: 97.411%\n","Iteration step: 134; Loss: 0.102, Accuracy: 97.407%\n","Iteration step: 135; Loss: 0.102, Accuracy: 97.403%\n","Iteration step: 136; Loss: 0.102, Accuracy: 97.400%\n","Iteration step: 137; Loss: 0.103, Accuracy: 97.373%\n","Iteration step: 138; Loss: 0.103, Accuracy: 97.370%\n","Iteration step: 139; Loss: 0.103, Accuracy: 97.388%\n","Iteration step: 140; Loss: 0.102, Accuracy: 97.407%\n","Iteration step: 141; Loss: 0.103, Accuracy: 97.381%\n","Iteration step: 142; Loss: 0.103, Accuracy: 97.378%\n","Iteration step: 143; Loss: 0.102, Accuracy: 97.396%\n","Iteration step: 144; Loss: 0.103, Accuracy: 97.371%\n","Iteration step: 145; Loss: 0.103, Accuracy: 97.346%\n","Iteration step: 146; Loss: 0.103, Accuracy: 97.343%\n","Iteration step: 147; Loss: 0.103, Accuracy: 97.340%\n","Iteration step: 148; Loss: 0.102, Accuracy: 97.357%\n","Iteration step: 149; Loss: 0.102, Accuracy: 97.354%\n","Iteration step: 150; Loss: 0.103, Accuracy: 97.330%\n","Iteration step: 151; Loss: 0.102, Accuracy: 97.348%\n","Iteration step: 152; Loss: 0.102, Accuracy: 97.345%\n","Iteration step: 153; Loss: 0.103, Accuracy: 97.342%\n","Iteration step: 154; Loss: 0.103, Accuracy: 97.359%\n","Iteration step: 155; Loss: 0.102, Accuracy: 97.376%\n","Iteration step: 156; Loss: 0.103, Accuracy: 97.353%\n","Iteration step: 157; Loss: 0.103, Accuracy: 97.369%\n","Iteration step: 158; Loss: 0.103, Accuracy: 97.366%\n","Iteration step: 159; Loss: 0.103, Accuracy: 97.344%\n","Iteration step: 160; Loss: 0.103, Accuracy: 97.341%\n","Iteration step: 161; Loss: 0.103, Accuracy: 97.338%\n","Iteration step: 162; Loss: 0.103, Accuracy: 97.354%\n","Iteration step: 163; Loss: 0.103, Accuracy: 97.332%\n","Iteration step: 164; Loss: 0.103, Accuracy: 97.311%\n","Iteration step: 165; Loss: 0.102, Accuracy: 97.315%\n","Epoch: 11; Validation loss 0.096701979637146; acc: 0.97371906042099\n","Current epoch: 12\n","Iteration step: 0; Loss: 0.138, Accuracy: 96.875%\n","Iteration step: 1; Loss: 0.126, Accuracy: 96.875%\n","Iteration step: 2; Loss: 0.092, Accuracy: 97.917%\n","Iteration step: 3; Loss: 0.088, Accuracy: 98.438%\n","Iteration step: 4; Loss: 0.094, Accuracy: 98.125%\n","Iteration step: 5; Loss: 0.126, Accuracy: 96.875%\n","Iteration step: 6; Loss: 0.111, Accuracy: 97.321%\n","Iteration step: 7; Loss: 0.104, Accuracy: 97.656%\n","Iteration step: 8; Loss: 0.096, Accuracy: 97.917%\n","Iteration step: 9; Loss: 0.096, Accuracy: 97.812%\n","Iteration step: 10; Loss: 0.094, Accuracy: 97.727%\n","Iteration step: 11; Loss: 0.092, Accuracy: 97.917%\n","Iteration step: 12; Loss: 0.094, Accuracy: 97.596%\n","Iteration step: 13; Loss: 0.094, Accuracy: 97.321%\n","Iteration step: 14; Loss: 0.100, Accuracy: 97.083%\n","Iteration step: 15; Loss: 0.098, Accuracy: 97.266%\n","Iteration step: 16; Loss: 0.099, Accuracy: 97.059%\n","Iteration step: 17; Loss: 0.095, Accuracy: 97.222%\n","Iteration step: 18; Loss: 0.093, Accuracy: 97.368%\n","Iteration step: 19; Loss: 0.105, Accuracy: 97.031%\n","Iteration step: 20; Loss: 0.104, Accuracy: 97.024%\n","Iteration step: 21; Loss: 0.101, Accuracy: 97.159%\n","Iteration step: 22; Loss: 0.102, Accuracy: 97.147%\n","Iteration step: 23; Loss: 0.102, Accuracy: 97.135%\n","Iteration step: 24; Loss: 0.102, Accuracy: 97.125%\n","Iteration step: 25; Loss: 0.101, Accuracy: 97.236%\n","Iteration step: 26; Loss: 0.100, Accuracy: 97.338%\n","Iteration step: 27; Loss: 0.098, Accuracy: 97.433%\n","Iteration step: 28; Loss: 0.096, Accuracy: 97.522%\n","Iteration step: 29; Loss: 0.094, Accuracy: 97.604%\n","Iteration step: 30; Loss: 0.093, Accuracy: 97.681%\n","Iteration step: 31; Loss: 0.092, Accuracy: 97.754%\n","Iteration step: 32; Loss: 0.094, Accuracy: 97.538%\n","Iteration step: 33; Loss: 0.096, Accuracy: 97.335%\n","Iteration step: 34; Loss: 0.096, Accuracy: 97.411%\n","Iteration step: 35; Loss: 0.096, Accuracy: 97.396%\n","Iteration step: 36; Loss: 0.095, Accuracy: 97.382%\n","Iteration step: 37; Loss: 0.097, Accuracy: 97.286%\n","Iteration step: 38; Loss: 0.098, Accuracy: 97.276%\n","Iteration step: 39; Loss: 0.097, Accuracy: 97.344%\n","Iteration step: 40; Loss: 0.095, Accuracy: 97.409%\n","Iteration step: 41; Loss: 0.097, Accuracy: 97.247%\n","Iteration step: 42; Loss: 0.096, Accuracy: 97.311%\n","Iteration step: 43; Loss: 0.095, Accuracy: 97.372%\n","Iteration step: 44; Loss: 0.095, Accuracy: 97.361%\n","Iteration step: 45; Loss: 0.102, Accuracy: 97.011%\n","Iteration step: 46; Loss: 0.103, Accuracy: 96.941%\n","Iteration step: 47; Loss: 0.104, Accuracy: 96.875%\n","Iteration step: 48; Loss: 0.103, Accuracy: 96.875%\n","Iteration step: 49; Loss: 0.103, Accuracy: 96.875%\n","Iteration step: 50; Loss: 0.103, Accuracy: 96.875%\n","Iteration step: 51; Loss: 0.103, Accuracy: 96.935%\n","Iteration step: 52; Loss: 0.103, Accuracy: 96.934%\n","Iteration step: 53; Loss: 0.101, Accuracy: 96.991%\n","Iteration step: 54; Loss: 0.101, Accuracy: 97.045%\n","Iteration step: 55; Loss: 0.100, Accuracy: 97.098%\n","Iteration step: 56; Loss: 0.099, Accuracy: 97.094%\n","Iteration step: 57; Loss: 0.098, Accuracy: 97.144%\n","Iteration step: 58; Loss: 0.098, Accuracy: 97.140%\n","Iteration step: 59; Loss: 0.098, Accuracy: 97.188%\n","Iteration step: 60; Loss: 0.098, Accuracy: 97.182%\n","Iteration step: 61; Loss: 0.097, Accuracy: 97.228%\n","Iteration step: 62; Loss: 0.097, Accuracy: 97.173%\n","Iteration step: 63; Loss: 0.097, Accuracy: 97.168%\n","Iteration step: 64; Loss: 0.096, Accuracy: 97.212%\n","Iteration step: 65; Loss: 0.096, Accuracy: 97.254%\n","Iteration step: 66; Loss: 0.097, Accuracy: 97.248%\n","Iteration step: 67; Loss: 0.097, Accuracy: 97.243%\n","Iteration step: 68; Loss: 0.096, Accuracy: 97.283%\n","Iteration step: 69; Loss: 0.096, Accuracy: 97.277%\n","Iteration step: 70; Loss: 0.096, Accuracy: 97.315%\n","Iteration step: 71; Loss: 0.096, Accuracy: 97.309%\n","Iteration step: 72; Loss: 0.096, Accuracy: 97.260%\n","Iteration step: 73; Loss: 0.095, Accuracy: 97.297%\n","Iteration step: 74; Loss: 0.095, Accuracy: 97.292%\n","Iteration step: 75; Loss: 0.096, Accuracy: 97.286%\n","Iteration step: 76; Loss: 0.096, Accuracy: 97.281%\n","Iteration step: 77; Loss: 0.097, Accuracy: 97.276%\n","Iteration step: 78; Loss: 0.097, Accuracy: 97.271%\n","Iteration step: 79; Loss: 0.098, Accuracy: 97.227%\n","Iteration step: 80; Loss: 0.099, Accuracy: 97.145%\n","Iteration step: 81; Loss: 0.098, Accuracy: 97.180%\n","Iteration step: 82; Loss: 0.099, Accuracy: 97.139%\n","Iteration step: 83; Loss: 0.099, Accuracy: 97.135%\n","Iteration step: 84; Loss: 0.098, Accuracy: 97.132%\n","Iteration step: 85; Loss: 0.098, Accuracy: 97.166%\n","Iteration step: 86; Loss: 0.098, Accuracy: 97.198%\n","Iteration step: 87; Loss: 0.097, Accuracy: 97.230%\n","Iteration step: 88; Loss: 0.097, Accuracy: 97.261%\n","Iteration step: 89; Loss: 0.097, Accuracy: 97.257%\n","Iteration step: 90; Loss: 0.098, Accuracy: 97.253%\n","Iteration step: 91; Loss: 0.098, Accuracy: 97.215%\n","Iteration step: 92; Loss: 0.098, Accuracy: 97.245%\n","Iteration step: 93; Loss: 0.097, Accuracy: 97.274%\n","Iteration step: 94; Loss: 0.097, Accuracy: 97.303%\n","Iteration step: 95; Loss: 0.096, Accuracy: 97.298%\n","Iteration step: 96; Loss: 0.096, Accuracy: 97.326%\n","Iteration step: 97; Loss: 0.096, Accuracy: 97.321%\n","Iteration step: 98; Loss: 0.095, Accuracy: 97.317%\n","Iteration step: 99; Loss: 0.095, Accuracy: 97.344%\n","Iteration step: 100; Loss: 0.095, Accuracy: 97.308%\n","Iteration step: 101; Loss: 0.095, Accuracy: 97.273%\n","Iteration step: 102; Loss: 0.095, Accuracy: 97.300%\n","Iteration step: 103; Loss: 0.095, Accuracy: 97.296%\n","Iteration step: 104; Loss: 0.094, Accuracy: 97.321%\n","Iteration step: 105; Loss: 0.094, Accuracy: 97.317%\n","Iteration step: 106; Loss: 0.094, Accuracy: 97.342%\n","Iteration step: 107; Loss: 0.093, Accuracy: 97.338%\n","Iteration step: 108; Loss: 0.093, Accuracy: 97.362%\n","Iteration step: 109; Loss: 0.092, Accuracy: 97.386%\n","Iteration step: 110; Loss: 0.092, Accuracy: 97.410%\n","Iteration step: 111; Loss: 0.092, Accuracy: 97.405%\n","Iteration step: 112; Loss: 0.092, Accuracy: 97.400%\n","Iteration step: 113; Loss: 0.092, Accuracy: 97.396%\n","Iteration step: 114; Loss: 0.092, Accuracy: 97.418%\n","Iteration step: 115; Loss: 0.093, Accuracy: 97.387%\n","Iteration step: 116; Loss: 0.093, Accuracy: 97.409%\n","Iteration step: 117; Loss: 0.092, Accuracy: 97.431%\n","Iteration step: 118; Loss: 0.092, Accuracy: 97.453%\n","Iteration step: 119; Loss: 0.092, Accuracy: 97.448%\n","Iteration step: 120; Loss: 0.092, Accuracy: 97.469%\n","Iteration step: 121; Loss: 0.092, Accuracy: 97.439%\n","Iteration step: 122; Loss: 0.092, Accuracy: 97.434%\n","Iteration step: 123; Loss: 0.092, Accuracy: 97.404%\n","Iteration step: 124; Loss: 0.092, Accuracy: 97.425%\n","Iteration step: 125; Loss: 0.091, Accuracy: 97.445%\n","Iteration step: 126; Loss: 0.091, Accuracy: 97.441%\n","Iteration step: 127; Loss: 0.092, Accuracy: 97.437%\n","Iteration step: 128; Loss: 0.093, Accuracy: 97.384%\n","Iteration step: 129; Loss: 0.093, Accuracy: 97.404%\n","Iteration step: 130; Loss: 0.093, Accuracy: 97.400%\n","Iteration step: 131; Loss: 0.092, Accuracy: 97.420%\n","Iteration step: 132; Loss: 0.092, Accuracy: 97.415%\n","Iteration step: 133; Loss: 0.092, Accuracy: 97.411%\n","Iteration step: 134; Loss: 0.092, Accuracy: 97.431%\n","Iteration step: 135; Loss: 0.092, Accuracy: 97.449%\n","Iteration step: 136; Loss: 0.092, Accuracy: 97.400%\n","Iteration step: 137; Loss: 0.092, Accuracy: 97.396%\n","Iteration step: 138; Loss: 0.092, Accuracy: 97.392%\n","Iteration step: 139; Loss: 0.092, Accuracy: 97.388%\n","Iteration step: 140; Loss: 0.092, Accuracy: 97.407%\n","Iteration step: 141; Loss: 0.091, Accuracy: 97.425%\n","Iteration step: 142; Loss: 0.091, Accuracy: 97.443%\n","Iteration step: 143; Loss: 0.091, Accuracy: 97.439%\n","Iteration step: 144; Loss: 0.091, Accuracy: 97.457%\n","Iteration step: 145; Loss: 0.091, Accuracy: 97.453%\n","Iteration step: 146; Loss: 0.091, Accuracy: 97.470%\n","Iteration step: 147; Loss: 0.091, Accuracy: 97.466%\n","Iteration step: 148; Loss: 0.091, Accuracy: 97.462%\n","Iteration step: 149; Loss: 0.091, Accuracy: 97.479%\n","Iteration step: 150; Loss: 0.093, Accuracy: 97.413%\n","Iteration step: 151; Loss: 0.093, Accuracy: 97.410%\n","Iteration step: 152; Loss: 0.094, Accuracy: 97.406%\n","Iteration step: 153; Loss: 0.093, Accuracy: 97.403%\n","Iteration step: 154; Loss: 0.094, Accuracy: 97.399%\n","Iteration step: 155; Loss: 0.093, Accuracy: 97.416%\n","Iteration step: 156; Loss: 0.093, Accuracy: 97.432%\n","Iteration step: 157; Loss: 0.093, Accuracy: 97.429%\n","Iteration step: 158; Loss: 0.094, Accuracy: 97.425%\n","Iteration step: 159; Loss: 0.093, Accuracy: 97.441%\n","Iteration step: 160; Loss: 0.093, Accuracy: 97.457%\n","Iteration step: 161; Loss: 0.093, Accuracy: 97.454%\n","Iteration step: 162; Loss: 0.093, Accuracy: 97.469%\n","Iteration step: 163; Loss: 0.093, Accuracy: 97.485%\n","Iteration step: 164; Loss: 0.093, Accuracy: 97.481%\n","Iteration step: 165; Loss: 0.093, Accuracy: 97.485%\n","Epoch: 12; Validation loss 0.08171775192022324; acc: 0.979580283164978\n","Current epoch: 13\n","Iteration step: 0; Loss: 0.028, Accuracy: 100.000%\n","Iteration step: 1; Loss: 0.083, Accuracy: 98.438%\n","Iteration step: 2; Loss: 0.137, Accuracy: 95.833%\n","Iteration step: 3; Loss: 0.108, Accuracy: 96.875%\n","Iteration step: 4; Loss: 0.104, Accuracy: 96.875%\n","Iteration step: 5; Loss: 0.097, Accuracy: 97.396%\n","Iteration step: 6; Loss: 0.107, Accuracy: 97.321%\n","Iteration step: 7; Loss: 0.109, Accuracy: 97.266%\n","Iteration step: 8; Loss: 0.108, Accuracy: 97.222%\n","Iteration step: 9; Loss: 0.112, Accuracy: 97.188%\n","Iteration step: 10; Loss: 0.114, Accuracy: 96.875%\n","Iteration step: 11; Loss: 0.111, Accuracy: 96.875%\n","Iteration step: 12; Loss: 0.105, Accuracy: 97.115%\n","Iteration step: 13; Loss: 0.105, Accuracy: 97.098%\n","Iteration step: 14; Loss: 0.101, Accuracy: 97.083%\n","Iteration step: 15; Loss: 0.098, Accuracy: 97.266%\n","Iteration step: 16; Loss: 0.095, Accuracy: 97.426%\n","Iteration step: 17; Loss: 0.094, Accuracy: 97.569%\n","Iteration step: 18; Loss: 0.091, Accuracy: 97.697%\n","Iteration step: 19; Loss: 0.092, Accuracy: 97.656%\n","Iteration step: 20; Loss: 0.089, Accuracy: 97.768%\n","Iteration step: 21; Loss: 0.091, Accuracy: 97.443%\n","Iteration step: 22; Loss: 0.090, Accuracy: 97.418%\n","Iteration step: 23; Loss: 0.092, Accuracy: 97.266%\n","Iteration step: 24; Loss: 0.089, Accuracy: 97.375%\n","Iteration step: 25; Loss: 0.088, Accuracy: 97.356%\n","Iteration step: 26; Loss: 0.088, Accuracy: 97.338%\n","Iteration step: 27; Loss: 0.094, Accuracy: 97.210%\n","Iteration step: 28; Loss: 0.094, Accuracy: 97.091%\n","Iteration step: 29; Loss: 0.094, Accuracy: 97.083%\n","Iteration step: 30; Loss: 0.094, Accuracy: 97.077%\n","Iteration step: 31; Loss: 0.094, Accuracy: 97.070%\n","Iteration step: 32; Loss: 0.092, Accuracy: 97.064%\n","Iteration step: 33; Loss: 0.092, Accuracy: 97.059%\n","Iteration step: 34; Loss: 0.093, Accuracy: 97.054%\n","Iteration step: 35; Loss: 0.091, Accuracy: 97.135%\n","Iteration step: 36; Loss: 0.090, Accuracy: 97.128%\n","Iteration step: 37; Loss: 0.089, Accuracy: 97.204%\n","Iteration step: 38; Loss: 0.087, Accuracy: 97.276%\n","Iteration step: 39; Loss: 0.088, Accuracy: 97.266%\n","Iteration step: 40; Loss: 0.088, Accuracy: 97.180%\n","Iteration step: 41; Loss: 0.088, Accuracy: 97.173%\n","Iteration step: 42; Loss: 0.087, Accuracy: 97.166%\n","Iteration step: 43; Loss: 0.086, Accuracy: 97.230%\n","Iteration step: 44; Loss: 0.087, Accuracy: 97.153%\n","Iteration step: 45; Loss: 0.087, Accuracy: 97.215%\n","Iteration step: 46; Loss: 0.086, Accuracy: 97.274%\n","Iteration step: 47; Loss: 0.084, Accuracy: 97.331%\n","Iteration step: 48; Loss: 0.084, Accuracy: 97.321%\n","Iteration step: 49; Loss: 0.084, Accuracy: 97.312%\n","Iteration step: 50; Loss: 0.083, Accuracy: 97.365%\n","Iteration step: 51; Loss: 0.083, Accuracy: 97.356%\n","Iteration step: 52; Loss: 0.082, Accuracy: 97.406%\n","Iteration step: 53; Loss: 0.081, Accuracy: 97.454%\n","Iteration step: 54; Loss: 0.081, Accuracy: 97.500%\n","Iteration step: 55; Loss: 0.082, Accuracy: 97.489%\n","Iteration step: 56; Loss: 0.082, Accuracy: 97.533%\n","Iteration step: 57; Loss: 0.081, Accuracy: 97.575%\n","Iteration step: 58; Loss: 0.080, Accuracy: 97.617%\n","Iteration step: 59; Loss: 0.080, Accuracy: 97.552%\n","Iteration step: 60; Loss: 0.079, Accuracy: 97.592%\n","Iteration step: 61; Loss: 0.080, Accuracy: 97.581%\n","Iteration step: 62; Loss: 0.080, Accuracy: 97.619%\n","Iteration step: 63; Loss: 0.079, Accuracy: 97.656%\n","Iteration step: 64; Loss: 0.079, Accuracy: 97.692%\n","Iteration step: 65; Loss: 0.078, Accuracy: 97.727%\n","Iteration step: 66; Loss: 0.078, Accuracy: 97.668%\n","Iteration step: 67; Loss: 0.078, Accuracy: 97.656%\n","Iteration step: 68; Loss: 0.078, Accuracy: 97.690%\n","Iteration step: 69; Loss: 0.077, Accuracy: 97.679%\n","Iteration step: 70; Loss: 0.077, Accuracy: 97.711%\n","Iteration step: 71; Loss: 0.079, Accuracy: 97.700%\n","Iteration step: 72; Loss: 0.079, Accuracy: 97.646%\n","Iteration step: 73; Loss: 0.079, Accuracy: 97.677%\n","Iteration step: 74; Loss: 0.081, Accuracy: 97.667%\n","Iteration step: 75; Loss: 0.080, Accuracy: 97.697%\n","Iteration step: 76; Loss: 0.080, Accuracy: 97.727%\n","Iteration step: 77; Loss: 0.081, Accuracy: 97.676%\n","Iteration step: 78; Loss: 0.081, Accuracy: 97.706%\n","Iteration step: 79; Loss: 0.080, Accuracy: 97.695%\n","Iteration step: 80; Loss: 0.080, Accuracy: 97.724%\n","Iteration step: 81; Loss: 0.080, Accuracy: 97.752%\n","Iteration step: 82; Loss: 0.079, Accuracy: 97.779%\n","Iteration step: 83; Loss: 0.078, Accuracy: 97.805%\n","Iteration step: 84; Loss: 0.079, Accuracy: 97.794%\n","Iteration step: 85; Loss: 0.078, Accuracy: 97.820%\n","Iteration step: 86; Loss: 0.078, Accuracy: 97.809%\n","Iteration step: 87; Loss: 0.078, Accuracy: 97.798%\n","Iteration step: 88; Loss: 0.078, Accuracy: 97.823%\n","Iteration step: 89; Loss: 0.078, Accuracy: 97.847%\n","Iteration step: 90; Loss: 0.078, Accuracy: 97.837%\n","Iteration step: 91; Loss: 0.078, Accuracy: 97.860%\n","Iteration step: 92; Loss: 0.078, Accuracy: 97.883%\n","Iteration step: 93; Loss: 0.078, Accuracy: 97.839%\n","Iteration step: 94; Loss: 0.078, Accuracy: 97.862%\n","Iteration step: 95; Loss: 0.077, Accuracy: 97.852%\n","Iteration step: 96; Loss: 0.078, Accuracy: 97.809%\n","Iteration step: 97; Loss: 0.079, Accuracy: 97.800%\n","Iteration step: 98; Loss: 0.079, Accuracy: 97.790%\n","Iteration step: 99; Loss: 0.078, Accuracy: 97.812%\n","Iteration step: 100; Loss: 0.078, Accuracy: 97.834%\n","Iteration step: 101; Loss: 0.080, Accuracy: 97.794%\n","Iteration step: 102; Loss: 0.080, Accuracy: 97.816%\n","Iteration step: 103; Loss: 0.080, Accuracy: 97.776%\n","Iteration step: 104; Loss: 0.080, Accuracy: 97.798%\n","Iteration step: 105; Loss: 0.080, Accuracy: 97.789%\n","Iteration step: 106; Loss: 0.080, Accuracy: 97.810%\n","Iteration step: 107; Loss: 0.080, Accuracy: 97.830%\n","Iteration step: 108; Loss: 0.080, Accuracy: 97.821%\n","Iteration step: 109; Loss: 0.081, Accuracy: 97.756%\n","Iteration step: 110; Loss: 0.081, Accuracy: 97.776%\n","Iteration step: 111; Loss: 0.081, Accuracy: 97.796%\n","Iteration step: 112; Loss: 0.080, Accuracy: 97.815%\n","Iteration step: 113; Loss: 0.080, Accuracy: 97.834%\n","Iteration step: 114; Loss: 0.080, Accuracy: 97.799%\n","Iteration step: 115; Loss: 0.081, Accuracy: 97.791%\n","Iteration step: 116; Loss: 0.081, Accuracy: 97.810%\n","Iteration step: 117; Loss: 0.081, Accuracy: 97.802%\n","Iteration step: 118; Loss: 0.082, Accuracy: 97.768%\n","Iteration step: 119; Loss: 0.082, Accuracy: 97.760%\n","Iteration step: 120; Loss: 0.081, Accuracy: 97.779%\n","Iteration step: 121; Loss: 0.081, Accuracy: 97.772%\n","Iteration step: 122; Loss: 0.083, Accuracy: 97.739%\n","Iteration step: 123; Loss: 0.082, Accuracy: 97.732%\n","Iteration step: 124; Loss: 0.082, Accuracy: 97.750%\n","Iteration step: 125; Loss: 0.082, Accuracy: 97.768%\n","Iteration step: 126; Loss: 0.082, Accuracy: 97.785%\n","Iteration step: 127; Loss: 0.081, Accuracy: 97.803%\n","Iteration step: 128; Loss: 0.081, Accuracy: 97.771%\n","Iteration step: 129; Loss: 0.081, Accuracy: 97.788%\n","Iteration step: 130; Loss: 0.081, Accuracy: 97.805%\n","Iteration step: 131; Loss: 0.081, Accuracy: 97.798%\n","Iteration step: 132; Loss: 0.081, Accuracy: 97.791%\n","Iteration step: 133; Loss: 0.081, Accuracy: 97.761%\n","Iteration step: 134; Loss: 0.081, Accuracy: 97.731%\n","Iteration step: 135; Loss: 0.081, Accuracy: 97.702%\n","Iteration step: 136; Loss: 0.081, Accuracy: 97.719%\n","Iteration step: 137; Loss: 0.081, Accuracy: 97.713%\n","Iteration step: 138; Loss: 0.081, Accuracy: 97.729%\n","Iteration step: 139; Loss: 0.081, Accuracy: 97.723%\n","Iteration step: 140; Loss: 0.080, Accuracy: 97.739%\n","Iteration step: 141; Loss: 0.081, Accuracy: 97.689%\n","Iteration step: 142; Loss: 0.081, Accuracy: 97.705%\n","Iteration step: 143; Loss: 0.081, Accuracy: 97.678%\n","Iteration step: 144; Loss: 0.081, Accuracy: 97.694%\n","Iteration step: 145; Loss: 0.081, Accuracy: 97.688%\n","Iteration step: 146; Loss: 0.081, Accuracy: 97.683%\n","Iteration step: 147; Loss: 0.081, Accuracy: 97.677%\n","Iteration step: 148; Loss: 0.081, Accuracy: 97.672%\n","Iteration step: 149; Loss: 0.081, Accuracy: 97.688%\n","Iteration step: 150; Loss: 0.081, Accuracy: 97.703%\n","Iteration step: 151; Loss: 0.082, Accuracy: 97.677%\n","Iteration step: 152; Loss: 0.081, Accuracy: 97.672%\n","Iteration step: 153; Loss: 0.081, Accuracy: 97.687%\n","Iteration step: 154; Loss: 0.081, Accuracy: 97.681%\n","Iteration step: 155; Loss: 0.082, Accuracy: 97.676%\n","Iteration step: 156; Loss: 0.082, Accuracy: 97.691%\n","Iteration step: 157; Loss: 0.083, Accuracy: 97.666%\n","Iteration step: 158; Loss: 0.083, Accuracy: 97.661%\n","Iteration step: 159; Loss: 0.083, Accuracy: 97.676%\n","Iteration step: 160; Loss: 0.083, Accuracy: 97.690%\n","Iteration step: 161; Loss: 0.084, Accuracy: 97.666%\n","Iteration step: 162; Loss: 0.083, Accuracy: 97.680%\n","Iteration step: 163; Loss: 0.083, Accuracy: 97.675%\n","Iteration step: 164; Loss: 0.083, Accuracy: 97.670%\n","Iteration step: 165; Loss: 0.084, Accuracy: 97.674%\n","Epoch: 13; Validation loss 0.08983658999204636; acc: 0.977311372756958\n","Current epoch: 14\n","Iteration step: 0; Loss: 0.102, Accuracy: 96.875%\n","Iteration step: 1; Loss: 0.153, Accuracy: 95.312%\n","Iteration step: 2; Loss: 0.113, Accuracy: 96.875%\n","Iteration step: 3; Loss: 0.105, Accuracy: 96.875%\n","Iteration step: 4; Loss: 0.110, Accuracy: 96.250%\n","Iteration step: 5; Loss: 0.100, Accuracy: 96.875%\n","Iteration step: 6; Loss: 0.090, Accuracy: 97.321%\n","Iteration step: 7; Loss: 0.083, Accuracy: 97.656%\n","Iteration step: 8; Loss: 0.093, Accuracy: 97.222%\n","Iteration step: 9; Loss: 0.092, Accuracy: 97.500%\n","Iteration step: 10; Loss: 0.087, Accuracy: 97.727%\n","Iteration step: 11; Loss: 0.101, Accuracy: 97.396%\n","Iteration step: 12; Loss: 0.096, Accuracy: 97.596%\n","Iteration step: 13; Loss: 0.093, Accuracy: 97.768%\n","Iteration step: 14; Loss: 0.088, Accuracy: 97.917%\n","Iteration step: 15; Loss: 0.087, Accuracy: 97.852%\n","Iteration step: 16; Loss: 0.083, Accuracy: 97.978%\n","Iteration step: 17; Loss: 0.082, Accuracy: 98.090%\n","Iteration step: 18; Loss: 0.081, Accuracy: 98.191%\n","Iteration step: 19; Loss: 0.079, Accuracy: 98.281%\n","Iteration step: 20; Loss: 0.077, Accuracy: 98.363%\n","Iteration step: 21; Loss: 0.076, Accuracy: 98.295%\n","Iteration step: 22; Loss: 0.079, Accuracy: 98.234%\n","Iteration step: 23; Loss: 0.078, Accuracy: 98.307%\n","Iteration step: 24; Loss: 0.081, Accuracy: 98.125%\n","Iteration step: 25; Loss: 0.079, Accuracy: 98.197%\n","Iteration step: 26; Loss: 0.077, Accuracy: 98.264%\n","Iteration step: 27; Loss: 0.075, Accuracy: 98.326%\n","Iteration step: 28; Loss: 0.072, Accuracy: 98.384%\n","Iteration step: 29; Loss: 0.072, Accuracy: 98.438%\n","Iteration step: 30; Loss: 0.071, Accuracy: 98.488%\n","Iteration step: 31; Loss: 0.074, Accuracy: 98.438%\n","Iteration step: 32; Loss: 0.073, Accuracy: 98.485%\n","Iteration step: 33; Loss: 0.078, Accuracy: 98.254%\n","Iteration step: 34; Loss: 0.076, Accuracy: 98.304%\n","Iteration step: 35; Loss: 0.077, Accuracy: 98.351%\n","Iteration step: 36; Loss: 0.079, Accuracy: 98.142%\n","Iteration step: 37; Loss: 0.081, Accuracy: 98.026%\n","Iteration step: 38; Loss: 0.080, Accuracy: 98.077%\n","Iteration step: 39; Loss: 0.083, Accuracy: 97.969%\n","Iteration step: 40; Loss: 0.081, Accuracy: 98.018%\n","Iteration step: 41; Loss: 0.080, Accuracy: 98.065%\n","Iteration step: 42; Loss: 0.079, Accuracy: 98.110%\n","Iteration step: 43; Loss: 0.078, Accuracy: 98.153%\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-6b1b3f56ff07>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m           \u001b[0;31m# Track progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-3442ceaf6faf>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(features, labels, training)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Get the probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-3e509bd5fbab>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_tensor, training)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mconv_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_expanded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mpool_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_max_pooling_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/activations.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(x, alpha, max_value, threshold)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \"\"\"\n\u001b[0;32m--> 306\u001b[0;31m     return backend.relu(\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(x, alpha, max_value, threshold)\u001b[0m\n\u001b[1;32m   5393\u001b[0m         \u001b[0mclip_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5394\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5395\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(features, name)\u001b[0m\n\u001b[1;32m  11580\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11581\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11582\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m  11583\u001b[0m         _ctx, \"Relu\", name, features)\n\u001b[1;32m  11584\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["tf_record_file = '/content/drive/MyDrive/HK2_2023-2024/NT230/processData/Opcode/opcode_tf_record_train'\n","vocabulary={\"UNK\": 0, \"NONE\": 1, \"PAD\": 2, \"andps\": 3, \"psubusb\": 4, \"por\": 5, \"jnz\": 6, \"fxch4\": 7, \"pabsw\": 8, \"bsr\": 9, \"setl\": 10, \"paddw\": 11, \"fxsave\": 12, \"vmwrite\": 13, \"bound\": 14, \"jo\": 15, \"movhps\": 16, \"into\": 17, \"vmovd\": 18, \"pxor\": 19, \"vinsertf128\": 20, \"vmovdqa\": 21, \"paddsw\": 22, \"fist\": 23, \"orps\": 24, \"vmovapd\": 25, \"paddusw\": 26, \"roundps\": 27, \"fsub\": 28, \"bsf\": 29, \"fcmovu\": 30, \"vorpd\": 31, \"packuswb\": 32, \"unpckhpd\": 33, \"shufpd\": 34, \"pminuw\": 35, \"psubq\": 36, \"arpl\": 37, \"pandn\": 38, \"extractps\": 39, \"vpunpckhbw\": 40, \"vcvtss2sd\": 41, \"vpmullw\": 42, \"bswap\": 43, \"rcr\": 44, \"pmovzxbd\": 45, \"movsd\": 46, \"lddqu\": 47, \"movhpd\": 48, \"packusdw\": 49, \"jns\": 50, \"pshuflw\": 51, \"jnb\": 52, \"psllw\": 53, \"cvttps2dq\": 54, \"cmova\": 55, \"psrlq\": 56, \"setnbe\": 57, \"fcmovbe\": 58, \"leave\": 59, \"punpckldq\": 60, \"ffreep\": 61, \"phaddd\": 62, \"cmovb\": 63, \"insertps\": 64, \"scas\": 65, \"cmpps\": 66, \"sub\": 67, \"punpckhqdq\": 68, \"xchg\": 69, \"fcmovnbe\": 70, \"rol\": 71, \"pmulhrsw\": 72, \"fstsw\": 73, \"movnti\": 74, \"jnp\": 75, \"setz\": 76, \"int\": 77, \"minsd\": 78, \"paddusb\": 79, \"mulps\": 80, \"fcompp\": 81, \"vextractf128\": 82, \"lar\": 83, \"psrld\": 84, \"seto\": 85, \"vperm2f128\": 86, \"js\": 87, \"fadd\": 88, \"not\": 89, \"jmp\": 90, \"lss\": 91, \"paddq\": 92, \"fcmovnb\": 93, \"pfsubr\": 94, \"psrlw\": 95, \"punpckhdq\": 96, \"sqrtss\": 97, \"jg\": 98, \"pavgw\": 99, \"rcpss\": 100, \"cvtsd2si\": 101, \"pmaddwd\": 102, \"ucomisd\": 103, \"btr\": 104, \"cmovbe\": 105, \"vmovsd\": 106, \"jge\": 107, \"cmpneqps\": 108, \"vpaddw\": 109, \"sbb\": 110, \"cmovp\": 111, \"fcomi\": 112, \"idiv\": 113, \"pavgusb\": 114, \"jl\": 115, \"psubusw\": 116, \"fsubr\": 117, \"btc\": 118, \"pfadd\": 119, \"pshufb\": 120, \"addps\": 121, \"pand\": 122, \"imul\": 123, \"lidt\": 124, \"pshufhw\": 125, \"movaps\": 126, \"fild\": 127, \"lfs\": 128, \"addsd\": 129, \"lgs\": 130, \"addpd\": 131, \"vmptrst\": 132, \"vpcmpeqw\": 133, \"pshufd\": 134, \"fidivr\": 135, \"divss\": 136, \"prefetcht2\": 137, \"psrldq\": 138, \"shl\": 139, \"psraw\": 140, \"cvtdq2pd\": 141, \"pcmpgtw\": 142, \"vmovddup\": 143, \"subpd\": 144, \"movsx\": 145, \"vpcmpgtw\": 146, \"xor\": 147, \"fmul\": 148, \"cmp\": 149, \"movss\": 150, \"retnw\": 151, \"vpextrw\": 152, \"femms\": 153, \"rcl\": 154, \"wait\": 155, \"pslld\": 156, \"orpd\": 157, \"vunpckhps\": 158, \"pinsrd\": 159, \"xbegin\": 160, \"inc\": 161, \"ficom\": 162, \"sgdt\": 163, \"test\": 164, \"setbe\": 165, \"mpsadbw\": 166, \"prefetchnta\": 167, \"cmpleps\": 168, \"pcmpeqd\": 169, \"cmovl\": 170, \"ffree\": 171, \"fdivp\": 172, \"cmpltps\": 173, \"cvttsd2si\": 174, \"pmaxub\": 175, \"vsqrtpd\": 176, \"fistp\": 177, \"fnstenv\": 178, \"punpcklbw\": 179, \"vpmaddwd\": 180, \"fxch\": 181, \"cvtpd2ps\": 182, \"ucomiss\": 183, \"setno\": 184, \"sar\": 185, \"maxps\": 186, \"pmuludq\": 187, \"cvtps2pd\": 188, \"vpaddusw\": 189, \"fsubrp\": 190, \"movlps\": 191, \"fld1\": 192, \"jb\": 193, \"and\": 194, \"jbe\": 195, \"pcmpeqw\": 196, \"fnsave\": 197, \"cmovo\": 198, \"out\": 199, \"frstor\": 200, \"ldmxcsr\": 201, \"div\": 202, \"cvtpi2ps\": 203, \"mulpd\": 204, \"add\": 205, \"pextrw\": 206, \"movq\": 207, \"pextrb\": 208, \"punpcklwd\": 209, \"shufps\": 210, \"fdivr\": 211, \"cvtsd2ss\": 212, \"adc\": 213, \"movq2dq\": 214, \"cmpltpd\": 215, \"paddb\": 216, \"cmps\": 217, \"addss\": 218, \"vpunpckldq\": 219, \"pmovzxwd\": 220, \"vaddps\": 221, \"cmovno\": 222, \"pfmul\": 223, \"pmaxsw\": 224, \"subss\": 225, \"cvtsi2ss\": 226, \"subsd\": 227, \"cdq\": 228, \"stmxcsr\": 229, \"vmptrld\": 230, \"setnl\": 231, \"shrd\": 232, \"push\": 233, \"or\": 234, \"fucompp\": 235, \"cvtdq2ps\": 236, \"vpshufhw\": 237, \"fnstsw\": 238, \"pmulhw\": 239, \"vmulps\": 240, \"xlat\": 241, \"cvtsi2sd\": 242, \"cmovnp\": 243, \"subps\": 244, \"pslldq\": 245, \"ror\": 246, \"fcmovne\": 247, \"pfrcpit1\": 248, \"mulss\": 249, \"psadbw\": 250, \"movmskps\": 251, \"fcomp\": 252, \"fnstcw\": 253, \"jp\": 254, \"divsd\": 255, \"movhlps\": 256, \"fmulp\": 257, \"fdiv\": 258, \"pfrcpit2\": 259, \"jno\": 260, \"setnz\": 261, \"fld\": 262, \"in\": 263, \"paddd\": 264, \"cmpeqsd\": 265, \"str\": 266, \"lds\": 267, \"setnb\": 268, \"aam\": 269, \"packsswb\": 270, \"sets\": 271, \"pminsw\": 272, \"vdivsd\": 273, \"xorpd\": 274, \"faddp\": 275, \"lldt\": 276, \"andnpd\": 277, \"pmovmskb\": 278, \"fucomp\": 279, \"retn\": 280, \"mov\": 281, \"fsubp\": 282, \"sqrtsd\": 283, \"clflush\": 284, \"pshufw\": 285, \"vrcpss\": 286, \"enter\": 287, \"vsubps\": 288, \"psubsb\": 289, \"fstp\": 290, \"movntdq\": 291, \"punpckhwd\": 292, \"cvtps2pi\": 293, \"fiadd\": 294, \"pfcmpge\": 295, \"setnp\": 296, \"pfrcp\": 297, \"psubw\": 298, \"movdq2q\": 299, \"lock\": 300, \"cmpsw\": 301, \"phaddw\": 302, \"sldt\": 303, \"pfsub\": 304, \"comisd\": 305, \"punpcklqdq\": 306, \"vcvttpd2dq\": 307, \"loopne\": 308, \"pop\": 309, \"lods\": 310, \"xadd\": 311, \"pblendvb\": 312, \"pcmpgtd\": 313, \"xorps\": 314, \"fcmovb\": 315, \"cmovge\": 316, \"movups\": 317, \"comiss\": 318, \"vdivps\": 319, \"pfnacc\": 320, \"fidiv\": 321, \"fucomi\": 322, \"fldenv\": 323, \"vmovaps\": 324, \"movntps\": 325, \"prefetchw\": 326, \"pmaddubsw\": 327, \"psubd\": 328, \"cmovns\": 329, \"pmulhuw\": 330, \"cmovs\": 331, \"setb\": 332, \"movlhps\": 333, \"movdqu\": 334, \"movzx\": 335, \"movmskpd\": 336, \"setle\": 337, \"psubsw\": 338, \"vshufps\": 339, \"prefetcht0\": 340, \"cmpnlesd\": 341, \"loop\": 342, \"cmpltsd\": 343, \"pswapd\": 344, \"vandnpd\": 345, \"unpcklpd\": 346, \"cld\": 347, \"cmovle\": 348, \"fldcw\": 349, \"lea\": 350, \"cmpxchg\": 351, \"fldz\": 352, \"vminsd\": 353, \"fcom\": 354, \"jz\": 355, \"cmpnlepd\": 356, \"shr\": 357, \"pminub\": 358, \"paddsb\": 359, \"fimul\": 360, \"vpsrad\": 361, \"rsqrtps\": 362, \"fxch7\": 363, \"minps\": 364, \"psubb\": 365, \"nop\": 366, \"call\": 367, \"minss\": 368, \"cvtss2sd\": 369, \"cvttps2pi\": 370, \"psrad\": 371, \"movntq\": 372, \"divps\": 373, \"vmovdqu\": 374, \"shld\": 375, \"cmplesd\": 376, \"stos\": 377, \"cvtss2si\": 378, \"vblendps\": 379, \"bts\": 380, \"mul\": 381, \"fisub\": 382, \"fcmove\": 383, \"retf\": 384, \"andpd\": 385, \"pinsrw\": 386, \"cmovg\": 387, \"pmullw\": 388, \"retfw\": 389, \"rcpps\": 390, \"vmread\": 391, \"sqrtps\": 392, \"maxss\": 393, \"jcxz\": 394, \"lsl\": 395, \"vpsllw\": 396, \"fisttp\": 397, \"packssdw\": 398, \"unpckhps\": 399, \"aad\": 400, \"lgdt\": 401, \"bt\": 402, \"vpermilps\": 403, \"pfmax\": 404, \"pfcmpgt\": 405, \"fucom\": 406, \"unpcklps\": 407, \"fbstp\": 408, \"psllq\": 409, \"movapd\": 410, \"palignr\": 411, \"fst\": 412, \"align\": 413, \"pextrd\": 414, \"vxorps\": 415, \"cvtps2dq\": 416, \"dec\": 417, \"ja\": 418, \"sal\": 419, \"movlpd\": 420, \"fisubr\": 421, \"phminposuw\": 422, \"andnps\": 423, \"pi2fd\": 424, \"movdqa\": 425, \"cmpxchg8b\": 426, \"vunpcklps\": 427, \"setnle\": 428, \"pf2id\": 429, \"fbld\": 430, \"jecxz\": 431, \"ficomp\": 432, \"punpckhbw\": 433, \"movd\": 434, \"fdivrp\": 435, \"loope\": 436, \"setp\": 437, \"mulsd\": 438, \"rsqrtss\": 439, \"pavgb\": 440, \"vmovups\": 441, \"fcmovnu\": 442, \"cvttss2si\": 443, \"les\": 444, \"xabort\": 445, \"neg\": 446, \"cmpneqpd\": 447, \"vpshuflw\": 448, \"pcmpeqb\": 449, \"setns\": 450, \"jle\": 451, \"pcmpgtb\": 452, \"dw\": 453, \"db\": 454, \"dd\": 455, \"stop_line\": 456, \"loc_\": 457, \"sub_\": 458, \"endp\": 459}\n","\n","lookup_table = create_lookup_table(vocabulary_mapping=vocabulary, num_oov_buckets=1)\n","\n","\n","# Training loop\n","# 1/ Iterate each epoch. An epoch is one pass through the dataset\n","# 2/ Whithin an epoch, iterate over each example in the training Dataset.\n","# 3/ Calculate model's loss and gradients\n","# 4/ Use an optimizer to update the model's variables\n","# 5/ Keep track of stats and repeat\n","\n","train_loss_results = []\n","train_accuracy_results = []\n","\n","validation_loss_results = []\n","validation_accuracy_results = []\n","\n","#checkpoint_path = \"models/ShallowCNN/model_ep_{}.ckpt\"\n","#checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","num_epochs = parameters['epochs']\n","\n","initial_loss = 10.0\n","\n","for epoch in range(num_epochs):\n","      print(\"Current epoch: {}\".format(epoch))\n","      # checkpoint_path = \"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/opcodes/FullData/opcode_model_cp.weights.h5\"\n","      checkpoint_path = \"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/models/{}/\".format(\"ShallowCNN\") + \"model_ep_{}.ckpt\".format(epoch)\n","      #checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","      d_train = make_dataset(tf_record_file,\n","                              lookup_table,\n","                              parameters['buffer_size'],\n","                              parameters['batch_size'],\n","                              1)\n","      d_val = make_dataset(tf_record_file,\n","                            lookup_table,\n","                            1024,\n","                            1,\n","                            1)\n","\n","\n","      # Training metrics\n","      epoch_loss_avg = tf.keras.metrics.Mean()\n","      epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n","      # Validation metrics\n","      val_epoch_loss_avg = tf.keras.metrics.Mean()\n","      val_epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n","      tr_step = 0\n","\n","      # Training loop\n","      for step, (x, y) in enumerate(d_train):\n","\n","\n","          loss, y_ = train_loop(features=x, labels=y, training=True)\n","\n","          # Track progress\n","          epoch_loss_avg(loss)\n","          epoch_accuracy(y, y_)\n","          print(\"Iteration step: {}; Loss: {:.3f}, Accuracy: {:.3%}\".format(tr_step,\n","                                                                            epoch_loss_avg.result(),\n","                                                                            epoch_accuracy.result()))\n","\n","\n","          tr_step += 1\n","\n","      # End epoch\n","      train_loss_results.append(epoch_loss_avg.result())\n","      train_accuracy_results.append(epoch_accuracy.result())\n","\n","\n","\n","      # Run a validation loop at the end of each epoch.\n","      for x_batch_val, y_batch_val in d_val:\n","          val_logits = model(x_batch_val)\n","          val_loss = loss_func(y_batch_val, val_logits)\n","\n","          # Update metrics\n","          val_epoch_loss_avg(val_loss)\n","          val_epoch_accuracy(y_batch_val, val_logits)\n","\n","      val_acc = val_epoch_accuracy.result()\n","      val_loss = val_epoch_loss_avg.result()\n","      print('Epoch: {}; Validation loss {}; acc: {}'.format(epoch, val_loss, val_acc))\n","\n","      validation_loss_results.append(val_loss)\n","      validation_accuracy_results.append(val_acc)\n","\n","      if float(val_loss) < initial_loss:\n","          initial_loss = float(val_loss)\n","          model.save_weights(checkpoint_path) # Save only the weights\n","\n"]},{"cell_type":"markdown","source":["# test opcodess\n"],"metadata":{"id":"bXXLr-p4YWzN"}},{"cell_type":"code","source":["model1 = model"],"metadata":{"id":"0ZS3lyVPM58W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocabulary={\"UNK\": 0, \"NONE\": 1, \"PAD\": 2, \"andps\": 3, \"psubusb\": 4, \"por\": 5, \"jnz\": 6, \"fxch4\": 7, \"pabsw\": 8, \"bsr\": 9, \"setl\": 10, \"paddw\": 11, \"fxsave\": 12, \"vmwrite\": 13, \"bound\": 14, \"jo\": 15, \"movhps\": 16, \"into\": 17, \"vmovd\": 18, \"pxor\": 19, \"vinsertf128\": 20, \"vmovdqa\": 21, \"paddsw\": 22, \"fist\": 23, \"orps\": 24, \"vmovapd\": 25, \"paddusw\": 26, \"roundps\": 27, \"fsub\": 28, \"bsf\": 29, \"fcmovu\": 30, \"vorpd\": 31, \"packuswb\": 32, \"unpckhpd\": 33, \"shufpd\": 34, \"pminuw\": 35, \"psubq\": 36, \"arpl\": 37, \"pandn\": 38, \"extractps\": 39, \"vpunpckhbw\": 40, \"vcvtss2sd\": 41, \"vpmullw\": 42, \"bswap\": 43, \"rcr\": 44, \"pmovzxbd\": 45, \"movsd\": 46, \"lddqu\": 47, \"movhpd\": 48, \"packusdw\": 49, \"jns\": 50, \"pshuflw\": 51, \"jnb\": 52, \"psllw\": 53, \"cvttps2dq\": 54, \"cmova\": 55, \"psrlq\": 56, \"setnbe\": 57, \"fcmovbe\": 58, \"leave\": 59, \"punpckldq\": 60, \"ffreep\": 61, \"phaddd\": 62, \"cmovb\": 63, \"insertps\": 64, \"scas\": 65, \"cmpps\": 66, \"sub\": 67, \"punpckhqdq\": 68, \"xchg\": 69, \"fcmovnbe\": 70, \"rol\": 71, \"pmulhrsw\": 72, \"fstsw\": 73, \"movnti\": 74, \"jnp\": 75, \"setz\": 76, \"int\": 77, \"minsd\": 78, \"paddusb\": 79, \"mulps\": 80, \"fcompp\": 81, \"vextractf128\": 82, \"lar\": 83, \"psrld\": 84, \"seto\": 85, \"vperm2f128\": 86, \"js\": 87, \"fadd\": 88, \"not\": 89, \"jmp\": 90, \"lss\": 91, \"paddq\": 92, \"fcmovnb\": 93, \"pfsubr\": 94, \"psrlw\": 95, \"punpckhdq\": 96, \"sqrtss\": 97, \"jg\": 98, \"pavgw\": 99, \"rcpss\": 100, \"cvtsd2si\": 101, \"pmaddwd\": 102, \"ucomisd\": 103, \"btr\": 104, \"cmovbe\": 105, \"vmovsd\": 106, \"jge\": 107, \"cmpneqps\": 108, \"vpaddw\": 109, \"sbb\": 110, \"cmovp\": 111, \"fcomi\": 112, \"idiv\": 113, \"pavgusb\": 114, \"jl\": 115, \"psubusw\": 116, \"fsubr\": 117, \"btc\": 118, \"pfadd\": 119, \"pshufb\": 120, \"addps\": 121, \"pand\": 122, \"imul\": 123, \"lidt\": 124, \"pshufhw\": 125, \"movaps\": 126, \"fild\": 127, \"lfs\": 128, \"addsd\": 129, \"lgs\": 130, \"addpd\": 131, \"vmptrst\": 132, \"vpcmpeqw\": 133, \"pshufd\": 134, \"fidivr\": 135, \"divss\": 136, \"prefetcht2\": 137, \"psrldq\": 138, \"shl\": 139, \"psraw\": 140, \"cvtdq2pd\": 141, \"pcmpgtw\": 142, \"vmovddup\": 143, \"subpd\": 144, \"movsx\": 145, \"vpcmpgtw\": 146, \"xor\": 147, \"fmul\": 148, \"cmp\": 149, \"movss\": 150, \"retnw\": 151, \"vpextrw\": 152, \"femms\": 153, \"rcl\": 154, \"wait\": 155, \"pslld\": 156, \"orpd\": 157, \"vunpckhps\": 158, \"pinsrd\": 159, \"xbegin\": 160, \"inc\": 161, \"ficom\": 162, \"sgdt\": 163, \"test\": 164, \"setbe\": 165, \"mpsadbw\": 166, \"prefetchnta\": 167, \"cmpleps\": 168, \"pcmpeqd\": 169, \"cmovl\": 170, \"ffree\": 171, \"fdivp\": 172, \"cmpltps\": 173, \"cvttsd2si\": 174, \"pmaxub\": 175, \"vsqrtpd\": 176, \"fistp\": 177, \"fnstenv\": 178, \"punpcklbw\": 179, \"vpmaddwd\": 180, \"fxch\": 181, \"cvtpd2ps\": 182, \"ucomiss\": 183, \"setno\": 184, \"sar\": 185, \"maxps\": 186, \"pmuludq\": 187, \"cvtps2pd\": 188, \"vpaddusw\": 189, \"fsubrp\": 190, \"movlps\": 191, \"fld1\": 192, \"jb\": 193, \"and\": 194, \"jbe\": 195, \"pcmpeqw\": 196, \"fnsave\": 197, \"cmovo\": 198, \"out\": 199, \"frstor\": 200, \"ldmxcsr\": 201, \"div\": 202, \"cvtpi2ps\": 203, \"mulpd\": 204, \"add\": 205, \"pextrw\": 206, \"movq\": 207, \"pextrb\": 208, \"punpcklwd\": 209, \"shufps\": 210, \"fdivr\": 211, \"cvtsd2ss\": 212, \"adc\": 213, \"movq2dq\": 214, \"cmpltpd\": 215, \"paddb\": 216, \"cmps\": 217, \"addss\": 218, \"vpunpckldq\": 219, \"pmovzxwd\": 220, \"vaddps\": 221, \"cmovno\": 222, \"pfmul\": 223, \"pmaxsw\": 224, \"subss\": 225, \"cvtsi2ss\": 226, \"subsd\": 227, \"cdq\": 228, \"stmxcsr\": 229, \"vmptrld\": 230, \"setnl\": 231, \"shrd\": 232, \"push\": 233, \"or\": 234, \"fucompp\": 235, \"cvtdq2ps\": 236, \"vpshufhw\": 237, \"fnstsw\": 238, \"pmulhw\": 239, \"vmulps\": 240, \"xlat\": 241, \"cvtsi2sd\": 242, \"cmovnp\": 243, \"subps\": 244, \"pslldq\": 245, \"ror\": 246, \"fcmovne\": 247, \"pfrcpit1\": 248, \"mulss\": 249, \"psadbw\": 250, \"movmskps\": 251, \"fcomp\": 252, \"fnstcw\": 253, \"jp\": 254, \"divsd\": 255, \"movhlps\": 256, \"fmulp\": 257, \"fdiv\": 258, \"pfrcpit2\": 259, \"jno\": 260, \"setnz\": 261, \"fld\": 262, \"in\": 263, \"paddd\": 264, \"cmpeqsd\": 265, \"str\": 266, \"lds\": 267, \"setnb\": 268, \"aam\": 269, \"packsswb\": 270, \"sets\": 271, \"pminsw\": 272, \"vdivsd\": 273, \"xorpd\": 274, \"faddp\": 275, \"lldt\": 276, \"andnpd\": 277, \"pmovmskb\": 278, \"fucomp\": 279, \"retn\": 280, \"mov\": 281, \"fsubp\": 282, \"sqrtsd\": 283, \"clflush\": 284, \"pshufw\": 285, \"vrcpss\": 286, \"enter\": 287, \"vsubps\": 288, \"psubsb\": 289, \"fstp\": 290, \"movntdq\": 291, \"punpckhwd\": 292, \"cvtps2pi\": 293, \"fiadd\": 294, \"pfcmpge\": 295, \"setnp\": 296, \"pfrcp\": 297, \"psubw\": 298, \"movdq2q\": 299, \"lock\": 300, \"cmpsw\": 301, \"phaddw\": 302, \"sldt\": 303, \"pfsub\": 304, \"comisd\": 305, \"punpcklqdq\": 306, \"vcvttpd2dq\": 307, \"loopne\": 308, \"pop\": 309, \"lods\": 310, \"xadd\": 311, \"pblendvb\": 312, \"pcmpgtd\": 313, \"xorps\": 314, \"fcmovb\": 315, \"cmovge\": 316, \"movups\": 317, \"comiss\": 318, \"vdivps\": 319, \"pfnacc\": 320, \"fidiv\": 321, \"fucomi\": 322, \"fldenv\": 323, \"vmovaps\": 324, \"movntps\": 325, \"prefetchw\": 326, \"pmaddubsw\": 327, \"psubd\": 328, \"cmovns\": 329, \"pmulhuw\": 330, \"cmovs\": 331, \"setb\": 332, \"movlhps\": 333, \"movdqu\": 334, \"movzx\": 335, \"movmskpd\": 336, \"setle\": 337, \"psubsw\": 338, \"vshufps\": 339, \"prefetcht0\": 340, \"cmpnlesd\": 341, \"loop\": 342, \"cmpltsd\": 343, \"pswapd\": 344, \"vandnpd\": 345, \"unpcklpd\": 346, \"cld\": 347, \"cmovle\": 348, \"fldcw\": 349, \"lea\": 350, \"cmpxchg\": 351, \"fldz\": 352, \"vminsd\": 353, \"fcom\": 354, \"jz\": 355, \"cmpnlepd\": 356, \"shr\": 357, \"pminub\": 358, \"paddsb\": 359, \"fimul\": 360, \"vpsrad\": 361, \"rsqrtps\": 362, \"fxch7\": 363, \"minps\": 364, \"psubb\": 365, \"nop\": 366, \"call\": 367, \"minss\": 368, \"cvtss2sd\": 369, \"cvttps2pi\": 370, \"psrad\": 371, \"movntq\": 372, \"divps\": 373, \"vmovdqu\": 374, \"shld\": 375, \"cmplesd\": 376, \"stos\": 377, \"cvtss2si\": 378, \"vblendps\": 379, \"bts\": 380, \"mul\": 381, \"fisub\": 382, \"fcmove\": 383, \"retf\": 384, \"andpd\": 385, \"pinsrw\": 386, \"cmovg\": 387, \"pmullw\": 388, \"retfw\": 389, \"rcpps\": 390, \"vmread\": 391, \"sqrtps\": 392, \"maxss\": 393, \"jcxz\": 394, \"lsl\": 395, \"vpsllw\": 396, \"fisttp\": 397, \"packssdw\": 398, \"unpckhps\": 399, \"aad\": 400, \"lgdt\": 401, \"bt\": 402, \"vpermilps\": 403, \"pfmax\": 404, \"pfcmpgt\": 405, \"fucom\": 406, \"unpcklps\": 407, \"fbstp\": 408, \"psllq\": 409, \"movapd\": 410, \"palignr\": 411, \"fst\": 412, \"align\": 413, \"pextrd\": 414, \"vxorps\": 415, \"cvtps2dq\": 416, \"dec\": 417, \"ja\": 418, \"sal\": 419, \"movlpd\": 420, \"fisubr\": 421, \"phminposuw\": 422, \"andnps\": 423, \"pi2fd\": 424, \"movdqa\": 425, \"cmpxchg8b\": 426, \"vunpcklps\": 427, \"setnle\": 428, \"pf2id\": 429, \"fbld\": 430, \"jecxz\": 431, \"ficomp\": 432, \"punpckhbw\": 433, \"movd\": 434, \"fdivrp\": 435, \"loope\": 436, \"setp\": 437, \"mulsd\": 438, \"rsqrtss\": 439, \"pavgb\": 440, \"vmovups\": 441, \"fcmovnu\": 442, \"cvttss2si\": 443, \"les\": 444, \"xabort\": 445, \"neg\": 446, \"cmpneqpd\": 447, \"vpshuflw\": 448, \"pcmpeqb\": 449, \"setns\": 450, \"jle\": 451, \"pcmpgtb\": 452, \"dw\": 453, \"db\": 454, \"dd\": 455, \"stop_line\": 456, \"loc_\": 457, \"sub_\": 458, \"endp\": 459}\n","\n","lookup_table = create_lookup_table(vocabulary_mapping=vocabulary, num_oov_buckets=1)"],"metadata":{"id":"db_ftmgXMo86"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162761,"status":"ok","timestamp":1713408269447,"user":{"displayName":"Nguyễn Thành Công","userId":"07855209270426231427"},"user_tz":-420},"id":"hEgdMGAkkDp_","outputId":"3496dbe6-7ee4-40c2-e038-2dd1264610ef"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).emb.embeddings\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).conv_3.kernel\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).conv_3.bias\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).conv_5.kernel\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).conv_5.bias\n"]},{"output_type":"stream","name":"stdout","text":["LOADING WEIGHTS!!!!\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).conv_7.kernel\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).conv_7.bias\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).dense.kernel\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).dense.bias\n"]},{"output_type":"stream","name":"stdout","text":["Test loss 0.13867677748203278; acc: 0.9682539701461792\n","Confusion Matrix:\n"," [[174   0   0   0   1   0   0   0   3]\n"," [  1 291   0   4   0   0   0   0   5]\n"," [  0   0 378   1   1   0   0   0   0]\n"," [  0   0   0  48   0   0   0   1   2]\n"," [  0   0   0   0   6   1   0   2   0]\n"," [  0   0   0   1   0  74   0   0   0]\n"," [  2   0   0   2   0   0  42   0   0]\n"," [  9   0   0   0   0   0   0 141   0]\n"," [  1   3   0   0   0   1   0   1 127]]\n"]}],"source":["model_test = ShallowCNN(parameters)\n","# model_test.load_weights(\"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/models/ShallowCNN/model_ep_12.ckpt\")\n","\n","if os.path.isdir(\"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/models/{}/\".format(\"ShallowCNN\")):\n","   print(\"LOADING WEIGHTS!!!!\")\n","   latest = tf.train.latest_checkpoint(\"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/models/{}/\".format(\"ShallowCNN\"))\n","   model_test.load_weights(latest)\n","\n","test_epoch_loss_avg = tf.keras.metrics.Mean()\n","test_epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n","\n","y_actual_test = []\n","y_pred_test = []\n","# Evaluate model on the test set\n","\n","d_test = make_dataset(\"/content/drive/MyDrive/HK2_2023-2024/NT230/processData/Opcode/opcode_tf_record_test\",\n","                      lookup_table,\n","                      1,\n","                      1,\n","                      1)\n","\n","for x_batch_test, y_batch_test in d_test:\n","    test_logits = model_test(x_batch_test)\n","    test_loss = loss_func(y_batch_test, test_logits)\n","\n","    # For the confusion matrix\n","    y_pred = tf.argmax(test_logits, axis=-1)\n","    y_pred_test.extend(y_pred)\n","    y_actual_test.extend(y_batch_test)\n","\n","    # Update metrics\n","    test_epoch_loss_avg(test_loss)\n","    test_epoch_accuracy(y_batch_test, test_logits)\n","\n","test_acc = test_epoch_accuracy.result()\n","test_loss = test_epoch_loss_avg.result()\n","print('Test loss {}; acc: {}'.format(test_loss, test_acc))\n","\n","cm = confusion_matrix(y_actual_test, y_pred_test)\n","print(\"Confusion Matrix:\\n {}\".format(cm))"]},{"cell_type":"code","source":["model_test.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gNA-qaQaGAe_","executionInfo":{"status":"ok","timestamp":1713408322310,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nguyễn Thành Công","userId":"07855209270426231427"}},"outputId":"88adbe65-47c2-43e7-f0c1-60d52ccc08e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"shallow_cnn_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  1844      \n","                                                                 \n"," conv2d (Conv2D)             multiple                  1300      \n","                                                                 \n"," global_max_pooling2d (Glob  multiple                  0         \n"," alMaxPooling2D)                                                 \n","                                                                 \n"," conv2d_1 (Conv2D)           multiple                  2100      \n","                                                                 \n"," global_max_pooling2d_1 (Gl  multiple                  0         \n"," obalMaxPooling2D)                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           multiple                  2900      \n","                                                                 \n"," global_max_pooling2d_2 (Gl  multiple                  0         \n"," obalMaxPooling2D)                                               \n","                                                                 \n"," dropout (Dropout)           multiple                  0         \n","                                                                 \n"," dense (Dense)               multiple                  2709      \n","                                                                 \n","=================================================================\n","Total params: 10853 (42.39 KB)\n","Trainable params: 10853 (42.39 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["test_tr = ShallowCNN(parameters)\n","# model_test.load_weights(\"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/models/ShallowCNN/model_ep_12.ckpt\")\n","\n","if os.path.isdir(\"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/models/{}/\".format(\"ShallowCNN\")):\n","   print(\"LOADING WEIGHTS!!!!\")\n","   latest = tf.train.latest_checkpoint(\"/content/drive/MyDrive/HK2_2023-2024/NT230/result_trainning/models/{}/\".format(\"ShallowCNN\"))\n","   test_tr.load_weights(latest)\n","\n","d_test = make_dataset(\"/content/drive/MyDrive/HK2_2023-2024/NT230/processData/Opcode/opcode_tf_record_test\",\n","                      lookup_table,\n","                      1,\n","                      1,\n","                      1)\n","for x_batch_test, y_batch_test in d_test:\n","    test_tr(x_batch_test)\n","    break\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGy0cGM4IOWA","executionInfo":{"status":"ok","timestamp":1713410740678,"user_tz":-420,"elapsed":1429,"user":{"displayName":"Nguyễn Thành Công","userId":"07855209270426231427"}},"outputId":"0726cb87-6be2-4d33-c93b-12907272209f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).emb.embeddings\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).conv_3.kernel\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).conv_3.bias\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).conv_5.kernel\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).conv_5.bias\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).conv_7.kernel\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).conv_7.bias\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).dense.kernel\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).dense.bias\n"]},{"output_type":"stream","name":"stdout","text":["LOADING WEIGHTS!!!!\n"]}]},{"cell_type":"code","source":["layer_names = [layer.name for layer in test_tr.layers]\n","print(test_tr.get_layer(layer_names[0]).get_weights())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LJXichHxPNce","executionInfo":{"status":"ok","timestamp":1713411084297,"user_tz":-420,"elapsed":329,"user":{"displayName":"Nguyễn Thành Công","userId":"07855209270426231427"}},"outputId":"6ebb325d-8266-478c-d2be-4049da3cc8b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[array([[ 0.25944492, -0.07129274,  0.13280305,  0.05998433],\n","       [ 0.02341154,  0.02827766, -0.0086977 ,  0.00122025],\n","       [-0.30409154,  0.29908797, -0.15273829,  0.47198862],\n","       ...,\n","       [-0.02153592, -0.04839319,  0.03893819,  0.0018658 ],\n","       [-0.03110635,  0.03800808,  0.0257141 , -0.02020764],\n","       [-0.0184991 , -0.03971901,  0.01098142,  0.00864998]],\n","      dtype=float32)]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FRq4i49xPJHk"},"outputs":[],"source":["d_train = make_dataset('/content/drive/MyDrive/HK2_2023-2024/NT230/processData/Opcode/opcode_tf_record_train',\n","                        lookup_table,\n","                        parameters['buffer_size'],\n","                        parameters['batch_size'],\n","                              1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"elapsed":645,"status":"error","timestamp":1713193045115,"user":{"displayName":"Nguyễn Thành Công","userId":"07855209270426231427"},"user_tz":-420},"id":"wpltPeZDPdGD","outputId":"05ccc107-2850-4a41-d633-a5f72fb1d3fa"},"outputs":[{"ename":"DataLossError","evalue":"{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} corrupted record at 3948893 [Op:IteratorGetNext] name: ","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-e52f5e9c7a10>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    774\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5882\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5883\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDataLossError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} corrupted record at 3948893 [Op:IteratorGetNext] name: "]}],"source":["import sys\n","for step, (x, y) in enumerate(d_train):\n","    print(x.shape)\n","    print(y.shape)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":685,"status":"ok","timestamp":1712982495336,"user":{"displayName":"Nguyễn Thành Công","userId":"07855209270426231427"},"user_tz":-420},"id":"J6hOBkuekXpw","outputId":"b30f7110-69ed-4232-baf0-7a2f07460ed0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[281 233  67 350 149 195 367 309 205 280 413 213 110 164   6 417 194 147\n"," 355 161 446  90 455 366 460 418 234 453 454   2 123  89 139 202  52 335\n"," 193 381 357 185 347 352 412 262 252 238 254  88 290  71 115  59 181  73\n"," 155 275  98 258 211 172 435 127  44  46 228  50 107 261 451  76 428 229\n"," 201 145 349 177  37 384 300 199  69 354 436 260 308 263 162 117 419 148\n"," 287 400 246  14  15 154 337 175 313 382 431 434  17 113  58 397  75 302\n"," 351 151  77 332 375  87 231  10 380 402 235 257  57  28 321 282 241  43\n"," 269 444 442 200  65 432 253 171 342 408 360 294 104 232 421 310 130 135\n","   3 178 267 430 390 217 383]\n"]}],"source":["\n","import tensorflow as tf\n","\n","# Assuming your tensor is named 'tensor'\n","unique_values, _ = tf.unique(tf.reshape(train, [-1]))\n","\n","# Convert unique values tensor to numpy array\n","unique_values_array = unique_values.numpy()\n","\n","# Print unique values\n","print(unique_values_array)\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/nt230-ac208e02-406f-4f70-9c9f-cb54fa4b46df.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20240411/auto/storage/goog4_request&X-Goog-Date=20240411T232428Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=1450ef1238e8efe62e564b294918909959a42c7f4eadc7994f0376dbf3ef50bb4eb0f8ecbdf034c88478685f76d30e567e7e287f6582fc5d433b5cab09a56ecd59b6ebe0641c9e88f643fcd2cc0b9df98434871f1adaad82af37c8fc2718819997782d18ed9338dc98ac6d3b54cb42f911e5093766bc67fd3ac90a6f4cd0cd3459577e5e185307e43278e31064e9eea382f739f5135493f2652e2cdbecea365a7f56842b98666dead4bfa2e3009d39fec5ab454aa466ad3e20b5ca5826bbd201cdaefb20830b7f4ed3044d739389ad387d1c19d9b4c1cedd460ee1bbc85157b883b45f110da2d6e74dad25b65b4a4c59d37fd0fa3fc1190fa63a6a930e3a4142","timestamp":1712905310154}],"toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":46665,"sourceId":4117,"sourceType":"competition"}],"dockerImageVersionId":30684,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}